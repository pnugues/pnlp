{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7adf9002",
   "metadata": {},
   "source": [
    "# Chapter 17: Sequence-to-Sequence Architectures: Encoder-Decoders and Decoders\n",
    "Stand-alone translation from an existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724a369",
   "metadata": {},
   "source": [
    "Programs from the book: [_Python for Natural Language Processing_](https://link.springer.com/book/9783031575488)\n",
    "\n",
    "__Author__: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe64fa",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6afa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import json\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1206aa1",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b52428",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pico_translator.vocab', 'r') as f:\n",
    "    token2idx = json.loads(f.read())\n",
    "idx2token = {v: k for k, v in token2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233016a9",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea6bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "VOCAB_SIZE = len(token2idx)\n",
    "D_MODEL = 512\n",
    "NHEAD = 8\n",
    "DIM_FF = 512\n",
    "BATCH_SIZE = 32\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "MAX_LEN = max_len + 2\n",
    "MODEL_NAME = 'pico_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc4a17",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e8f0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 dropout=0.1,\n",
    "                 max_len=max_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.input_embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        pe = self.pos_encoding(max_len, d_model)\n",
    "        self.pos_embedding = nn.Embedding.from_pretrained(pe, freeze=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        pos_mat = torch.arange(X.size(-1), device=X.device)\n",
    "        X = self.input_embedding(X) * math.sqrt(self.d_model)\n",
    "        X += self.pos_embedding(pos_mat)\n",
    "        return self.dropout(X)\n",
    "\n",
    "    def pos_encoding(self, max_len, d_model):\n",
    "        dividend = torch.arange(max_len).unsqueeze(0).T\n",
    "        divisor = torch.pow(10000.0, torch.arange(0, d_model, 2) / d_model)\n",
    "        angles = dividend / divisor\n",
    "        pe = torch.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = torch.sin(angles)\n",
    "        pe[:, 1::2] = torch.cos(angles)\n",
    "        return pe\n",
    "\n",
    "\n",
    "class Translator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model=512,\n",
    "                 nhead=8,\n",
    "                 num_encoder_layers=6,\n",
    "                 num_decoder_layers=6,\n",
    "                 dim_feedforward=2048,\n",
    "                 dropout=0.1,\n",
    "                 vocab_size=30000,\n",
    "                 max_len=128):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, d_model, max_len=max_len)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
    "                                          dim_feedforward, dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "        self.fc.weight = self.embedding.input_embedding.weight\n",
    "\n",
    "    def forward(self, src, tgt, src_padding, tgt_padding):\n",
    "        src_embs = self.embedding(src)\n",
    "        tgt_embs = self.embedding(tgt)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(\n",
    "            tgt.size(dim=1), device=src.device)\n",
    "        x = self.transformer(\n",
    "            src_embs, \n",
    "            tgt_embs, \n",
    "            tgt_mask=tgt_mask,\n",
    "            src_key_padding_mask=src_padding,\n",
    "            memory_key_padding_mask=src_padding,\n",
    "            tgt_key_padding_mask=tgt_padding)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7fc2db",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85bb0564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (embedding): Embedding(\n",
       "    (input_embedding): Embedding(117, 512, padding_idx=0)\n",
       "    (pos_embedding): Embedding(102, 512)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=117, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cpu')\n",
    "model = Translator(d_model=D_MODEL, nhead=NHEAD, num_encoder_layers=NUM_ENCODER_LAYERS,\n",
    "                   num_decoder_layers=NUM_DECODER_LAYERS, dim_feedforward=DIM_FF,\n",
    "                   vocab_size=VOCAB_SIZE, max_len=MAX_LEN).to()\n",
    "model.load_state_dict(torch.load(MODEL_NAME, map_location=DEVICE))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca7c2c",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b05c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqs2tensors(seqs, token2idx):\n",
    "    tensors = []\n",
    "    for seq in seqs:\n",
    "        seq = ['<s>'] + list(seq) + ['</s>']\n",
    "        tensors += [torch.LongTensor(\n",
    "            [token2idx.get(x, 1) for x in seq])]  # <unk> -> 1\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a895ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensors2seqs(tensors, idx2token):\n",
    "    seqs = []\n",
    "    for tensor in tensors:\n",
    "        seqs += [[idx2token.get(x.item(), '<unk>') for x in tensor]]\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47f67ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src_seq, max_len):\n",
    "    src_embs = model.embedding(src_seq)\n",
    "    memory = model.transformer.encoder(src_embs)\n",
    "    tgt_seq = torch.LongTensor([token2idx['<s>']]).to(DEVICE)\n",
    "    tgt_embs = model.embedding(tgt_seq)\n",
    "    max_len = min(max_len, MAX_LEN)\n",
    "\n",
    "    for _ in range(max_len-1):\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(\n",
    "            tgt_embs.size(dim=0), device=DEVICE)\n",
    "        tgt_output = model.transformer.decoder(tgt_embs,\n",
    "                                               memory,\n",
    "                                               tgt_mask=tgt_mask)\n",
    "        char_prob = model.fc(tgt_output[-1])\n",
    "        next_char = torch.argmax(char_prob)\n",
    "        tgt_seq = torch.cat(\n",
    "            (tgt_seq,\n",
    "             torch.unsqueeze(next_char, dim=0)), dim=0)\n",
    "        tgt_embs = model.embedding(tgt_seq)\n",
    "        if next_char.item() == token2idx['</s>']:\n",
    "            break\n",
    "    return tgt_seq[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a602ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_batched(model, src_seq, max_len):\n",
    "    # Added a batched version\n",
    "    src_seq = src_seq.unsqueeze(0) if src_seq.dim() == 1 else src_seq\n",
    "    src_embs = model.embedding(src_seq)\n",
    "    memory = model.transformer.encoder(src_embs)\n",
    "    tgt_seq = torch.LongTensor([[token2idx['<s>']]]).to(DEVICE)\n",
    "    tgt_embs = model.embedding(tgt_seq)\n",
    "    max_len = min(max_len, MAX_LEN)\n",
    "\n",
    "    for _ in range(max_len - 1):\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(\n",
    "            tgt_embs.size(dim=1), device=DEVICE)\n",
    "        tgt_output = model.transformer.decoder(\n",
    "            tgt_embs, memory, tgt_mask=tgt_mask)\n",
    "        char_prob = model.fc(tgt_output[:, -1, :])\n",
    "        next_char = torch.argmax(char_prob, dim=-1).unsqueeze(-1)\n",
    "        tgt_seq = torch.cat((tgt_seq, next_char), dim=1)\n",
    "        tgt_embs = model.embedding(tgt_seq)\n",
    "        if next_char.item() == token2idx['</s>']:\n",
    "            break\n",
    "    return tgt_seq[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37bd6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(src_sentence, model=model):\n",
    "    src = seqs2tensors([src_sentence.strip()], token2idx)[0].to(DEVICE)\n",
    "    num_chars = src.size(dim=0)\n",
    "    tgt_chars = greedy_decode_batched(model, src, max_len=num_chars + 20)\n",
    "    tgt_chars = tensors2seqs([tgt_chars], idx2token)[0]\n",
    "    if tgt_chars[-1] == '</s>':\n",
    "        tgt_chars = tgt_chars[:-1]\n",
    "    tgt_str = ''.join(tgt_chars)\n",
    "    return tgt_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cdaf6d",
   "metadata": {},
   "source": [
    "## Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "187f7f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(title=\"Pico Translator\") as demo:\n",
    "    gr.Markdown(\"# Pico Translator\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            src_sentence = gr.Textbox(\n",
    "                label=\"Source text in French\", placeholder=\"Write your text...\")\n",
    "        with gr.Column():\n",
    "            tgt_sentence = gr.Textbox(\n",
    "                label=\"English translation\", placeholder=\"Translation will show here...\")\n",
    "    btn = gr.Button(\"Translate!\")\n",
    "    btn.click(fn=translate, inputs=[src_sentence], outputs=[tgt_sentence])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed5f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
