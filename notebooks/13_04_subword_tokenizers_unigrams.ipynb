{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: Subword Segmentation\n",
    "Tokenizers using the unigram language model from Taku (2018): https://arxiv.org/pdf/1804.10959.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programs from the book: [_Python for Natural Language Processing_](https://link.springer.com/book/9783031575488)\n",
    "\n",
    "__Author__: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "from math import log\n",
    "from tqdm import tqdm\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the files and we store the corpus in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = 'HOMER'  # 'DICKENS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORPUS == 'DICKENS':\n",
    "    folder = PATH + 'dickens/'\n",
    "elif CORPUS == 'HOMER':\n",
    "    folder = PATH + 'classics/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir, suffix):\n",
    "    \"\"\"\n",
    "    Returns all the files in a folder ending with suffix\n",
    "    :param dir:\n",
    "    :param suffix:\n",
    "    :return: the list of file names\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(suffix):\n",
    "            files.append(file)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iliad.txt', 'odyssey.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CORPUS == 'DICKENS':\n",
    "    files = get_files(folder, 'txt')\n",
    "elif CORPUS == 'HOMER':\n",
    "    files = ['iliad.txt', 'odyssey.txt']\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../datasets/classics/iliad.txt', '../datasets/classics/odyssey.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [folder + file for file in files]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for file in files:\n",
    "    with open(file, encoding='utf8') as f:\n",
    "        text += ' ' + f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' BOOK I\\n\\nSing, O goddess, the anger of Achilles son of Peleus, that brought\\ncountless ills upon the '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretokenization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pretokenize the text using the spaces as delimiters.\n",
    "In BERT, simply `split()`: https://github.com/google-research/bert/blob/master/tokenization.py#L300-L359. Here we use a regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\p{P}|[^\\s\\p{P}]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [(match.group(), (match.start(), match.end()))\n",
    "         for match in re.finditer(pattern, text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOOK', 'I', 'Sing,', 'O', 'goddess,', 'the', 'anger', 'of']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BOOK', (1, 5)),\n",
       " ('I', (6, 7)),\n",
       " ('Sing', (9, 13)),\n",
       " (',', (13, 14)),\n",
       " ('O', (15, 16)),\n",
       " ('goddess', (17, 24)),\n",
       " (',', (24, 25)),\n",
       " ('the', (26, 29))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretokenize(pattern, text):\n",
    "    return re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pretokenize(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cnts = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19920), ('the', 15258), ('and', 11467), ('of', 8640), ('.', 8108)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cnts.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cnts['her']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPE():\n",
    "    def __init__(self, merge_cnt=200):\n",
    "        self.merge_cnt = merge_cnt\n",
    "        self.pattern = r'\\p{P}|[^\\s\\p{P}]+'\n",
    "\n",
    "    def pretokenize(self, text):\n",
    "        words = re.findall(self.pattern, text)\n",
    "        words = list(map(lambda x: '▁' + x, words))\n",
    "        return words\n",
    "\n",
    "    def _bpe_init(self, text):\n",
    "        words = self.pretokenize(text)\n",
    "        word_cnts = Counter(words)\n",
    "        self.words_bpe = {\n",
    "            word: {'freq': freq,\n",
    "                   'swords': list(word)}\n",
    "            for word, freq in word_cnts.items()}\n",
    "        self.vocab = list(\n",
    "            set([char for word in self.words_bpe\n",
    "                for char in self.words_bpe[word]['swords']]))\n",
    "\n",
    "    def _count_bigrams(self):\n",
    "        self.pair_cnts = Counter()\n",
    "        for word_dict in self.words_bpe.values():\n",
    "            swords = tuple(word_dict['swords'])\n",
    "            freq = word_dict['freq']\n",
    "            for i in range(len(swords) - 1):\n",
    "                self.pair_cnts[swords[i:i + 2]] += freq\n",
    "\n",
    "    def _merge_pair(self, pair, swords):\n",
    "        pair_str = ''.join(pair)\n",
    "        i = 0\n",
    "        temp = []\n",
    "        while i < len(swords) - 1:\n",
    "            if pair == swords[i:i + 2]:\n",
    "                temp += [pair_str]\n",
    "                i += 2\n",
    "            else:\n",
    "                temp += [swords[i]]\n",
    "                i += 1\n",
    "        if i == len(swords) - 1:\n",
    "            temp += [swords[i]]\n",
    "        swords = temp\n",
    "        return swords\n",
    "\n",
    "    def fit(self, text):\n",
    "        self._bpe_init(text)\n",
    "\n",
    "        self.merge_ops = []\n",
    "        for _ in range(self.merge_cnt):\n",
    "            self._count_bigrams()\n",
    "            self.best_pair = max(self.pair_cnts,\n",
    "                                 key=self.pair_cnts.get)\n",
    "            merge_op = list(self.best_pair)\n",
    "            self.merge_ops.append(merge_op)\n",
    "            for word_dict in self.words_bpe.values():\n",
    "                word_dict['swords'] = self._merge_pair(\n",
    "                    merge_op,\n",
    "                    word_dict['swords'])\n",
    "        self._build_vocab()\n",
    "\n",
    "    def _build_vocab(self):\n",
    "        swords = list(map(lambda x: ''.join(x), self.merge_ops))\n",
    "        self.vocab += swords\n",
    "\n",
    "    def encode(self, word):\n",
    "        swords = list(word)\n",
    "        for op in self.merge_ops:\n",
    "            swords = self._merge_pair(op, swords)\n",
    "        return swords\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        tokenized_text = []\n",
    "        cache = {}\n",
    "        words = self.pretokenize(text)\n",
    "        for word in words:\n",
    "            if word not in cache:\n",
    "                cache[word] = self.encode(word)\n",
    "            subwords = cache[word]\n",
    "            tokenized_text += subwords\n",
    "        return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = BPE()\n",
    "bpe.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'▁BOOK': {'freq': 48, 'swords': ['▁', 'B', 'O', 'O', 'K']},\n",
       " '▁I': {'freq': 3194, 'swords': ['▁I']},\n",
       " '▁Sing': {'freq': 2, 'swords': ['▁S', 'ing']},\n",
       " '▁,': {'freq': 19920, 'swords': ['▁,']},\n",
       " '▁O': {'freq': 77, 'swords': ['▁', 'O']},\n",
       " '▁goddess': {'freq': 112, 'swords': ['▁go', 'd', 'd', 'es', 's']},\n",
       " '▁the': {'freq': 15258, 'swords': ['▁the']},\n",
       " '▁anger': {'freq': 74, 'swords': ['▁an', 'g', 'er']},\n",
       " '▁of': {'freq': 8640, 'swords': ['▁of']},\n",
       " '▁Achilles': {'freq': 440, 'swords': ['▁Ach', 'ill', 'es']},\n",
       " '▁son': {'freq': 1246, 'swords': ['▁son']},\n",
       " '▁Peleus': {'freq': 145, 'swords': ['▁P', 'e', 'le', 'us']},\n",
       " '▁that': {'freq': 2558, 'swords': ['▁that']},\n",
       " '▁brought': {'freq': 208, 'swords': ['▁br', 'ou', 'ght']},\n",
       " '▁countless': {'freq': 8, 'swords': ['▁c', 'ou', 'n', 't', 'l', 'es', 's']},\n",
       " '▁ills': {'freq': 5, 'swords': ['▁', 'ill', 's']},\n",
       " '▁upon': {'freq': 792, 'swords': ['▁up', 'on']},\n",
       " '▁Achaeans': {'freq': 601, 'swords': ['▁Ach', 'ae', 'ans']},\n",
       " '▁.': {'freq': 8108, 'swords': ['▁.']},\n",
       " '▁Many': {'freq': 26, 'swords': ['▁M', 'an', 'y']},\n",
       " '▁a': {'freq': 3575, 'swords': ['▁a']},\n",
       " '▁brave': {'freq': 157, 'swords': ['▁br', 'a', 've']},\n",
       " '▁soul': {'freq': 30, 'swords': ['▁s', 'ou', 'l']},\n",
       " '▁did': {'freq': 748, 'swords': ['▁d', 'id']},\n",
       " '▁it': {'freq': 2109, 'swords': ['▁it']},\n",
       " '▁send': {'freq': 103, 'swords': ['▁se', 'nd']},\n",
       " '▁hurrying': {'freq': 10, 'swords': ['▁h', 'ur', 'r', 'y', 'ing']},\n",
       " '▁down': {'freq': 454, 'swords': ['▁d', 'ow', 'n']},\n",
       " '▁to': {'freq': 6492, 'swords': ['▁to']},\n",
       " '▁Hades': {'freq': 77, 'swords': ['▁H', 'ad', 'es']},\n",
       " '▁and': {'freq': 11467, 'swords': ['▁and']},\n",
       " '▁many': {'freq': 310, 'swords': ['▁man', 'y']},\n",
       " '▁hero': {'freq': 53, 'swords': ['▁he', 'ro']},\n",
       " '▁yield': {'freq': 18, 'swords': ['▁y', 'ie', 'ld']},\n",
       " '▁prey': {'freq': 11, 'swords': ['▁p', 're', 'y']},\n",
       " '▁dogs': {'freq': 56, 'swords': ['▁do', 'g', 's']},\n",
       " '▁vultures': {'freq': 21,\n",
       "  'swords': ['▁', 'v', 'u', 'l', 't', 'u', 're', 's']},\n",
       " '▁for': {'freq': 2653, 'swords': ['▁for']},\n",
       " '▁so': {'freq': 1316, 'swords': ['▁so']},\n",
       " '▁were': {'freq': 1151, 'swords': ['▁were']},\n",
       " '▁counsels': {'freq': 22, 'swords': ['▁c', 'ou', 'n', 'sel', 's']},\n",
       " '▁Jove': {'freq': 653, 'swords': ['▁', 'J', 'ove']},\n",
       " '▁fulfilled': {'freq': 9, 'swords': ['▁f', 'u', 'l', 'f', 'ill', 'ed']},\n",
       " '▁from': {'freq': 1522, 'swords': ['▁from']},\n",
       " '▁day': {'freq': 242, 'swords': ['▁d', 'ay']},\n",
       " '▁on': {'freq': 1811, 'swords': ['▁on']},\n",
       " '▁which': {'freq': 669, 'swords': ['▁whi', 'ch']},\n",
       " '▁Atreus': {'freq': 151, 'swords': ['▁A', 't', 're', 'us']},\n",
       " '▁king': {'freq': 129, 'swords': ['▁k', 'ing']},\n",
       " '▁men': {'freq': 689, 'swords': ['▁m', 'en']},\n",
       " '▁great': {'freq': 459, 'swords': ['▁g', 're', 'at']},\n",
       " '▁first': {'freq': 230, 'swords': ['▁f', 'ir', 'st']},\n",
       " '▁fell': {'freq': 252, 'swords': ['▁f', 'ell']},\n",
       " '▁out': {'freq': 689, 'swords': ['▁o', 'ut']},\n",
       " '▁with': {'freq': 2710, 'swords': ['▁with']},\n",
       " '▁one': {'freq': 975, 'swords': ['▁one']},\n",
       " '▁another': {'freq': 282, 'swords': ['▁an', 'ot', 'her']},\n",
       " '▁And': {'freq': 195, 'swords': ['▁A', 'nd']},\n",
       " '▁gods': {'freq': 417, 'swords': ['▁go', 'd', 's']},\n",
       " '▁was': {'freq': 2158, 'swords': ['▁was']},\n",
       " '▁set': {'freq': 330, 'swords': ['▁s', 'et']},\n",
       " '▁them': {'freq': 1811, 'swords': ['▁them']},\n",
       " '▁quarrel': {'freq': 26, 'swords': ['▁', 'q', 'u', 'ar', 're', 'l']},\n",
       " '▁?': {'freq': 570, 'swords': ['▁', '?']},\n",
       " '▁It': {'freq': 159, 'swords': ['▁I', 't']},\n",
       " '▁Leto': {'freq': 15, 'swords': ['▁', 'L', 'et', 'o']},\n",
       " '▁;': {'freq': 2510, 'swords': ['▁;']},\n",
       " '▁he': {'freq': 4189, 'swords': ['▁he']},\n",
       " '▁angry': {'freq': 114, 'swords': ['▁an', 'g', 'r', 'y']},\n",
       " '▁sent': {'freq': 176, 'swords': ['▁s', 'ent']},\n",
       " '▁pestilence': {'freq': 5, 'swords': ['▁p', 'est', 'il', 'en', 'ce']},\n",
       " '▁host': {'freq': 114, 'swords': ['▁h', 'o', 'st']},\n",
       " '▁plague': {'freq': 6, 'swords': ['▁p', 'l', 'a', 'g', 'u', 'e']},\n",
       " '▁people': {'freq': 340, 'swords': ['▁p', 'e', 'o', 'p', 'le']},\n",
       " '▁because': {'freq': 71, 'swords': ['▁be', 'c', 'a', 'us', 'e']},\n",
       " '▁had': {'freq': 1725, 'swords': ['▁had']},\n",
       " '▁dishonoured': {'freq': 6, 'swords': ['▁d', 'is', 'h', 'on', 'ou', 'red']},\n",
       " '▁Chryses': {'freq': 7, 'swords': ['▁', 'C', 'h', 'r', 'y', 'ses']},\n",
       " '▁his': {'freq': 3749, 'swords': ['▁his']},\n",
       " '▁priest': {'freq': 14, 'swords': ['▁p', 'ri', 'est']},\n",
       " '▁Now': {'freq': 122, 'swords': ['▁', 'N', 'ow']},\n",
       " '▁come': {'freq': 518, 'swords': ['▁c', 'ome']},\n",
       " '▁ships': {'freq': 519, 'swords': ['▁ship', 's']},\n",
       " '▁free': {'freq': 30, 'swords': ['▁f', 're', 'e']},\n",
       " '▁daughter': {'freq': 165, 'swords': ['▁d', 'a', 'u', 'ght', 'er']},\n",
       " '▁him': {'freq': 2926, 'swords': ['▁him']},\n",
       " '▁ransom': {'freq': 38, 'swords': ['▁r', 'ans', 'om']},\n",
       " '▁:': {'freq': 254, 'swords': ['▁', ':']},\n",
       " '▁moreover': {'freq': 59, 'swords': ['▁m', 'ore', 'o', 'ver']},\n",
       " '▁bore': {'freq': 92, 'swords': ['▁b', 'ore']},\n",
       " '▁in': {'freq': 3791, 'swords': ['▁in']},\n",
       " '▁hand': {'freq': 378, 'swords': ['▁ha', 'nd']},\n",
       " '▁sceptre': {'freq': 21, 'swords': ['▁s', 'ce', 'p', 't', 're']},\n",
       " '▁Apollo': {'freq': 170, 'swords': ['▁A', 'p', 'o', 'll', 'o']},\n",
       " '▁wreathed': {'freq': 3, 'swords': ['▁w', 're', 'at', 'he', 'd']},\n",
       " '▁suppliant': {'freq': 16, 'swords': ['▁su', 'p', 'p', 'l', 'i', 'an', 't']},\n",
       " \"▁'\": {'freq': 1145, 'swords': [\"▁'\"]},\n",
       " '▁s': {'freq': 616, 'swords': ['▁s']},\n",
       " '▁wreath': {'freq': 3, 'swords': ['▁w', 're', 'at', 'h']},\n",
       " '▁besought': {'freq': 20, 'swords': ['▁b', 'es', 'ou', 'ght']},\n",
       " '▁but': {'freq': 1601, 'swords': ['▁but']},\n",
       " '▁most': {'freq': 137, 'swords': ['▁m', 'o', 'st']},\n",
       " '▁all': {'freq': 1601, 'swords': ['▁all']},\n",
       " '▁two': {'freq': 400, 'swords': ['▁t', 'w', 'o']},\n",
       " '▁sons': {'freq': 196, 'swords': ['▁son', 's']},\n",
       " '▁who': {'freq': 1247, 'swords': ['▁who']},\n",
       " '▁their': {'freq': 1328, 'swords': ['▁their']},\n",
       " '▁chiefs': {'freq': 20, 'swords': ['▁ch', 'ie', 'f', 's']},\n",
       " '▁\"': {'freq': 3574, 'swords': ['▁\"']},\n",
       " '▁Sons': {'freq': 4, 'swords': ['▁S', 'on', 's']},\n",
       " '▁cried': {'freq': 100, 'swords': ['▁c', 'ri', 'ed']},\n",
       " '▁other': {'freq': 443, 'swords': ['▁o', 'ther']},\n",
       " '▁may': {'freq': 533, 'swords': ['▁m', 'ay']},\n",
       " '▁dwell': {'freq': 35, 'swords': ['▁d', 'w', 'ell']},\n",
       " '▁Olympus': {'freq': 99, 'swords': ['▁', 'O', 'ly', 'm', 'p', 'us']},\n",
       " '▁grant': {'freq': 45, 'swords': ['▁g', 'r', 'an', 't']},\n",
       " '▁you': {'freq': 3521, 'swords': ['▁you']},\n",
       " '▁sack': {'freq': 27, 'swords': ['▁sa', 'ck']},\n",
       " '▁city': {'freq': 291, 'swords': ['▁c', 'it', 'y']},\n",
       " '▁Priam': {'freq': 192, 'swords': ['▁P', 'ri', 'am']},\n",
       " '▁reach': {'freq': 64, 'swords': ['▁re', 'a', 'ch']},\n",
       " '▁your': {'freq': 1210, 'swords': ['▁your']},\n",
       " '▁homes': {'freq': 7, 'swords': ['▁h', 'om', 'es']},\n",
       " '▁safety': {'freq': 11, 'swords': ['▁sa', 'f', 'et', 'y']},\n",
       " '▁my': {'freq': 1393, 'swords': ['▁my']},\n",
       " '▁accept': {'freq': 15, 'swords': ['▁a', 'c', 'ce', 'p', 't']},\n",
       " '▁her': {'freq': 1145, 'swords': ['▁her']},\n",
       " '▁reverence': {'freq': 3, 'swords': ['▁re', 've', 're', 'n', 'ce']},\n",
       " '▁On': {'freq': 130, 'swords': ['▁', 'O', 'n']},\n",
       " '▁this': {'freq': 942, 'swords': ['▁this']},\n",
       " '▁rest': {'freq': 89, 'swords': ['▁re', 'st']},\n",
       " '▁voice': {'freq': 67, 'swords': ['▁', 'v', 'o', 'i', 'ce']},\n",
       " '▁respecting': {'freq': 2, 'swords': ['▁re', 's', 'p', 'e', 'ct', 'ing']},\n",
       " '▁taking': {'freq': 60, 'swords': ['▁t', 'a', 'k', 'ing']},\n",
       " '▁offered': {'freq': 52, 'swords': ['▁of', 'f', 'e', 'red']},\n",
       " '▁not': {'freq': 1572, 'swords': ['▁not']},\n",
       " '▁Agamemnon': {'freq': 231, 'swords': ['▁A', 'g', 'ame', 'm', 'n', 'on']},\n",
       " '▁spoke': {'freq': 254, 'swords': ['▁sp', 'o', 'ke']},\n",
       " '▁fiercely': {'freq': 31, 'swords': ['▁f', 'i', 'er', 'ce', 'ly']},\n",
       " '▁roughly': {'freq': 4, 'swords': ['▁r', 'ough', 'ly']},\n",
       " '▁away': {'freq': 270, 'swords': ['▁a', 'w', 'ay']},\n",
       " '▁Old': {'freq': 13, 'swords': ['▁', 'O', 'ld']},\n",
       " '▁man': {'freq': 769, 'swords': ['▁man']},\n",
       " '▁said': {'freq': 888, 'swords': ['▁said']},\n",
       " '▁let': {'freq': 441, 'swords': ['▁le', 't']},\n",
       " '▁me': {'freq': 1620, 'swords': ['▁me']},\n",
       " '▁find': {'freq': 149, 'swords': ['▁f', 'ind']},\n",
       " '▁tarrying': {'freq': 2, 'swords': ['▁t', 'ar', 'r', 'y', 'ing']},\n",
       " '▁about': {'freq': 706, 'swords': ['▁ab', 'out']},\n",
       " '▁our': {'freq': 431, 'swords': ['▁o', 'ur']},\n",
       " '▁nor': {'freq': 342, 'swords': ['▁n', 'or']},\n",
       " '▁yet': {'freq': 257, 'swords': ['▁y', 'et']},\n",
       " '▁coming': {'freq': 105, 'swords': ['▁c', 'om', 'ing']},\n",
       " '▁hereafter': {'freq': 34, 'swords': ['▁he', 're', 'a', 'f', 'ter']},\n",
       " '▁Your': {'freq': 24, 'swords': ['▁', 'Y', 'our']},\n",
       " '▁god': {'freq': 211, 'swords': ['▁go', 'd']},\n",
       " '▁shall': {'freq': 564, 'swords': ['▁sh', 'all']},\n",
       " '▁profit': {'freq': 3, 'swords': ['▁p', 'ro', 'f', 'it']},\n",
       " '▁nothing': {'freq': 153, 'swords': ['▁not', 'h', 'ing']},\n",
       " '▁will': {'freq': 1496, 'swords': ['▁will']},\n",
       " '▁She': {'freq': 140, 'swords': ['▁S', 'he']},\n",
       " '▁grow': {'freq': 22, 'swords': ['▁g', 'r', 'ow']},\n",
       " '▁old': {'freq': 249, 'swords': ['▁o', 'ld']},\n",
       " '▁house': {'freq': 539, 'swords': ['▁h', 'ou', 'se']},\n",
       " '▁at': {'freq': 1168, 'swords': ['▁at']},\n",
       " '▁Argos': {'freq': 50, 'swords': ['▁A', 'r', 'g', 'o', 's']},\n",
       " '▁far': {'freq': 194, 'swords': ['▁f', 'ar']},\n",
       " '▁own': {'freq': 544, 'swords': ['▁o', 'w', 'n']},\n",
       " '▁home': {'freq': 316, 'swords': ['▁h', 'ome']},\n",
       " '▁busying': {'freq': 1, 'swords': ['▁b', 'us', 'y', 'ing']},\n",
       " '▁herself': {'freq': 57, 'swords': ['▁her', 'sel', 'f']},\n",
       " '▁loom': {'freq': 12, 'swords': ['▁l', 'o', 'om']},\n",
       " '▁visiting': {'freq': 2, 'swords': ['▁', 'v', 'is', 'it', 'ing']},\n",
       " '▁couch': {'freq': 19, 'swords': ['▁c', 'ou', 'ch']},\n",
       " '▁go': {'freq': 514, 'swords': ['▁go']},\n",
       " '▁do': {'freq': 630, 'swords': ['▁do']},\n",
       " '▁provoke': {'freq': 6, 'swords': ['▁p', 'ro', 'v', 'o', 'ke']},\n",
       " '▁or': {'freq': 759, 'swords': ['▁or']},\n",
       " '▁be': {'freq': 1096, 'swords': ['▁be']},\n",
       " '▁worse': {'freq': 31, 'swords': ['▁w', 'or', 'se']},\n",
       " '▁The': {'freq': 534, 'swords': ['▁The']},\n",
       " '▁feared': {'freq': 19, 'swords': ['▁f', 'e', 'a', 'red']},\n",
       " '▁obeyed': {'freq': 15, 'swords': ['▁o', 'b', 'e', 'y', 'ed']},\n",
       " '▁Not': {'freq': 14, 'swords': ['▁', 'N', 'ot']},\n",
       " '▁word': {'freq': 56, 'swords': ['▁w', 'or', 'd']},\n",
       " '▁went': {'freq': 628, 'swords': ['▁w', 'ent']},\n",
       " '▁by': {'freq': 1196, 'swords': ['▁by']},\n",
       " '▁shore': {'freq': 66, 'swords': ['▁sh', 'ore']},\n",
       " '▁sounding': {'freq': 8, 'swords': ['▁s', 'ound', 'ing']},\n",
       " '▁sea': {'freq': 341, 'swords': ['▁se', 'a']},\n",
       " '▁prayed': {'freq': 63, 'swords': ['▁p', 'r', 'ay', 'ed']},\n",
       " '▁apart': {'freq': 21, 'swords': ['▁a', 'p', 'ar', 't']},\n",
       " '▁King': {'freq': 134, 'swords': ['▁', 'K', 'ing']},\n",
       " '▁whom': {'freq': 245, 'swords': ['▁wh', 'om']},\n",
       " '▁lovely': {'freq': 37, 'swords': ['▁l', 'ove', 'ly']},\n",
       " '▁borne': {'freq': 32, 'swords': ['▁b', 'or', 'n', 'e']},\n",
       " '▁Hear': {'freq': 29, 'swords': ['▁H', 'ear']},\n",
       " '▁silver': {'freq': 79, 'swords': ['▁s', 'il', 'ver']},\n",
       " '▁bow': {'freq': 128, 'swords': ['▁b', 'ow']},\n",
       " '▁protectest': {'freq': 2, 'swords': ['▁p', 'r', 'ot', 'e', 'ct', 'est']},\n",
       " '▁Chryse': {'freq': 5, 'swords': ['▁', 'C', 'h', 'r', 'y', 'se']},\n",
       " '▁holy': {'freq': 14, 'swords': ['▁h', 'o', 'ly']},\n",
       " '▁Cilla': {'freq': 2, 'swords': ['▁', 'C', 'ill', 'a']},\n",
       " '▁rulest': {'freq': 6, 'swords': ['▁r', 'u', 'l', 'est']},\n",
       " '▁Tenedos': {'freq': 5, 'swords': ['▁T', 'en', 'ed', 'o', 's']},\n",
       " '▁thy': {'freq': 5, 'swords': ['▁th', 'y']},\n",
       " '▁might': {'freq': 258, 'swords': ['▁m', 'ight']},\n",
       " '▁hear': {'freq': 103, 'swords': ['▁he', 'ar']},\n",
       " '▁oh': {'freq': 2, 'swords': ['▁o', 'h']},\n",
       " '▁thou': {'freq': 6, 'swords': ['▁th', 'ou']},\n",
       " '▁Sminthe': {'freq': 1, 'swords': ['▁S', 'm', 'in', 't', 'he']},\n",
       " '▁If': {'freq': 150, 'swords': ['▁I', 'f']},\n",
       " '▁have': {'freq': 1504, 'swords': ['▁have']},\n",
       " '▁ever': {'freq': 199, 'swords': ['▁e', 'ver']},\n",
       " '▁decked': {'freq': 2, 'swords': ['▁de', 'ck', 'ed']},\n",
       " '▁temple': {'freq': 19, 'swords': ['▁t', 'e', 'm', 'p', 'le']},\n",
       " '▁garlands': {'freq': 2, 'swords': ['▁g', 'ar', 'l', 'and', 's']},\n",
       " '▁burned': {'freq': 20, 'swords': ['▁b', 'ur', 'n', 'ed']},\n",
       " '▁thigh': {'freq': 37, 'swords': ['▁th', 'i', 'gh']},\n",
       " '▁-': {'freq': 5180, 'swords': ['▁-']},\n",
       " '▁bones': {'freq': 47, 'swords': ['▁b', 'on', 'es']},\n",
       " '▁fat': {'freq': 43, 'swords': ['▁f', 'at']},\n",
       " '▁bulls': {'freq': 9, 'swords': ['▁b', 'u', 'll', 's']},\n",
       " '▁goats': {'freq': 43, 'swords': ['▁go', 'at', 's']},\n",
       " '▁prayer': {'freq': 44, 'swords': ['▁p', 'r', 'ay', 'er']},\n",
       " '▁arrows': {'freq': 44, 'swords': ['▁a', 'r', 'r', 'ow', 's']},\n",
       " '▁avenge': {'freq': 24, 'swords': ['▁a', 'ven', 'g', 'e']},\n",
       " '▁these': {'freq': 296, 'swords': ['▁the', 'se']},\n",
       " '▁tears': {'freq': 62, 'swords': ['▁t', 'ear', 's']},\n",
       " '▁Danaans': {'freq': 121, 'swords': ['▁', 'D', 'an', 'a', 'ans']},\n",
       " '▁Thus': {'freq': 238, 'swords': ['▁T', 'h', 'us']},\n",
       " '▁pray': {'freq': 49, 'swords': ['▁p', 'r', 'ay']},\n",
       " '▁heard': {'freq': 181, 'swords': ['▁he', 'ard']},\n",
       " '▁He': {'freq': 539, 'swords': ['▁He']},\n",
       " '▁came': {'freq': 481, 'swords': ['▁c', 'ame']},\n",
       " '▁furious': {'freq': 37, 'swords': ['▁f', 'ur', 'i', 'ou', 's']},\n",
       " '▁summits': {'freq': 13, 'swords': ['▁su', 'm', 'm', 'it', 's']},\n",
       " '▁quiver': {'freq': 13, 'swords': ['▁', 'q', 'u', 'i', 'ver']},\n",
       " '▁shoulder': {'freq': 53, 'swords': ['▁sh', 'ould', 'er']},\n",
       " '▁rattled': {'freq': 2, 'swords': ['▁r', 'at', 't', 'l', 'ed']},\n",
       " '▁back': {'freq': 470, 'swords': ['▁b', 'a', 'ck']},\n",
       " '▁rage': {'freq': 39, 'swords': ['▁r', 'a', 'g', 'e']},\n",
       " '▁trembled': {'freq': 9, 'swords': ['▁t', 're', 'm', 'b', 'l', 'ed']},\n",
       " '▁within': {'freq': 106, 'swords': ['▁with', 'in']},\n",
       " '▁sat': {'freq': 112, 'swords': ['▁s', 'at']},\n",
       " '▁himself': {'freq': 241, 'swords': ['▁him', 'sel', 'f']},\n",
       " '▁face': {'freq': 118, 'swords': ['▁f', 'a', 'ce']},\n",
       " '▁as': {'freq': 2247, 'swords': ['▁as']},\n",
       " '▁dark': {'freq': 71, 'swords': ['▁d', 'ar', 'k']},\n",
       " '▁night': {'freq': 143, 'swords': ['▁n', 'ight']},\n",
       " '▁rang': {'freq': 37, 'swords': ['▁r', 'an', 'g']},\n",
       " '▁death': {'freq': 175, 'swords': ['▁de', 'at', 'h']},\n",
       " '▁shot': {'freq': 14, 'swords': ['▁sh', 'ot']},\n",
       " '▁arrow': {'freq': 93, 'swords': ['▁a', 'r', 'r', 'ow']},\n",
       " '▁midst': {'freq': 24, 'swords': ['▁m', 'id', 'st']},\n",
       " '▁First': {'freq': 46, 'swords': ['▁', 'F', 'ir', 'st']},\n",
       " '▁smote': {'freq': 30, 'swords': ['▁s', 'm', 'ot', 'e']},\n",
       " '▁mules': {'freq': 35, 'swords': ['▁m', 'u', 'l', 'es']},\n",
       " '▁hounds': {'freq': 31, 'swords': ['▁h', 'ound', 's']},\n",
       " '▁presently': {'freq': 58, 'swords': ['▁p', 're', 's', 'ent', 'ly']},\n",
       " '▁aimed': {'freq': 36, 'swords': ['▁a', 'im', 'ed']},\n",
       " '▁shafts': {'freq': 5, 'swords': ['▁sh', 'a', 'f', 't', 's']},\n",
       " '▁themselves': {'freq': 120, 'swords': ['▁them', 'sel', 've', 's']},\n",
       " '▁long': {'freq': 271, 'swords': ['▁l', 'ong']},\n",
       " '▁pyres': {'freq': 1, 'swords': ['▁p', 'y', 're', 's']},\n",
       " '▁dead': {'freq': 178, 'swords': ['▁de', 'ad']},\n",
       " '▁burning': {'freq': 29, 'swords': ['▁b', 'ur', 'n', 'ing']},\n",
       " '▁For': {'freq': 60, 'swords': ['▁', 'F', 'or']},\n",
       " '▁nine': {'freq': 38, 'swords': ['▁n', 'in', 'e']},\n",
       " '▁whole': {'freq': 124, 'swords': ['▁who', 'le']},\n",
       " '▁days': {'freq': 71, 'swords': ['▁d', 'ay', 's']},\n",
       " '▁among': {'freq': 426, 'swords': ['▁am', 'ong']},\n",
       " '▁tenth': {'freq': 15, 'swords': ['▁t', 'ent', 'h']},\n",
       " '▁called': {'freq': 95, 'swords': ['▁c', 'all', 'ed']},\n",
       " '▁assembly': {'freq': 47, 'swords': ['▁as', 'se', 'm', 'b', 'ly']},\n",
       " '▁moved': {'freq': 21, 'swords': ['▁m', 'ove', 'd']},\n",
       " '▁thereto': {'freq': 2, 'swords': ['▁there', 't', 'o']},\n",
       " '▁Juno': {'freq': 125, 'swords': ['▁', 'J', 'un', 'o']},\n",
       " '▁saw': {'freq': 266, 'swords': ['▁sa', 'w']},\n",
       " '▁throes': {'freq': 2, 'swords': ['▁th', 'ro', 'es']},\n",
       " '▁compassion': {'freq': 12,\n",
       "  'swords': ['▁c', 'om', 'p', 'as', 's', 'i', 'on']},\n",
       " '▁Then': {'freq': 478, 'swords': ['▁T', 'hen']},\n",
       " '▁when': {'freq': 1031, 'swords': ['▁when']},\n",
       " '▁they': {'freq': 1830, 'swords': ['▁they']},\n",
       " '▁got': {'freq': 224, 'swords': ['▁g', 'ot']},\n",
       " '▁together': {'freq': 91, 'swords': ['▁to', 'g', 'et', 'her']},\n",
       " '▁rose': {'freq': 77, 'swords': ['▁r', 'o', 'se']},\n",
       " '▁Son': {'freq': 44, 'swords': ['▁S', 'on']},\n",
       " '▁deem': {'freq': 6, 'swords': ['▁de', 'e', 'm']},\n",
       " '▁we': {'freq': 785, 'swords': ['▁we']},\n",
       " '▁should': {'freq': 424, 'swords': ['▁sh', 'ould']},\n",
       " '▁now': {'freq': 645, 'swords': ['▁n', 'ow']},\n",
       " '▁turn': {'freq': 97, 'swords': ['▁t', 'ur', 'n']},\n",
       " '▁roving': {'freq': 2, 'swords': ['▁r', 'o', 'v', 'ing']},\n",
       " '▁if': {'freq': 506, 'swords': ['▁', 'if']},\n",
       " '▁would': {'freq': 697, 'swords': ['▁w', 'ould']},\n",
       " '▁escape': {'freq': 55, 'swords': ['▁', 'es', 'c', 'a', 'p', 'e']},\n",
       " '▁destruction': {'freq': 52,\n",
       "  'swords': ['▁d', 'est', 'r', 'u', 'ct', 'i', 'on']},\n",
       " '▁are': {'freq': 1093, 'swords': ['▁are']},\n",
       " '▁being': {'freq': 146, 'swords': ['▁be', 'ing']},\n",
       " '▁cut': {'freq': 97, 'swords': ['▁c', 'ut']},\n",
       " '▁war': {'freq': 89, 'swords': ['▁w', 'ar']},\n",
       " '▁once': {'freq': 229, 'swords': ['▁on', 'ce']},\n",
       " '▁Let': {'freq': 95, 'swords': ['▁', 'L', 'et']},\n",
       " '▁us': {'freq': 610, 'swords': ['▁', 'us']},\n",
       " '▁ask': {'freq': 66, 'swords': ['▁as', 'k']},\n",
       " '▁some': {'freq': 482, 'swords': ['▁s', 'ome']},\n",
       " '▁prophet': {'freq': 13, 'swords': ['▁p', 'ro', 'p', 'he', 't']},\n",
       " '▁reader': {'freq': 3, 'swords': ['▁re', 'ad', 'er']},\n",
       " '▁dreams': {'freq': 9, 'swords': ['▁d', 're', 'am', 's']},\n",
       " '▁(': {'freq': 34, 'swords': ['▁', '(']},\n",
       " '▁too': {'freq': 180, 'swords': ['▁to', 'o']},\n",
       " '▁)': {'freq': 34, 'swords': ['▁', ')']},\n",
       " '▁can': {'freq': 438, 'swords': ['▁c', 'an']},\n",
       " '▁tell': {'freq': 306, 'swords': ['▁t', 'ell']},\n",
       " '▁why': {'freq': 68, 'swords': ['▁wh', 'y']},\n",
       " '▁Phoebus': {'freq': 39, 'swords': ['▁P', 'h', 'o', 'e', 'b', 'us']},\n",
       " '▁is': {'freq': 1545, 'swords': ['▁is']},\n",
       " '▁say': {'freq': 211, 'swords': ['▁s', 'ay']},\n",
       " '▁whether': {'freq': 174, 'swords': ['▁w', 'he', 'ther']},\n",
       " '▁vow': {'freq': 6, 'swords': ['▁', 'v', 'ow']},\n",
       " '▁broken': {'freq': 26, 'swords': ['▁b', 'ro', 'k', 'en']},\n",
       " '▁hecatomb': {'freq': 16, 'swords': ['▁he', 'c', 'at', 'om', 'b']},\n",
       " '▁savour': {'freq': 7, 'swords': ['▁sa', 'v', 'our']},\n",
       " '▁lambs': {'freq': 21, 'swords': ['▁l', 'am', 'b', 's']},\n",
       " '▁without': {'freq': 192, 'swords': ['▁with', 'out']},\n",
       " '▁blemish': {'freq': 2, 'swords': ['▁b', 'le', 'm', 'is', 'h']},\n",
       " '▁take': {'freq': 405, 'swords': ['▁t', 'a', 'ke']},\n",
       " '▁With': {'freq': 115, 'swords': ['▁W', 'ith']},\n",
       " '▁words': {'freq': 128, 'swords': ['▁w', 'or', 'd', 's']},\n",
       " '▁Calchas': {'freq': 7, 'swords': ['▁', 'C', 'al', 'ch', 'as']},\n",
       " '▁Thestor': {'freq': 4, 'swords': ['▁The', 'st', 'or']},\n",
       " '▁wisest': {'freq': 6, 'swords': ['▁w', 'is', 'est']},\n",
       " '▁augurs': {'freq': 2, 'swords': ['▁a', 'u', 'g', 'ur', 's']},\n",
       " '▁knew': {'freq': 75, 'swords': ['▁k', 'n', 'e', 'w']},\n",
       " '▁things': {'freq': 107, 'swords': ['▁th', 'ing', 's']},\n",
       " '▁past': {'freq': 29, 'swords': ['▁p', 'as', 't']},\n",
       " '▁present': {'freq': 54, 'swords': ['▁p', 're', 's', 'ent']},\n",
       " '▁speak': {'freq': 138, 'swords': ['▁sp', 'e', 'a', 'k']},\n",
       " '▁guided': {'freq': 9, 'swords': ['▁g', 'u', 'id', 'ed']},\n",
       " '▁fleet': {'freq': 93, 'swords': ['▁f', 'le', 'et']},\n",
       " '▁Ilius': {'freq': 99, 'swords': ['▁I', 'l', 'i', 'us']},\n",
       " '▁through': {'freq': 303, 'swords': ['▁th', 'r', 'ough']},\n",
       " '▁prophesyings': {'freq': 3,\n",
       "  'swords': ['▁p', 'ro', 'p', 'he', 's', 'y', 'ing', 's']},\n",
       " '▁inspired': {'freq': 10, 'swords': ['▁in', 's', 'p', 'i', 'red']},\n",
       " '▁sincerity': {'freq': 9, 'swords': ['▁s', 'in', 'c', 'er', 'it', 'y']},\n",
       " '▁goodwill': {'freq': 15, 'swords': ['▁go', 'od', 'w', 'ill']},\n",
       " '▁addressed': {'freq': 18, 'swords': ['▁a', 'd', 'd', 're', 's', 's', 'ed']},\n",
       " '▁thus': {'freq': 197, 'swords': ['▁th', 'us']},\n",
       " '▁loved': {'freq': 29, 'swords': ['▁l', 'ove', 'd']},\n",
       " '▁heaven': {'freq': 316, 'swords': ['▁he', 'a', 'ven']},\n",
       " '▁bid': {'freq': 68, 'swords': ['▁b', 'id']},\n",
       " '▁therefore': {'freq': 282, 'swords': ['▁there', 'f', 'ore']},\n",
       " '▁consider': {'freq': 18, 'swords': ['▁c', 'on', 's', 'id', 'er']},\n",
       " '▁swear': {'freq': 28, 'swords': ['▁s', 'w', 'ear']},\n",
       " '▁stand': {'freq': 123, 'swords': ['▁st', 'and']},\n",
       " '▁heartily': {'freq': 9, 'swords': ['▁he', 'ar', 't', 'i', 'ly']},\n",
       " '▁deed': {'freq': 19, 'swords': ['▁de', 'ed']},\n",
       " '▁know': {'freq': 221, 'swords': ['▁k', 'n', 'ow']},\n",
       " '▁offend': {'freq': 2, 'swords': ['▁of', 'f', 'e', 'nd']},\n",
       " '▁rules': {'freq': 4, 'swords': ['▁r', 'u', 'l', 'es']},\n",
       " '▁Argives': {'freq': 157, 'swords': ['▁A', 'r', 'g', 'ive', 's']},\n",
       " '▁subjection': {'freq': 4, 'swords': ['▁su', 'b', 'j', 'e', 'ct', 'i', 'on']},\n",
       " '▁A': {'freq': 45, 'swords': ['▁A']},\n",
       " '▁plain': {'freq': 107, 'swords': ['▁p', 'l', 'ain']},\n",
       " '▁cannot': {'freq': 126, 'swords': ['▁c', 'an', 'n', 'ot']},\n",
       " '▁against': {'freq': 265, 'swords': ['▁a', 'g', 'ain', 'st']},\n",
       " '▁swallow': {'freq': 7, 'swords': ['▁s', 'w', 'all', 'ow']},\n",
       " '▁displeasure': {'freq': 13,\n",
       "  'swords': ['▁d', 'is', 'p', 'le', 'as', 'u', 're']},\n",
       " '▁nurse': {'freq': 26, 'swords': ['▁n', 'ur', 'se']},\n",
       " '▁revenge': {'freq': 28, 'swords': ['▁re', 'ven', 'g', 'e']},\n",
       " '▁till': {'freq': 324, 'swords': ['▁t', 'ill']},\n",
       " '▁has': {'freq': 671, 'swords': ['▁ha', 's']},\n",
       " '▁wreaked': {'freq': 1, 'swords': ['▁w', 're', 'a', 'k', 'ed']},\n",
       " '▁Consider': {'freq': 4, 'swords': ['▁', 'C', 'on', 's', 'id', 'er']},\n",
       " '▁no': {'freq': 694, 'swords': ['▁no']},\n",
       " '▁protect': {'freq': 33, 'swords': ['▁p', 'r', 'ot', 'e', 'ct']},\n",
       " '▁answered': {'freq': 300, 'swords': ['▁an', 's', 'w', 'e', 'red']},\n",
       " '▁Fear': {'freq': 8, 'swords': ['▁', 'F', 'ear']},\n",
       " '▁whose': {'freq': 101, 'swords': ['▁who', 'se']},\n",
       " '▁oracles': {'freq': 5, 'swords': ['▁or', 'a', 'c', 'l', 'es']},\n",
       " '▁reveal': {'freq': 1, 'swords': ['▁re', 've', 'al']},\n",
       " '▁Danaan': {'freq': 14, 'swords': ['▁', 'D', 'an', 'a', 'an']},\n",
       " '▁lay': {'freq': 161, 'swords': ['▁l', 'ay']},\n",
       " '▁while': {'freq': 457, 'swords': ['▁whi', 'le']},\n",
       " '▁live': {'freq': 92, 'swords': ['▁l', 'ive']},\n",
       " '▁look': {'freq': 102, 'swords': ['▁l', 'o', 'o', 'k']},\n",
       " '▁earth': {'freq': 135, 'swords': ['▁e', 'ar', 'th']},\n",
       " '▁though': {'freq': 338, 'swords': ['▁th', 'ough']},\n",
       " '▁name': {'freq': 76, 'swords': ['▁n', 'ame']},\n",
       " '▁foremost': {'freq': 62, 'swords': ['▁f', 'ore', 'm', 'o', 'st']},\n",
       " '▁Thereon': {'freq': 36, 'swords': ['▁The', 're', 'on']},\n",
       " '▁seer': {'freq': 10, 'swords': ['▁se', 'er']},\n",
       " '▁boldly': {'freq': 5, 'swords': ['▁b', 'o', 'ld', 'ly']},\n",
       " '▁neither': {'freq': 127, 'swords': ['▁n', 'e', 'it', 'her']},\n",
       " '▁sake': {'freq': 26, 'swords': ['▁sa', 'ke']},\n",
       " '▁evils': {'freq': 3, 'swords': ['▁e', 'v', 'il', 's']},\n",
       " '▁others': {'freq': 206, 'swords': ['▁o', 'ther', 's']},\n",
       " '▁deliver': {'freq': 7, 'swords': ['▁de', 'l', 'i', 'ver']},\n",
       " '▁restored': {'freq': 3, 'swords': ['▁re', 'st', 'ore', 'd']},\n",
       " '▁girl': {'freq': 37, 'swords': ['▁g', 'ir', 'l']},\n",
       " '▁fee': {'freq': 1, 'swords': ['▁f', 'e', 'e']},\n",
       " '▁father': {'freq': 403, 'swords': ['▁f', 'at', 'her']},\n",
       " '▁perhaps': {'freq': 4, 'swords': ['▁p', 'er', 'h', 'a', 'p', 's']},\n",
       " '▁appease': {'freq': 5, 'swords': ['▁a', 'p', 'p', 'e', 'as', 'e']},\n",
       " '▁His': {'freq': 65, 'swords': ['▁H', 'is']},\n",
       " '▁heart': {'freq': 236, 'swords': ['▁he', 'ar', 't']},\n",
       " '▁black': {'freq': 36, 'swords': ['▁b', 'l', 'a', 'ck']},\n",
       " '▁eyes': {'freq': 159, 'swords': ['▁e', 'y', 'es']},\n",
       " '▁flashed': {'freq': 7, 'swords': ['▁f', 'l', 'as', 'he', 'd']},\n",
       " '▁fire': {'freq': 163, 'swords': ['▁f', 'i', 're']},\n",
       " '▁scowled': {'freq': 7, 'swords': ['▁s', 'c', 'ow', 'l', 'ed']},\n",
       " '▁Seer': {'freq': 1, 'swords': ['▁S', 'e', 'er']},\n",
       " '▁evil': {'freq': 56, 'swords': ['▁e', 'v', 'il']},\n",
       " '▁never': {'freq': 203, 'swords': ['▁n', 'e', 'ver']},\n",
       " '▁prophesied': {'freq': 3, 'swords': ['▁p', 'ro', 'p', 'he', 's', 'i', 'ed']},\n",
       " '▁smooth': {'freq': 9, 'swords': ['▁s', 'm', 'o', 'ot', 'h']},\n",
       " '▁concerning': {'freq': 6, 'swords': ['▁c', 'on', 'c', 'er', 'n', 'ing']},\n",
       " '▁foretell': {'freq': 3, 'swords': ['▁f', 'ore', 't', 'ell']},\n",
       " '▁You': {'freq': 195, 'swords': ['▁', 'Y', 'ou']},\n",
       " '▁comfort': {'freq': 17, 'swords': ['▁c', 'om', 'f', 'or', 't']},\n",
       " '▁performance': {'freq': 1,\n",
       "  'swords': ['▁p', 'er', 'f', 'or', 'm', 'an', 'ce']},\n",
       " '▁seeing': {'freq': 44, 'swords': ['▁se', 'e', 'ing']},\n",
       " '▁saying': {'freq': 225, 'swords': ['▁s', 'ay', 'ing']},\n",
       " '▁plagued': {'freq': 2, 'swords': ['▁p', 'l', 'a', 'g', 'u', 'ed']},\n",
       " '▁keeping': {'freq': 28, 'swords': ['▁', 'ke', 'ep', 'ing']},\n",
       " '▁love': {'freq': 38, 'swords': ['▁l', 'ove']},\n",
       " '▁better': {'freq': 135, 'swords': ['▁be', 't', 'ter']},\n",
       " '▁even': {'freq': 427, 'swords': ['▁e', 'ven']},\n",
       " '▁than': {'freq': 275, 'swords': ['▁th', 'an']},\n",
       " '▁wife': {'freq': 147, 'swords': ['▁w', 'if', 'e']},\n",
       " '▁Clytemnestra': {'freq': 4,\n",
       "  'swords': ['▁', 'C', 'ly', 't', 'e', 'm', 'n', 'est', 'r', 'a']},\n",
       " '▁peer': {'freq': 31, 'swords': ['▁p', 'e', 'er']},\n",
       " '▁she': {'freq': 849, 'swords': ['▁she']},\n",
       " '▁alike': {'freq': 34, 'swords': ['▁a', 'l', 'i', 'ke']},\n",
       " '▁form': {'freq': 28, 'swords': ['▁for', 'm']},\n",
       " '▁feature': {'freq': 1, 'swords': ['▁f', 'e', 'at', 'u', 're']},\n",
       " '▁understanding': {'freq': 24,\n",
       "  'swords': ['▁u', 'nd', 'er', 'st', 'and', 'ing']},\n",
       " '▁accomplishments': {'freq': 4,\n",
       "  'swords': ['▁a', 'c', 'c', 'om', 'p', 'l', 'is', 'h', 'm', 'ent', 's']},\n",
       " '▁Still': {'freq': 29, 'swords': ['▁S', 't', 'ill']},\n",
       " '▁give': {'freq': 287, 'swords': ['▁g', 'ive']},\n",
       " '▁up': {'freq': 646, 'swords': ['▁up']},\n",
       " '▁must': {'freq': 195, 'swords': ['▁m', 'us', 't']},\n",
       " '▁die': {'freq': 50, 'swords': ['▁d', 'ie']},\n",
       " '▁prize': {'freq': 46, 'swords': ['▁p', 'ri', 'z', 'e']},\n",
       " '▁instead': {'freq': 13, 'swords': ['▁in', 'st', 'e', 'ad']},\n",
       " '▁alone': {'freq': 93, 'swords': ['▁a', 'l', 'on', 'e']},\n",
       " '▁This': {'freq': 126, 'swords': ['▁T', 'h', 'is']},\n",
       " '▁well': {'freq': 230, 'swords': ['▁we', 'll']},\n",
       " '▁behold': {'freq': 16, 'swords': ['▁be', 'h', 'o', 'ld']},\n",
       " '▁elsewhither': {'freq': 4,\n",
       "  'swords': ['▁e', 'l', 'se', 'w', 'h', 'it', 'her']},\n",
       " '▁Most': {'freq': 8, 'swords': ['▁M', 'o', 'st']},\n",
       " '▁noble': {'freq': 156, 'swords': ['▁no', 'b', 'le']},\n",
       " '▁covetous': {'freq': 1, 'swords': ['▁c', 'ove', 't', 'ou', 's']},\n",
       " '▁beyond': {'freq': 40, 'swords': ['▁be', 'y', 'o', 'nd']},\n",
       " '▁mankind': {'freq': 33, 'swords': ['▁man', 'k', 'ind']},\n",
       " '▁how': {'freq': 233, 'swords': ['▁h', 'ow']},\n",
       " '▁We': {'freq': 113, 'swords': ['▁W', 'e']},\n",
       " '▁common': {'freq': 18, 'swords': ['▁c', 'om', 'm', 'on']},\n",
       " '▁store': {'freq': 42, 'swords': ['▁st', 'ore']},\n",
       " '▁Those': {'freq': 11, 'swords': ['▁T', 'h', 'o', 'se']},\n",
       " '▁took': {'freq': 403, 'swords': ['▁to', 'o', 'k']},\n",
       " '▁cities': {'freq': 31, 'swords': ['▁c', 'it', 'i', 'es']},\n",
       " '▁been': {'freq': 493, 'swords': ['▁be', 'en']},\n",
       " '▁awarded': {'freq': 7, 'swords': ['▁a', 'w', 'ard', 'ed']},\n",
       " '▁disallow': {'freq': 1, 'swords': ['▁d', 'is', 'all', 'ow']},\n",
       " '▁awards': {'freq': 1, 'swords': ['▁a', 'w', 'ard', 's']},\n",
       " '▁made': {'freq': 421, 'swords': ['▁m', 'ad', 'e']},\n",
       " '▁already': {'freq': 69, 'swords': ['▁a', 'l', 're', 'ad', 'y']},\n",
       " '▁Give': {'freq': 7, 'swords': ['▁', 'G', 'ive']},\n",
       " '▁grants': {'freq': 3, 'swords': ['▁g', 'r', 'an', 't', 's']},\n",
       " '▁Troy': {'freq': 152, 'swords': ['▁T', 'ro', 'y']},\n",
       " '▁requite': {'freq': 5, 'swords': ['▁re', 'q', 'u', 'it', 'e']},\n",
       " '▁three': {'freq': 71, 'swords': ['▁th', 're', 'e']},\n",
       " '▁fourfold': {'freq': 1, 'swords': ['▁f', 'our', 'f', 'o', 'ld']},\n",
       " '▁valiant': {'freq': 60, 'swords': ['▁', 'v', 'al', 'i', 'an', 't']},\n",
       " '▁outwit': {'freq': 2, 'swords': ['▁o', 'ut', 'w', 'it']},\n",
       " '▁overreach': {'freq': 1, 'swords': ['▁o', 'ver', 're', 'a', 'ch']},\n",
       " '▁persuade': {'freq': 17, 'swords': ['▁p', 'er', 's', 'u', 'ad', 'e']},\n",
       " '▁Are': {'freq': 24, 'swords': ['▁A', 're']},\n",
       " '▁keep': {'freq': 143, 'swords': ['▁', 'ke', 'ep']},\n",
       " '▁sit': {'freq': 56, 'swords': ['▁s', 'it']},\n",
       " '▁tamely': {'freq': 3, 'swords': ['▁t', 'ame', 'ly']},\n",
       " '▁under': {'freq': 226, 'swords': ['▁u', 'nd', 'er']},\n",
       " '▁loss': {'freq': 23, 'swords': ['▁l', 'o', 's', 's']},\n",
       " '▁bidding': {'freq': 23, 'swords': ['▁b', 'id', 'd', 'ing']},\n",
       " '▁fair': {'freq': 147, 'swords': ['▁f', 'a', 'ir']},\n",
       " '▁exchange': {'freq': 5, 'swords': ['▁e', 'x', 'ch', 'an', 'g', 'e']},\n",
       " '▁liking': {'freq': 10, 'swords': ['▁l', 'i', 'k', 'ing']},\n",
       " '▁Ajax': {'freq': 183, 'swords': ['▁A', 'j', 'a', 'x']},\n",
       " '▁Ulysses': {'freq': 703, 'swords': ['▁', 'U', 'ly', 's', 'ses']},\n",
       " '▁whomsoever': {'freq': 3, 'swords': ['▁wh', 'om', 's', 'o', 'e', 'ver']},\n",
       " '▁rue': {'freq': 11, 'swords': ['▁r', 'u', 'e']},\n",
       " '▁But': {'freq': 210, 'swords': ['▁', 'B', 'ut']},\n",
       " '▁thought': {'freq': 73, 'swords': ['▁th', 'ou', 'ght']},\n",
       " '▁draw': {'freq': 63, 'swords': ['▁d', 'r', 'a', 'w']},\n",
       " '▁ship': {'freq': 297, 'swords': ['▁ship']},\n",
       " '▁into': {'freq': 615, 'swords': ['▁in', 't', 'o']},\n",
       " '▁crew': {'freq': 46, 'swords': ['▁c', 're', 'w']},\n",
       " '▁expressly': {'freq': 2, 'swords': ['▁e', 'x', 'p', 're', 's', 's', 'ly']},\n",
       " '▁put': {'freq': 230, 'swords': ['▁p', 'ut']},\n",
       " '▁board': {'freq': 61, 'swords': ['▁b', 'o', 'ard']},\n",
       " '▁Chryseis': {'freq': 5, 'swords': ['▁', 'C', 'h', 'r', 'y', 'se', 'is']},\n",
       " '▁also': {'freq': 268, 'swords': ['▁a', 'l', 's', 'o']},\n",
       " '▁further': {'freq': 92, 'swords': ['▁f', 'ur', 'ther']},\n",
       " '▁chief': {'freq': 41, 'swords': ['▁ch', 'ie', 'f']},\n",
       " '▁command': {'freq': 16, 'swords': ['▁c', 'om', 'm', 'and']},\n",
       " '▁either': {'freq': 123, 'swords': ['▁e', 'it', 'her']},\n",
       " '▁Idomeneus': {'freq': 84, 'swords': ['▁I', 'd', 'om', 'en', 'e', 'us']},\n",
       " '▁yourself': {'freq': 135, 'swords': ['▁your', 'sel', 'f']},\n",
       " '▁mighty': {'freq': 127, 'swords': ['▁m', 'ight', 'y']},\n",
       " '▁warrior': {'freq': 26, 'swords': ['▁w', 'ar', 'ri', 'or']},\n",
       " '▁offer': {'freq': 37, 'swords': ['▁of', 'f', 'er']},\n",
       " '▁sacrifice': {'freq': 52, 'swords': ['▁sa', 'c', 'ri', 'f', 'i', 'ce']},\n",
       " '▁steeped': {'freq': 3, 'swords': ['▁st', 'e', 'ep', 'ed']},\n",
       " '▁insolence': {'freq': 17, 'swords': ['▁in', 's', 'o', 'l', 'en', 'ce']},\n",
       " '▁lust': {'freq': 9, 'swords': ['▁l', 'us', 't']},\n",
       " '▁gain': {'freq': 15, 'swords': ['▁g', 'ain']},\n",
       " '▁what': {'freq': 393, 'swords': ['▁wh', 'at']},\n",
       " '▁any': {'freq': 336, 'swords': ['▁an', 'y']},\n",
       " '▁foray': {'freq': 1, 'swords': ['▁for', 'ay']},\n",
       " '▁open': {'freq': 51, 'swords': ['▁o', 'p', 'en']},\n",
       " '▁fighting': {'freq': 173, 'swords': ['▁f', 'ight', 'ing']},\n",
       " '▁warring': {'freq': 2, 'swords': ['▁w', 'ar', 'r', 'ing']},\n",
       " '▁here': {'freq': 319, 'swords': ['▁he', 're']},\n",
       " '▁ill': {'freq': 82, 'swords': ['▁', 'ill']},\n",
       " '▁Trojans': {'freq': 573, 'swords': ['▁T', 'ro', 'j', 'ans']},\n",
       " '▁done': {'freq': 145, 'swords': ['▁d', 'on', 'e']},\n",
       " '▁They': {'freq': 236, 'swords': ['▁The', 'y']},\n",
       " '▁raided': {'freq': 1, 'swords': ['▁r', 'a', 'id', 'ed']},\n",
       " '▁cattle': {'freq': 62, 'swords': ['▁c', 'at', 't', 'le']},\n",
       " '▁horses': {'freq': 308, 'swords': ['▁h', 'or', 'ses']},\n",
       " '▁harvests': {'freq': 1, 'swords': ['▁h', 'ar', 've', 'st', 's']},\n",
       " '▁rich': {'freq': 74, 'swords': ['▁r', 'i', 'ch']},\n",
       " '▁plains': {'freq': 3, 'swords': ['▁p', 'l', 'ain', 's']},\n",
       " '▁Phthia': {'freq': 18, 'swords': ['▁P', 'h', 'th', 'i', 'a']},\n",
       " '▁between': {'freq': 99, 'swords': ['▁be', 't', 'w', 'e', 'en']},\n",
       " '▁there': {'freq': 601, 'swords': ['▁there']},\n",
       " '▁space': {'freq': 24, 'swords': ['▁sp', 'a', 'ce']},\n",
       " '▁both': {'freq': 300, 'swords': ['▁b', 'ot', 'h']},\n",
       " '▁mountain': {'freq': 62, 'swords': ['▁m', 'ou', 'n', 't', 'ain']},\n",
       " '▁followed': {'freq': 52, 'swords': ['▁f', 'o', 'll', 'ow', 'ed']},\n",
       " '▁Sir': {'freq': 44, 'swords': ['▁S', 'ir']},\n",
       " '▁Insolence': {'freq': 1, 'swords': ['▁I', 'n', 's', 'o', 'l', 'en', 'ce']},\n",
       " '▁!': {'freq': 20, 'swords': ['▁', '!']},\n",
       " '▁pleasure': {'freq': 18, 'swords': ['▁p', 'le', 'as', 'u', 're']},\n",
       " '▁ours': {'freq': 11, 'swords': ['▁o', 'ur', 's']},\n",
       " '▁satisfaction': {'freq': 11,\n",
       "  'swords': ['▁s', 'at', 'is', 'f', 'a', 'ct', 'i', 'on']},\n",
       " '▁shameless': {'freq': 3, 'swords': ['▁sh', 'ame', 'l', 'es', 's']},\n",
       " '▁self': {'freq': 22, 'swords': ['▁se', 'l', 'f']},\n",
       " '▁Menelaus': {'freq': 211, 'swords': ['▁M', 'en', 'e', 'l', 'a', 'us']},\n",
       " '▁forget': {'freq': 30, 'swords': ['▁for', 'g', 'et']},\n",
       " '▁threaten': {'freq': 2, 'swords': ['▁th', 're', 'at', 'en']},\n",
       " '▁rob': {'freq': 12, 'swords': ['▁r', 'o', 'b']},\n",
       " '▁toiled': {'freq': 2, 'swords': ['▁to', 'il', 'ed']},\n",
       " '▁given': {'freq': 120, 'swords': ['▁g', 'i', 'ven']},\n",
       " '▁Never': {'freq': 15, 'swords': ['▁', 'N', 'e', 'ver']},\n",
       " '▁receive': {'freq': 9, 'swords': ['▁re', 'ce', 'ive']},\n",
       " '▁good': {'freq': 295, 'swords': ['▁go', 'od']},\n",
       " '▁hands': {'freq': 328, 'swords': ['▁ha', 'nd', 's']},\n",
       " '▁part': {'freq': 83, 'swords': ['▁p', 'ar', 't']},\n",
       " '▁When': {'freq': 356, 'swords': ['▁W', 'hen']},\n",
       " '▁sharing': {'freq': 3, 'swords': ['▁sh', 'ar', 'ing']},\n",
       " '▁comes': {'freq': 69, 'swords': ['▁c', 'om', 'es']},\n",
       " '▁share': {'freq': 29, 'swords': ['▁sh', 'a', 're']},\n",
       " '▁largest': {'freq': 7, 'swords': ['▁l', 'ar', 'g', 'est']},\n",
       " '▁forsooth': {'freq': 6, 'swords': ['▁for', 's', 'o', 'ot', 'h']},\n",
       " '▁get': {'freq': 187, 'swords': ['▁g', 'et']},\n",
       " '▁thankful': {'freq': 11, 'swords': ['▁th', 'an', 'k', 'f', 'u', 'l']},\n",
       " '▁labour': {'freq': 21, 'swords': ['▁l', 'a', 'b', 'our']},\n",
       " '▁much': {'freq': 320, 'swords': ['▁m', 'u', 'ch']},\n",
       " '▁return': {'freq': 138, 'swords': ['▁re', 't', 'ur', 'n']},\n",
       " '▁stay': {'freq': 132, 'swords': ['▁st', 'ay']},\n",
       " '▁gather': {'freq': 24, 'swords': ['▁g', 'at', 'her']},\n",
       " '▁gold': {'freq': 126, 'swords': ['▁go', 'ld']},\n",
       " '▁substance': {'freq': 11, 'swords': ['▁su', 'b', 'st', 'an', 'ce']},\n",
       " '▁Fly': {'freq': 1, 'swords': ['▁', 'F', 'ly']},\n",
       " '▁make': {'freq': 275, 'swords': ['▁m', 'a', 'ke']},\n",
       " '▁prayers': {'freq': 17, 'swords': ['▁p', 'r', 'ay', 'er', 's']},\n",
       " '▁honour': {'freq': 89, 'swords': ['▁h', 'on', 'our']},\n",
       " '▁above': {'freq': 55, 'swords': ['▁ab', 'ove']},\n",
       " '▁lord': {'freq': 68, 'swords': ['▁l', 'or', 'd']},\n",
       " '▁counsel': {'freq': 66, 'swords': ['▁c', 'ou', 'n', 'sel']},\n",
       " '▁There': {'freq': 145, 'swords': ['▁The', 're']},\n",
       " '▁hateful': {'freq': 10, 'swords': ['▁h', 'at', 'e', 'f', 'u', 'l']},\n",
       " '▁quarrelsome': {'freq': 1,\n",
       "  'swords': ['▁', 'q', 'u', 'ar', 're', 'l', 's', 'ome']},\n",
       " '▁affected': {'freq': 2, 'swords': ['▁a', 'f', 'f', 'e', 'ct', 'ed']},\n",
       " '▁What': {'freq': 55, 'swords': ['▁W', 'h', 'at']},\n",
       " '▁Was': {'freq': 8, 'swords': ['▁W', 'as']},\n",
       " '▁Go': {'freq': 42, 'swords': ['▁', 'G', 'o']},\n",
       " '▁then': {'freq': 749, 'swords': ['▁the', 'n']},\n",
       " '▁comrades': {'freq': 84, 'swords': ['▁c', 'om', 'r', 'ad', 'es']},\n",
       " '▁over': {'freq': 526, 'swords': ['▁o', 'ver']},\n",
       " '▁Myrmidons': {'freq': 41, 'swords': ['▁M', 'y', 'r', 'm', 'id', 'on', 's']},\n",
       " '▁care': {'freq': 68, 'swords': ['▁c', 'a', 're']},\n",
       " '▁since': {'freq': 40, 'swords': ['▁s', 'in', 'ce']},\n",
       " '▁followers': {'freq': 16, 'swords': ['▁f', 'o', 'll', 'ow', 'er', 's']},\n",
       " '▁tent': {'freq': 54, 'swords': ['▁t', 'ent']},\n",
       " '▁Briseis': {'freq': 13, 'swords': ['▁', 'B', 'r', 'is', 'e', 'is']},\n",
       " '▁learn': {'freq': 36, 'swords': ['▁le', 'ar', 'n']},\n",
       " '▁stronger': {'freq': 39, 'swords': ['▁st', 'r', 'ong', 'er']},\n",
       " '▁am': {'freq': 337, 'swords': ['▁am']},\n",
       " '▁fear': {'freq': 117, 'swords': ['▁f', 'ear']},\n",
       " '▁equal': {'freq': 14, 'swords': ['▁e', 'q', 'u', 'al']},\n",
       " '▁comparable': {'freq': 2, 'swords': ['▁c', 'om', 'p', 'ar', 'a', 'b', 'le']},\n",
       " '▁shaggy': {'freq': 6, 'swords': ['▁sh', 'a', 'g', 'g', 'y']},\n",
       " '▁breast': {'freq': 34, 'swords': ['▁b', 're', 'as', 't']},\n",
       " '▁divided': {'freq': 22, 'swords': ['▁d', 'i', 'v', 'id', 'ed']},\n",
       " '▁sword': {'freq': 101, 'swords': ['▁s', 'w', 'or', 'd']},\n",
       " '▁push': {'freq': 2, 'swords': ['▁p', 'us', 'h']},\n",
       " '▁aside': {'freq': 27, 'swords': ['▁as', 'id', 'e']},\n",
       " '▁kill': {'freq': 105, 'swords': ['▁k', 'ill']},\n",
       " '▁restrain': {'freq': 6, 'swords': ['▁re', 'st', 'r', 'ain']},\n",
       " '▁check': {'freq': 17, 'swords': ['▁c', 'he', 'ck']},\n",
       " '▁While': {'freq': 23, 'swords': ['▁W', 'h', 'i', 'le']},\n",
       " '▁minds': {'freq': 22, 'swords': ['▁m', 'ind', 's']},\n",
       " '▁drawing': {'freq': 19, 'swords': ['▁d', 'r', 'a', 'w', 'ing']},\n",
       " '▁its': {'freq': 151, 'swords': ['▁it', 's']},\n",
       " '▁scabbard': {'freq': 6, 'swords': ['▁s', 'c', 'a', 'b', 'b', 'ard']},\n",
       " '▁Minerva': {'freq': 307, 'swords': ['▁M', 'in', 'er', 'v', 'a']},\n",
       " '▁seized': {'freq': 23, 'swords': ['▁se', 'i', 'z', 'ed']},\n",
       " '▁yellow': {'freq': 9, 'swords': ['▁y', 'ell', 'ow']},\n",
       " '▁hair': {'freq': 44, 'swords': ['▁ha', 'ir']},\n",
       " '▁visible': {'freq': 3, 'swords': ['▁', 'v', 'is', 'i', 'b', 'le']},\n",
       " '▁could': {'freq': 375, 'swords': ['▁c', 'ould']},\n",
       " '▁see': {'freq': 356, 'swords': ['▁se', 'e']},\n",
       " '▁turned': {'freq': 95, 'swords': ['▁t', 'ur', 'n', 'ed']},\n",
       " '▁amaze': {'freq': 2, 'swords': ['▁am', 'a', 'z', 'e']},\n",
       " '▁Why': {'freq': 35, 'swords': ['▁W', 'h', 'y']},\n",
       " '▁aegis': {'freq': 39, 'swords': ['▁a', 'e', 'g', 'is']},\n",
       " '▁bearing': {'freq': 64, 'swords': ['▁be', 'ar', 'ing']},\n",
       " '▁To': {'freq': 36, 'swords': ['▁T', 'o']},\n",
       " '▁pride': {'freq': 19, 'swords': ['▁p', 'r', 'id', 'e']},\n",
       " '▁surely': {'freq': 50, 'swords': ['▁su', 're', 'ly']},\n",
       " '▁pay': {'freq': 28, 'swords': ['▁p', 'ay']},\n",
       " '▁life': {'freq': 113, 'swords': ['▁l', 'if', 'e']},\n",
       " '▁cares': {'freq': 5, 'swords': ['▁c', 'a', 're', 's']},\n",
       " '▁Cease': {'freq': 4, 'swords': ['▁', 'C', 'e', 'as', 'e']},\n",
       " '▁brawling': {'freq': 4, 'swords': ['▁br', 'a', 'w', 'l', 'ing']},\n",
       " '▁rail': {'freq': 4, 'swords': ['▁r', 'a', 'il']},\n",
       " '▁railing': {'freq': 6, 'swords': ['▁r', 'a', 'il', 'ing']},\n",
       " '▁vain': {'freq': 38, 'swords': ['▁', 'v', 'ain']},\n",
       " '▁gifts': {'freq': 43, 'swords': ['▁g', 'if', 't', 's']},\n",
       " '▁times': {'freq': 30, 'swords': ['▁t', 'im', 'es']},\n",
       " '▁splendid': {'freq': 11, 'swords': ['▁sp', 'le', 'nd', 'id']},\n",
       " '▁reason': {'freq': 25, 'swords': ['▁re', 'as', 'on']},\n",
       " '▁insult': {'freq': 9, 'swords': ['▁in', 's', 'u', 'l', 't']},\n",
       " '▁Hold': {'freq': 7, 'swords': ['▁H', 'o', 'ld']},\n",
       " '▁obey': {'freq': 14, 'swords': ['▁o', 'b', 'e', 'y']},\n",
       " '▁Goddess': {'freq': 6, 'swords': ['▁', 'G', 'od', 'd', 'es', 's']},\n",
       " '▁however': {'freq': 143, 'swords': ['▁h', 'ow', 'e', 'ver']},\n",
       " '▁best': {'freq': 139, 'swords': ['▁b', 'est']},\n",
       " '▁stayed': {'freq': 78, 'swords': ['▁st', 'ay', 'ed']},\n",
       " '▁hilt': {'freq': 4, 'swords': ['▁h', 'il', 't']},\n",
       " '▁thrust': {'freq': 16, 'swords': ['▁th', 'r', 'us', 't']},\n",
       " '▁bade': {'freq': 77, 'swords': ['▁b', 'ad', 'e']},\n",
       " '▁again': {'freq': 298, 'swords': ['▁a', 'g', 'ain']},\n",
       " '▁began': {'freq': 117, 'swords': ['▁be', 'g', 'an']},\n",
       " '▁still': {'freq': 297, 'swords': ['▁st', 'ill']},\n",
       " '▁Wine': {'freq': 2, 'swords': ['▁W', 'in', 'e']},\n",
       " '▁bibber': {'freq': 1, 'swords': ['▁b', 'i', 'b', 'b', 'er']},\n",
       " '▁dog': {'freq': 9, 'swords': ['▁do', 'g']},\n",
       " '▁hind': {'freq': 5, 'swords': ['▁h', 'ind']},\n",
       " '▁dare': {'freq': 39, 'swords': ['▁d', 'a', 're']},\n",
       " '▁fight': {'freq': 362, 'swords': ['▁f', 'ight']},\n",
       " '▁chosen': {'freq': 16, 'swords': ['▁ch', 'o', 's', 'en']},\n",
       " '▁ambuscade': {'freq': 8, 'swords': ['▁am', 'b', 'us', 'c', 'ad', 'e']},\n",
       " '▁shun': {'freq': 6, 'swords': ['▁sh', 'un']},\n",
       " '▁itself': {'freq': 45, 'swords': ['▁it', 'sel', 'f']},\n",
       " '▁rather': {'freq': 40, 'swords': ['▁r', 'at', 'her']},\n",
       " '▁round': {'freq': 336, 'swords': ['▁r', 'ound']},\n",
       " '▁prizes': {'freq': 22, 'swords': ['▁p', 'ri', 'z', 'es']},\n",
       " '▁contradicts': {'freq': 3,\n",
       "  'swords': ['▁c', 'on', 't', 'r', 'ad', 'i', 'ct', 's']},\n",
       " '▁devour': {'freq': 14, 'swords': ['▁de', 'v', 'our']},\n",
       " '▁feeble': {'freq': 6, 'swords': ['▁f', 'e', 'e', 'b', 'le']},\n",
       " '▁folk': {'freq': 4, 'swords': ['▁f', 'o', 'l', 'k']},\n",
       " '▁otherwise': {'freq': 10, 'swords': ['▁o', 'ther', 'w', 'is', 'e']},\n",
       " '▁henceforward': {'freq': 9,\n",
       "  'swords': ['▁he', 'n', 'ce', 'f', 'or', 'w', 'ard']},\n",
       " '▁Therefore': {'freq': 48, 'swords': ['▁The', 're', 'f', 'ore']},\n",
       " '▁oath': {'freq': 33, 'swords': ['▁o', 'at', 'h']},\n",
       " '▁nay': {'freq': 5, 'swords': ['▁n', 'ay']},\n",
       " '▁shalt': {'freq': 1, 'swords': ['▁sh', 'al', 't']},\n",
       " '▁sprout': {'freq': 1, 'swords': ['▁sp', 'r', 'out']},\n",
       " '▁leaf': {'freq': 3, 'swords': ['▁le', 'a', 'f']},\n",
       " '▁shoot': {'freq': 16, 'swords': ['▁sh', 'o', 'ot']},\n",
       " '▁bud': {'freq': 1, 'swords': ['▁b', 'u', 'd']},\n",
       " '▁anew': {'freq': 7, 'swords': ['▁an', 'e', 'w']},\n",
       " '▁left': {'freq': 273, 'swords': ['▁le', 'f', 't']},\n",
       " '▁parent': {'freq': 1, 'swords': ['▁p', 'a', 're', 'n', 't']},\n",
       " '▁stem': {'freq': 1, 'swords': ['▁st', 'e', 'm']},\n",
       " '▁mountains': {'freq': 32, 'swords': ['▁m', 'ou', 'n', 't', 'ain', 's']},\n",
       " '▁axe': {'freq': 9, 'swords': ['▁a', 'x', 'e']},\n",
       " '▁stripped': {'freq': 24, 'swords': ['▁st', 'ri', 'p', 'p', 'ed']},\n",
       " '▁bark': {'freq': 4, 'swords': ['▁b', 'ar', 'k']},\n",
       " '▁bear': {'freq': 71, 'swords': ['▁be', 'ar']},\n",
       " '▁judges': {'freq': 2, 'swords': ['▁', 'j', 'u', 'd', 'g', 'es']},\n",
       " '▁guardians': {'freq': 2, 'swords': ['▁g', 'u', 'ard', 'i', 'ans']},\n",
       " '▁decrees': {'freq': 3, 'swords': ['▁de', 'c', 're', 'es']},\n",
       " '▁solemnly': {'freq': 5, 'swords': ['▁so', 'le', 'm', 'n', 'ly']},\n",
       " '▁fondly': {'freq': 7, 'swords': ['▁f', 'o', 'nd', 'ly']},\n",
       " '▁In': {'freq': 79, 'swords': ['▁I', 'n']},\n",
       " '▁distress': {'freq': 21, 'swords': ['▁d', 'is', 't', 're', 's', 's']},\n",
       " '▁fall': {'freq': 112, 'swords': ['▁f', 'all']},\n",
       " '▁dying': {'freq': 17, 'swords': ['▁d', 'y', 'ing']},\n",
       " '▁murderous': {'freq': 23, 'swords': ['▁m', 'ur', 'd', 'er', 'ou', 's']},\n",
       " '▁Hector': {'freq': 480, 'swords': ['▁He', 'ct', 'or']},\n",
       " '▁help': {'freq': 109, 'swords': ['▁he', 'l', 'p']},\n",
       " '▁rend': {'freq': 3, 'swords': ['▁re', 'nd']},\n",
       " '▁hour': {'freq': 22, 'swords': ['▁h', 'our']},\n",
       " '▁bravest': {'freq': 31, 'swords': ['▁br', 'a', 've', 'st']},\n",
       " '▁dashed': {'freq': 8, 'swords': ['▁d', 'as', 'he', 'd']},\n",
       " '▁bestudded': {'freq': 1, 'swords': ['▁b', 'est', 'u', 'd', 'd', 'ed']},\n",
       " '▁ground': {'freq': 259, 'swords': ['▁g', 'r', 'ound']},\n",
       " '▁seat': {'freq': 90, 'swords': ['▁se', 'at']},\n",
       " '▁beginning': {'freq': 22, 'swords': ['▁be', 'g', 'in', 'n', 'ing']},\n",
       " '▁place': {'freq': 157, 'swords': ['▁p', 'l', 'a', 'ce']},\n",
       " '▁side': {'freq': 204, 'swords': ['▁s', 'id', 'e']},\n",
       " '▁uprose': {'freq': 9, 'swords': ['▁up', 'ro', 'se']},\n",
       " '▁tongued': {'freq': 2, 'swords': ['▁to', 'n', 'g', 'u', 'ed']},\n",
       " '▁Nestor': {'freq': 131, 'swords': ['▁', 'N', 'est', 'or']},\n",
       " '▁facile': {'freq': 2, 'swords': ['▁f', 'a', 'c', 'i', 'le']},\n",
       " '▁speaker': {'freq': 5, 'swords': ['▁sp', 'e', 'a', 'k', 'er']},\n",
       " '▁Pylians': {'freq': 9, 'swords': ['▁P', 'y', 'l', 'i', 'ans']},\n",
       " '▁lips': {'freq': 13, 'swords': ['▁l', 'ip', 's']},\n",
       " '▁sweeter': {'freq': 3, 'swords': ['▁s', 'w', 'e', 'et', 'er']},\n",
       " '▁honey': {'freq': 10, 'swords': ['▁h', 'on', 'e', 'y']},\n",
       " '▁Two': {'freq': 7, 'swords': ['▁T', 'w', 'o']},\n",
       " '▁generations': {'freq': 6,\n",
       "  'swords': ['▁g', 'en', 'er', 'at', 'i', 'on', 's']},\n",
       " '▁born': {'freq': 52, 'swords': ['▁b', 'or', 'n']},\n",
       " '▁bred': {'freq': 13, 'swords': ['▁b', 'red']},\n",
       " '▁Pylos': {'freq': 49, 'swords': ['▁P', 'y', 'lo', 's']},\n",
       " '▁passed': {'freq': 43, 'swords': ['▁p', 'as', 's', 'ed']},\n",
       " '▁rule': {'freq': 12, 'swords': ['▁r', 'u', 'le']},\n",
       " '▁reigning': {'freq': 3, 'swords': ['▁re', 'i', 'g', 'n', 'ing']},\n",
       " '▁third': {'freq': 30, 'swords': ['▁th', 'ir', 'd']},\n",
       " '▁Of': {'freq': 24, 'swords': ['▁', 'O', 'f']},\n",
       " '▁truth': {'freq': 42, 'swords': ['▁t', 'r', 'ut', 'h']},\n",
       " '▁sorrow': {'freq': 79, 'swords': ['▁s', 'or', 'r', 'ow']},\n",
       " '▁befallen': {'freq': 10, 'swords': ['▁be', 'f', 'all', 'en']},\n",
       " '▁Achaean': {'freq': 44, 'swords': ['▁Ach', 'ae', 'an']},\n",
       " '▁land': {'freq': 154, 'swords': ['▁l', 'and']},\n",
       " '▁Surely': {'freq': 13, 'swords': ['▁S', 'u', 're', 'ly']},\n",
       " '▁rejoice': {'freq': 9, 'swords': ['▁re', 'j', 'o', 'i', 'ce']},\n",
       " '▁glad': {'freq': 63, 'swords': ['▁g', 'l', 'ad']},\n",
       " '▁excellent': {'freq': 48, 'swords': ['▁e', 'x', 'ce', 'll', 'ent']},\n",
       " '▁older': {'freq': 18, 'swords': ['▁o', 'ld', 'er']},\n",
       " '▁Moreover': {'freq': 31, 'swords': ['▁M', 'ore', 'o', 'ver']},\n",
       " '▁familiar': {'freq': 1, 'swords': ['▁f', 'am', 'il', 'i', 'ar']},\n",
       " '▁friend': {'freq': 64, 'swords': ['▁fr', 'ie', 'nd']},\n",
       " '▁greater': {'freq': 21, 'swords': ['▁g', 're', 'at', 'er']},\n",
       " '▁disregard': {'freq': 2, 'swords': ['▁d', 'is', 're', 'g', 'ard']},\n",
       " '▁such': {'freq': 219, 'swords': ['▁su', 'ch']},\n",
       " '▁Pirithous': {'freq': 7, 'swords': ['▁P', 'ir', 'ith', 'ou', 's']},\n",
       " '▁Dryas': {'freq': 2, 'swords': ['▁', 'D', 'r', 'y', 'as']},\n",
       " '▁shepherd': {'freq': 27, 'swords': ['▁she', 'p', 'her', 'd']},\n",
       " '▁Caeneus': {'freq': 2, 'swords': ['▁', 'C', 'a', 'en', 'e', 'us']},\n",
       " '▁Exadius': {'freq': 1, 'swords': ['▁', 'E', 'x', 'ad', 'i', 'us']},\n",
       " '▁godlike': {'freq': 7, 'swords': ['▁go', 'd', 'l', 'i', 'ke']},\n",
       " '▁Polyphemus': {'freq': 7, 'swords': ['▁P', 'o', 'ly', 'p', 'he', 'm', 'us']},\n",
       " '▁Theseus': {'freq': 3, 'swords': ['▁The', 'se', 'us']},\n",
       " '▁Aegeus': {'freq': 1, 'swords': ['▁A', 'e', 'g', 'e', 'us']},\n",
       " '▁immortals': {'freq': 54, 'swords': ['▁', 'im', 'm', 'or', 't', 'al', 's']},\n",
       " '▁These': {'freq': 55, 'swords': ['▁The', 'se']},\n",
       " '▁mightiest': {'freq': 11, 'swords': ['▁m', 'ight', 'i', 'est']},\n",
       " '▁fought': {'freq': 56, 'swords': ['▁f', 'ou', 'ght']},\n",
       " '▁fiercest': {'freq': 2, 'swords': ['▁f', 'i', 'er', 'c', 'est']},\n",
       " '▁tribes': {'freq': 6, 'swords': ['▁t', 'ri', 'b', 'es']},\n",
       " '▁savages': {'freq': 5, 'swords': ['▁sa', 'v', 'a', 'g', 'es']},\n",
       " '▁utterly': {'freq': 19, 'swords': ['▁', 'ut', 'ter', 'ly']},\n",
       " '▁overthrew': {'freq': 3, 'swords': ['▁o', 'ver', 'th', 're', 'w']},\n",
       " '▁distant': {'freq': 13, 'swords': ['▁d', 'is', 't', 'an', 't']},\n",
       " '▁living': {'freq': 47, 'swords': ['▁l', 'i', 'v', 'ing']},\n",
       " '▁withstand': {'freq': 6, 'swords': ['▁with', 'st', 'and']},\n",
       " '▁persuaded': {'freq': 6, 'swords': ['▁p', 'er', 's', 'u', 'ad', 'ed']},\n",
       " '▁So': {'freq': 93, 'swords': ['▁S', 'o']},\n",
       " '▁yourselves': {'freq': 23, 'swords': ['▁your', 'sel', 've', 's']},\n",
       " '▁more': {'freq': 278, 'swords': ['▁m', 'ore']},\n",
       " '▁way': {'freq': 318, 'swords': ['▁w', 'ay']},\n",
       " '▁strong': {'freq': 138, 'swords': ['▁st', 'r', 'ong']},\n",
       " '▁strive': {'freq': 5, 'swords': ['▁st', 'ri', 've']},\n",
       " '▁grace': {'freq': 9, 'swords': ['▁g', 'r', 'a', 'ce']},\n",
       " '▁wields': {'freq': 4, 'swords': ['▁w', 'ie', 'ld', 's']},\n",
       " '▁like': {'freq': 321, 'swords': ['▁l', 'i', 'ke']},\n",
       " '▁mother': {'freq': 200, 'swords': ['▁m', 'ot', 'her']},\n",
       " '▁implore': {'freq': 6, 'swords': ['▁', 'im', 'p', 'l', 'ore']},\n",
       " '▁end': {'freq': 162, 'swords': ['▁e', 'nd']},\n",
       " '▁battle': {'freq': 255, 'swords': ['▁b', 'at', 't', 'le']},\n",
       " '▁tower': {'freq': 18, 'swords': ['▁to', 'w', 'er']},\n",
       " '▁strength': {'freq': 101, 'swords': ['▁st', 're', 'n', 'g', 'th']},\n",
       " '▁true': {'freq': 62, 'swords': ['▁t', 'r', 'u', 'e']},\n",
       " '▁fellow': {'freq': 52, 'swords': ['▁f', 'ell', 'ow']},\n",
       " '▁needs': {'freq': 8, 'swords': ['▁n', 'e', 'ed', 's']},\n",
       " '▁become': {'freq': 33, 'swords': ['▁be', 'c', 'ome']},\n",
       " '▁master': {'freq': 57, 'swords': ['▁m', 'as', 'ter']},\n",
       " '▁captain': {'freq': 36, 'swords': ['▁c', 'a', 'p', 't', 'ain']},\n",
       " '▁hardly': {'freq': 36, 'swords': ['▁h', 'ard', 'ly']},\n",
       " '▁Granted': {'freq': 2, 'swords': ['▁', 'G', 'r', 'an', 't', 'ed']},\n",
       " '▁right': {'freq': 157, 'swords': ['▁r', 'ight']},\n",
       " '▁interrupted': {'freq': 2,\n",
       "  'swords': ['▁in', 'ter', 'r', 'u', 'p', 't', 'ed']},\n",
       " '▁mean': {'freq': 32, 'swords': ['▁me', 'an']},\n",
       " '▁coward': {'freq': 19, 'swords': ['▁c', 'ow', 'ard']},\n",
       " '▁Order': {'freq': 1, 'swords': ['▁', 'O', 'r', 'd', 'er']},\n",
       " '▁longer': {'freq': 95, 'swords': ['▁l', 'ong', 'er']},\n",
       " '▁Furthermore': {'freq': 13, 'swords': ['▁', 'F', 'ur', 'ther', 'm', 'ore']},\n",
       " '▁those': {'freq': 190, 'swords': ['▁th', 'o', 'se']},\n",
       " '▁gave': {'freq': 207, 'swords': ['▁g', 'a', 've']},\n",
       " '▁else': {'freq': 78, 'swords': ['▁e', 'l', 'se']},\n",
       " '▁carry': {'freq': 45, 'swords': ['▁c', 'ar', 'r', 'y']},\n",
       " '▁force': {'freq': 54, 'swords': ['▁for', 'ce']},\n",
       " '▁Try': {'freq': 2, 'swords': ['▁T', 'r', 'y']},\n",
       " '▁spear': {'freq': 429, 'swords': ['▁sp', 'ear']},\n",
       " '▁reddened': {'freq': 3, 'swords': ['▁re', 'd', 'd', 'en', 'ed']},\n",
       " '▁blood': {'freq': 153, 'swords': ['▁b', 'lo', 'od']},\n",
       " '▁quarrelled': {'freq': 4, 'swords': ['▁', 'q', 'u', 'ar', 're', 'll', 'ed']},\n",
       " '▁angrily': {'freq': 9, 'swords': ['▁an', 'g', 'ri', 'ly']},\n",
       " '▁broke': {'freq': 46, 'swords': ['▁b', 'ro', 'ke']},\n",
       " '▁tents': {'freq': 47, 'swords': ['▁t', 'ent', 's']},\n",
       " '▁Menoetius': {'freq': 33, 'swords': ['▁M', 'en', 'o', 'et', 'i', 'us']},\n",
       " '▁company': {'freq': 22, 'swords': ['▁c', 'om', 'p', 'an', 'y']},\n",
       " '▁drew': {'freq': 135, 'swords': ['▁d', 're', 'w']},\n",
       " '▁vessel': {'freq': 19, 'swords': ['▁', 've', 's', 'sel']},\n",
       " '▁water': {'freq': 160, 'swords': ['▁w', 'at', 'er']},\n",
       " '▁chose': {'freq': 14, 'swords': ['▁ch', 'o', 'se']},\n",
       " '▁twenty': {'freq': 44, 'swords': ['▁t', 'w', 'ent', 'y']},\n",
       " '▁oarsmen': {'freq': 6, 'swords': ['▁o', 'ar', 's', 'm', 'en']},\n",
       " '▁escorted': {'freq': 3, 'swords': ['▁', 'es', 'c', 'or', 't', 'ed']},\n",
       " '▁sailed': {'freq': 27, 'swords': ['▁sa', 'il', 'ed']},\n",
       " '▁ways': {'freq': 22, 'swords': ['▁w', 'ay', 's']},\n",
       " '▁purify': {'freq': 3, 'swords': ['▁p', 'ur', 'if', 'y']},\n",
       " '▁purified': {'freq': 2, 'swords': ['▁p', 'ur', 'if', 'i', 'ed']},\n",
       " '▁cast': {'freq': 20, 'swords': ['▁c', 'as', 't']},\n",
       " '▁filth': {'freq': 5, 'swords': ['▁f', 'il', 'th']},\n",
       " '▁hecatombs': {'freq': 21, 'swords': ['▁he', 'c', 'at', 'om', 'b', 's']},\n",
       " '▁smoke': {'freq': 18, 'swords': ['▁s', 'm', 'o', 'ke']},\n",
       " '▁curling': {'freq': 1, 'swords': ['▁c', 'ur', 'l', 'ing']},\n",
       " '▁towards': {'freq': 190, 'swords': ['▁to', 'w', 'ard', 's']},\n",
       " '▁busy': {'freq': 21, 'swords': ['▁b', 'us', 'y']},\n",
       " '▁throughout': {'freq': 38, 'swords': ['▁th', 'r', 'ough', 'out']},\n",
       " '▁threat': {'freq': 2, 'swords': ['▁th', 're', 'at']},\n",
       " '▁trusty': {'freq': 7, 'swords': ['▁t', 'r', 'us', 't', 'y']},\n",
       " '▁messengers': {'freq': 9, 'swords': ['▁m', 'es', 's', 'en', 'g', 'er', 's']},\n",
       " '▁squires': {'freq': 9, 'swords': ['▁s', 'q', 'u', 'i', 're', 's']},\n",
       " '▁Talthybius': {'freq': 10,\n",
       "  'swords': ['▁T', 'al', 'th', 'y', 'b', 'i', 'us']},\n",
       " '▁Eurybates': {'freq': 4, 'swords': ['▁', 'E', 'ur', 'y', 'b', 'at', 'es']},\n",
       " '▁bring': {'freq': 144, 'swords': ['▁br', 'ing']},\n",
       " '▁hither': {'freq': 52, 'swords': ['▁h', 'it', 'her']},\n",
       " '▁press': {'freq': 23, 'swords': ['▁p', 're', 's', 's']},\n",
       " '▁harder': {'freq': 7, 'swords': ['▁h', 'ard', 'er']},\n",
       " '▁charged': {'freq': 11, 'swords': ['▁ch', 'ar', 'g', 'ed']},\n",
       " '▁straightly': {'freq': 1, 'swords': ['▁st', 'r', 'a', 'ight', 'ly']},\n",
       " '▁dismissed': {'freq': 4, 'swords': ['▁d', 'is', 'm', 'is', 's', 'ed']},\n",
       " '▁whereon': {'freq': 118, 'swords': ['▁w', 'he', 're', 'on']},\n",
       " '▁sorrowfully': {'freq': 4,\n",
       "  'swords': ['▁s', 'or', 'r', 'ow', 'f', 'u', 'll', 'y']},\n",
       " '▁seaside': {'freq': 2, 'swords': ['▁se', 'as', 'id', 'e']},\n",
       " '▁found': {'freq': 106, 'swords': ['▁f', 'ound']},\n",
       " '▁sitting': {'freq': 51, 'swords': ['▁s', 'it', 't', 'ing']},\n",
       " '▁pleased': {'freq': 25, 'swords': ['▁p', 'le', 'as', 'ed']},\n",
       " '▁beheld': {'freq': 17, 'swords': ['▁be', 'he', 'ld']},\n",
       " '▁stood': {'freq': 165, 'swords': ['▁st', 'o', 'od']},\n",
       " '▁fearfully': {'freq': 6, 'swords': ['▁f', 'ear', 'f', 'u', 'll', 'y']},\n",
       " '▁reverently': {'freq': 1, 'swords': ['▁re', 've', 're', 'n', 't', 'ly']},\n",
       " '▁before': {'freq': 339, 'swords': ['▁be', 'f', 'ore']},\n",
       " '▁Welcome': {'freq': 2, 'swords': ['▁W', 'e', 'l', 'c', 'ome']},\n",
       " '▁heralds': {'freq': 16, 'swords': ['▁her', 'a', 'ld', 's']},\n",
       " '▁near': {'freq': 159, 'swords': ['▁n', 'ear']},\n",
       " '▁Patroclus': {'freq': 177, 'swords': ['▁P', 'at', 'ro', 'c', 'l', 'us']},\n",
       " '▁witnesses': {'freq': 5, 'swords': ['▁w', 'it', 'n', 'es', 'ses']},\n",
       " '▁blessed': {'freq': 36, 'swords': ['▁b', 'l', 'es', 's', 'ed']},\n",
       " '▁mortal': {'freq': 55, 'swords': ['▁m', 'or', 't', 'al']},\n",
       " '▁fierceness': {'freq': 6, 'swords': ['▁f', 'i', 'er', 'c', 'en', 'es', 's']},\n",
       " '▁need': {'freq': 36, 'swords': ['▁n', 'e', 'ed']},\n",
       " '▁save': {'freq': 80, 'swords': ['▁sa', 've']},\n",
       " '▁ruin': {'freq': 20, 'swords': ['▁r', 'u', 'in']},\n",
       " '▁seek': {'freq': 5, 'swords': ['▁se', 'e', 'k']},\n",
       " '▁mad': {'freq': 21, 'swords': ['▁m', 'ad']},\n",
       " '▁knows': {'freq': 30, 'swords': ['▁k', 'n', 'ow', 's']},\n",
       " '▁after': {'freq': 288, 'swords': ['▁a', 'f', 'ter']},\n",
       " '▁dear': {'freq': 110, 'swords': ['▁d', 'ear']},\n",
       " '▁comrade': {'freq': 75, 'swords': ['▁c', 'om', 'r', 'ad', 'e']},\n",
       " '▁bidden': {'freq': 10, 'swords': ['▁b', 'id', 'd', 'en']},\n",
       " '▁woman': {'freq': 110, 'swords': ['▁w', 'om', 'an']},\n",
       " '▁loth': {'freq': 13, 'swords': ['▁l', 'ot', 'h']},\n",
       " '▁hoar': {'freq': 2, 'swords': ['▁h', 'o', 'ar']},\n",
       " '▁weeping': {'freq': 68, 'swords': ['▁we', 'ep', 'ing']},\n",
       " '▁looking': {'freq': 86, 'swords': ['▁l', 'o', 'o', 'k', 'ing']},\n",
       " '▁boundless': {'freq': 1, 'swords': ['▁b', 'ound', 'l', 'es', 's']},\n",
       " '▁waste': {'freq': 12, 'swords': ['▁was', 't', 'e']},\n",
       " '▁waters': {'freq': 60, 'swords': ['▁w', 'at', 'er', 's']},\n",
       " '▁raised': {'freq': 82, 'swords': ['▁r', 'a', 'is', 'ed']},\n",
       " '▁immortal': {'freq': 67, 'swords': ['▁', 'im', 'm', 'or', 't', 'al']},\n",
       " '▁Mother': {'freq': 8, 'swords': ['▁M', 'ot', 'her']},\n",
       " '▁doomed': {'freq': 14, 'swords': ['▁do', 'om', 'ed']},\n",
       " '▁little': {'freq': 80, 'swords': ['▁l', 'it', 't', 'le']},\n",
       " '▁season': {'freq': 9, 'swords': ['▁se', 'as', 'on']},\n",
       " '▁thunders': {'freq': 4, 'swords': ['▁th', 'u', 'nd', 'er', 's']},\n",
       " '▁glorious': {'freq': 20, 'swords': ['▁g', 'l', 'or', 'i', 'ou', 's']},\n",
       " '▁dishonour': {'freq': 8, 'swords': ['▁d', 'is', 'h', 'on', 'our']},\n",
       " '▁robbed': {'freq': 19, 'swords': ['▁r', 'o', 'b', 'b', 'ed']},\n",
       " '▁As': {'freq': 331, 'swords': ['▁A', 's']},\n",
       " '▁wept': {'freq': 43, 'swords': ['▁we', 'p', 't']},\n",
       " '▁aloud': {'freq': 42, 'swords': ['▁a', 'l', 'ou', 'd']},\n",
       " '▁where': {'freq': 337, 'swords': ['▁w', 'he', 're']},\n",
       " '▁depths': {'freq': 9, 'swords': ['▁de', 'p', 'th', 's']},\n",
       " '▁hard': {'freq': 103, 'swords': ['▁h', 'ard']},\n",
       " '▁Forthwith': {'freq': 18, 'swords': ['▁', 'F', 'or', 'th', 'w', 'ith']},\n",
       " '▁grey': {'freq': 27, 'swords': ['▁g', 're', 'y']},\n",
       " '▁mist': {'freq': 13, 'swords': ['▁m', 'is', 't']},\n",
       " '▁waves': {'freq': 49, 'swords': ['▁w', 'a', 've', 's']},\n",
       " '▁caressed': {'freq': 6, 'swords': ['▁c', 'a', 're', 's', 's', 'ed']},\n",
       " '▁My': {'freq': 140, 'swords': ['▁M', 'y']},\n",
       " '▁grieves': {'freq': 4, 'swords': ['▁g', 'ri', 'e', 've', 's']},\n",
       " '▁Keep': {'freq': 6, 'swords': ['▁', 'K', 'e', 'ep']},\n",
       " '▁deep': {'freq': 59, 'swords': ['▁de', 'ep']},\n",
       " '▁sigh': {'freq': 10, 'swords': ['▁s', 'i', 'gh']},\n",
       " '▁Thebe': {'freq': 4, 'swords': ['▁The', 'b', 'e']},\n",
       " '▁Eetion': {'freq': 11, 'swords': ['▁', 'E', 'et', 'i', 'on']},\n",
       " '▁sacked': {'freq': 32, 'swords': ['▁sa', 'ck', 'ed']},\n",
       " '▁spoil': {'freq': 16, 'swords': ['▁sp', 'o', 'il']},\n",
       " '▁shared': {'freq': 2, 'swords': ['▁sh', 'a', 'red']},\n",
       " '▁duly': {'freq': 6, 'swords': ['▁d', 'u', 'ly']},\n",
       " '▁meed': {'freq': 3, 'swords': ['▁me', 'ed']},\n",
       " '▁dearly': {'freq': 13, 'swords': ['▁d', 'ear', 'ly']},\n",
       " '▁deadly': {'freq': 16, 'swords': ['▁de', 'ad', 'ly']},\n",
       " '▁dart': {'freq': 12, 'swords': ['▁d', 'ar', 't']},\n",
       " '▁died': {'freq': 27, 'swords': ['▁d', 'i', 'ed']},\n",
       " '▁thick': {'freq': 89, 'swords': ['▁th', 'i', 'ck']},\n",
       " '▁everywhither': {'freq': 1,\n",
       "  'swords': ['▁e', 'ver', 'y', 'w', 'h', 'it', 'her']},\n",
       " '▁wide': {'freq': 29, 'swords': ['▁w', 'id', 'e']},\n",
       " '▁At': {'freq': 39, 'swords': ['▁A', 't']},\n",
       " '▁last': {'freq': 74, 'swords': ['▁l', 'as', 't']},\n",
       " '▁fulness': {'freq': 1, 'swords': ['▁f', 'u', 'l', 'n', 'es', 's']},\n",
       " '▁knowledge': {'freq': 10, 'swords': ['▁k', 'n', 'ow', 'l', 'ed', 'g', 'e']},\n",
       " '▁declared': {'freq': 5, 'swords': ['▁de', 'c', 'l', 'a', 'red']},\n",
       " '▁myself': {'freq': 146, 'swords': ['▁my', 'sel', 'f']},\n",
       " '▁Whereon': {'freq': 2, 'swords': ['▁W', 'he', 're', 'on']},\n",
       " '▁threatened': {'freq': 6, 'swords': ['▁th', 're', 'at', 'en', 'ed']},\n",
       " '▁sending': {'freq': 11, 'swords': ['▁se', 'nd', 'ing']},\n",
       " '▁just': {'freq': 107, 'swords': ['▁', 'j', 'us', 't']},\n",
       " '▁taken': {'freq': 106, 'swords': ['▁t', 'a', 'k', 'en']},\n",
       " '▁Briseus': {'freq': 3, 'swords': ['▁', 'B', 'r', 'is', 'e', 'us']},\n",
       " '▁Help': {'freq': 6, 'swords': ['▁He', 'l', 'p']},\n",
       " '▁able': {'freq': 46, 'swords': ['▁ab', 'le']},\n",
       " '▁service': {'freq': 17, 'swords': ['▁s', 'er', 'v', 'i', 'ce']},\n",
       " '▁aid': {'freq': 9, 'swords': ['▁a', 'id']},\n",
       " '▁Ofttimes': {'freq': 1, 'swords': ['▁', 'O', 'f', 't', 't', 'im', 'es']},\n",
       " '▁glory': {'freq': 59, 'swords': ['▁g', 'l', 'or', 'y']},\n",
       " '▁saved': {'freq': 34, 'swords': ['▁sa', 've', 'd']},\n",
       " '▁Saturn': {'freq': 92, 'swords': ['▁S', 'at', 'ur', 'n']},\n",
       " '▁Neptune': {'freq': 120, 'swords': ['▁', 'N', 'ep', 't', 'un', 'e']},\n",
       " '▁Pallas': {'freq': 22, 'swords': ['▁P', 'all', 'as']},\n",
       " '▁bonds': {'freq': 5, 'swords': ['▁b', 'o', 'nd', 's']},\n",
       " '▁delivered': {'freq': 9, 'swords': ['▁de', 'l', 'ive', 'red']},\n",
       " '▁calling': {'freq': 16, 'swords': ['▁c', 'all', 'ing']},\n",
       " '▁hundred': {'freq': 24, 'swords': ['▁h', 'u', 'nd', 'red']},\n",
       " '▁handed': {'freq': 37, 'swords': ['▁ha', 'nd', 'ed']},\n",
       " '▁monster': {'freq': 18, 'swords': ['▁m', 'on', 'st', 'er']},\n",
       " '▁call': {'freq': 51, 'swords': ['▁c', 'all']},\n",
       " '▁Briareus': {'freq': 1, 'swords': ['▁', 'B', 'ri', 'a', 're', 'us']},\n",
       " '▁Aegaeon': {'freq': 1, 'swords': ['▁A', 'e', 'g', 'ae', 'on']},\n",
       " '▁beside': {'freq': 48, 'swords': ['▁b', 'es', 'id', 'e']},\n",
       " '▁afraid': {'freq': 47, 'swords': ['▁a', 'f', 'r', 'a', 'id']},\n",
       " '▁bind': {'freq': 12, 'swords': ['▁b', 'ind']},\n",
       " '▁remind': {'freq': 4, 'swords': ['▁re', 'm', 'ind']},\n",
       " '▁clasp': {'freq': 4, 'swords': ['▁c', 'l', 'as', 'p']},\n",
       " '▁knees': {'freq': 66, 'swords': ['▁k', 'n', 'e', 'es']},\n",
       " '▁succour': {'freq': 3, 'swords': ['▁su', 'c', 'c', 'our']},\n",
       " '▁hemmed': {'freq': 9, 'swords': ['▁he', 'm', 'm', 'ed']},\n",
       " '▁sterns': {'freq': 9, 'swords': ['▁st', 'er', 'n', 's']},\n",
       " '▁perish': {'freq': 32, 'swords': ['▁p', 'er', 'is', 'h']},\n",
       " '▁reap': {'freq': 5, 'swords': ['▁re', 'a', 'p']},\n",
       " '▁joy': {'freq': 17, 'swords': ['▁', 'j', 'o', 'y']},\n",
       " '▁blindness': {'freq': 1, 'swords': ['▁b', 'l', 'ind', 'n', 'es', 's']},\n",
       " '▁offering': {'freq': 41, 'swords': ['▁of', 'f', 'er', 'ing']},\n",
       " '▁Thetis': {'freq': 47, 'swords': ['▁The', 't', 'is']},\n",
       " '▁woe': {'freq': 15, 'swords': ['▁w', 'o', 'e']},\n",
       " '▁suckled': {'freq': 4, 'swords': ['▁su', 'ck', 'l', 'ed']},\n",
       " '▁Would': {'freq': 30, 'swords': ['▁W', 'ould']},\n",
       " '▁indeed': {'freq': 107, 'swords': ['▁', 'ind', 'e', 'ed']},\n",
       " '▁lived': {'freq': 38, 'swords': ['▁l', 'ive', 'd']},\n",
       " '▁span': {'freq': 1, 'swords': ['▁sp', 'an']},\n",
       " '▁brief': {'freq': 3, 'swords': ['▁b', 'ri', 'e', 'f']},\n",
       " '▁alas': {'freq': 4, 'swords': ['▁a', 'l', 'as']},\n",
       " '▁short': {'freq': 20, 'swords': ['▁sh', 'or', 't']},\n",
       " '▁peers': {'freq': 7, 'swords': ['▁p', 'e', 'er', 's']},\n",
       " '▁nevertheless': {'freq': 49,\n",
       "  'swords': ['▁n', 'e', 'ver', 't', 'he', 'l', 'es', 's']},\n",
       " '▁snowy': {'freq': 7, 'swords': ['▁s', 'n', 'ow', 'y']},\n",
       " '▁heights': {'freq': 7, 'swords': ['▁he', 'ight', 's']},\n",
       " '▁tale': {'freq': 20, 'swords': ['▁t', 'a', 'le']},\n",
       " '▁meanwhile': {'freq': 12, 'swords': ['▁me', 'an', 'w', 'h', 'i', 'le']},\n",
       " '▁hold': {'freq': 171, 'swords': ['▁h', 'o', 'ld']},\n",
       " '▁aloof': {'freq': 22, 'swords': ['▁a', 'lo', 'o', 'f']},\n",
       " '▁yesterday': {'freq': 11, 'swords': ['▁y', 'es', 'ter', 'd', 'ay']},\n",
       " '▁Oceanus': {'freq': 37, 'swords': ['▁', 'O', 'ce', 'an', 'us']},\n",
       " '▁feast': {'freq': 30, 'swords': ['▁f', 'e', 'as', 't']},\n",
       " '▁Ethiopians': {'freq': 5,\n",
       "  'swords': ['▁', 'E', 'th', 'i', 'o', 'p', 'i', 'ans']},\n",
       " '▁twelve': {'freq': 68, 'swords': ['▁t', 'w', 'e', 'l', 've']},\n",
       " '▁hence': {'freq': 10, 'swords': ['▁he', 'n', 'ce']},\n",
       " '▁mansion': {'freq': 5, 'swords': ['▁m', 'ans', 'i', 'on']},\n",
       " '▁paved': {'freq': 3, 'swords': ['▁p', 'a', 've', 'd']},\n",
       " '▁bronze': {'freq': 155, 'swords': ['▁br', 'on', 'z', 'e']},\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.words_bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁', 't'], ['h', 'e'], ['▁', 'a'], ['▁t', 'he'], ['▁', 's']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.merge_ops[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation with BPE: Initial Distribution of the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'he', 're', 'f', 'ore']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.encode('therefore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Sit', '▁careless', '▁in', '▁the', '▁shade', '▁!']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.pretokenize('Sit careless in the shade!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁S',\n",
       " 'it',\n",
       " '▁c',\n",
       " 'a',\n",
       " 're',\n",
       " 'l',\n",
       " 'es',\n",
       " 's',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁sh',\n",
       " 'ad',\n",
       " 'e',\n",
       " '▁',\n",
       " '!']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = bpe.tokenize('Sit careless in the shade!')\n",
    "words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = bpe.tokenize(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_nll(tokens):\n",
    "    token_cnts = Counter(tokens)\n",
    "    total_cnt = token_cnts.total()\n",
    "    uni_probs = {token: -log(cnt/total_cnt) for\n",
    "                 token, cnt in token_cnts.items()}\n",
    "    return uni_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.880767285455809"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_probs_bpe = calc_nll(tokens)\n",
    "uni_probs_bpe['her']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram():\n",
    "    def __init__(self, uni_probs):\n",
    "        self.uni_probs = uni_probs\n",
    "        self.pattern = r'\\p{P}|[^\\s\\p{P}]+'\n",
    "\n",
    "    def pretokenize(self, text):\n",
    "        words = re.findall(self.pattern, text)\n",
    "        words = list(map(lambda x: '▁' + x, words))\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = Unigram(uni_probs_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.105016576360653"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.uni_probs['▁t']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation with the Language Model: Brute Force"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see how to split a word in all possible ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram():\n",
    "    def __init__(self, uni_probs):\n",
    "        self.uni_probs = uni_probs\n",
    "        self.pattern = r'\\p{P}|[^\\s\\p{P}]+'\n",
    "\n",
    "    def pretokenize(self, text):\n",
    "        words = re.findall(self.pattern, text)\n",
    "        words = list(map(lambda x: '▁' + x, words))\n",
    "        return words\n",
    "\n",
    "    @staticmethod\n",
    "    def split_word(string, splitpoints):\n",
    "        subwords = []\n",
    "        prev_sp = 0\n",
    "        for i, sp in enumerate(splitpoints, start=1):\n",
    "            if sp == '1':\n",
    "                subword = string[prev_sp:i]\n",
    "                prev_sp = i\n",
    "                subwords.append(subword)\n",
    "        subword = string[prev_sp:]\n",
    "        subwords.append(subword)\n",
    "        return subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['th', 'e', 're']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unigram.split_word('there', '0110')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = '▁there'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁there'],\n",
       " ['▁ther', 'e'],\n",
       " ['▁the', 're'],\n",
       " ['▁the', 'r', 'e'],\n",
       " ['▁th', 'ere'],\n",
       " ['▁th', 'er', 'e'],\n",
       " ['▁th', 'e', 're'],\n",
       " ['▁th', 'e', 'r', 'e'],\n",
       " ['▁t', 'here'],\n",
       " ['▁t', 'her', 'e'],\n",
       " ['▁t', 'he', 're'],\n",
       " ['▁t', 'he', 'r', 'e'],\n",
       " ['▁t', 'h', 'ere'],\n",
       " ['▁t', 'h', 'er', 'e'],\n",
       " ['▁t', 'h', 'e', 're'],\n",
       " ['▁t', 'h', 'e', 'r', 'e'],\n",
       " ['▁', 'there'],\n",
       " ['▁', 'ther', 'e'],\n",
       " ['▁', 'the', 're'],\n",
       " ['▁', 'the', 'r', 'e'],\n",
       " ['▁', 'th', 'ere'],\n",
       " ['▁', 'th', 'er', 'e'],\n",
       " ['▁', 'th', 'e', 're'],\n",
       " ['▁', 'th', 'e', 'r', 'e'],\n",
       " ['▁', 't', 'here'],\n",
       " ['▁', 't', 'her', 'e'],\n",
       " ['▁', 't', 'he', 're'],\n",
       " ['▁', 't', 'he', 'r', 'e'],\n",
       " ['▁', 't', 'h', 'ere'],\n",
       " ['▁', 't', 'h', 'er', 'e'],\n",
       " ['▁', 't', 'h', 'e', 're'],\n",
       " ['▁', 't', 'h', 'e', 'r', 'e']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_sp = len(word) - 1\n",
    "candidates = []\n",
    "for i in range(2**cnt_sp):\n",
    "    splitpoints = f'{i:0{cnt_sp}b}'\n",
    "    candidates += [Unigram.split_word(word, splitpoints)]\n",
    "candidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute all the probabilities and we keep the min negative log likelihood (NLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁there'], 6.563964135162586)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([(cand,\n",
    "      sum(map(lambda x: uni_probs_bpe.get(x, 1000), cand)))\n",
    "     for cand in candidates], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram():\n",
    "    def __init__(self, uni_probs):\n",
    "        self.uni_probs = uni_probs\n",
    "        self.pattern = r'\\p{P}|[^\\s\\p{P}]+'\n",
    "\n",
    "    def pretokenize(self, text):\n",
    "        words = re.findall(self.pattern, text)\n",
    "        words = list(map(lambda x: '▁' + x, words))\n",
    "        return words\n",
    "\n",
    "    @staticmethod\n",
    "    def split_word(string, splitpoints):\n",
    "        subwords = []\n",
    "        prev_sp = 0\n",
    "        for i, sp in enumerate(splitpoints, start=1):\n",
    "            if sp == '1':\n",
    "                subword = string[prev_sp:i]\n",
    "                prev_sp = i\n",
    "                subwords.append(subword)\n",
    "        subword = string[prev_sp:]\n",
    "        subwords.append(subword)\n",
    "        return subwords\n",
    "\n",
    "    def encode(self, word):\n",
    "        cnt_sp = len(word) - 1\n",
    "        if cnt_sp > 20:\n",
    "            return list(word)\n",
    "        candidates = []\n",
    "        for i in range(2**cnt_sp):\n",
    "            splitpoints = f'{i:0{cnt_sp}b}'\n",
    "            candidates += [Unigram.split_word(word, splitpoints)]\n",
    "        return min(\n",
    "            [(cand,\n",
    "              sum(map(lambda x: self.uni_probs.get(x, 1000), cand))\n",
    "              ) for cand in candidates],\n",
    "            key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = Unigram(uni_probs_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ther', 'e'], 10.395533624170854)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁there'], 6.563964135162586)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('▁there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁the', 'x', 're', 'x', 'x'], 28.163451667610353)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('▁thexrexx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁with'], 5.3599913308366505)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('▁with')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram():\n",
    "    def __init__(self, uni_probs):\n",
    "        self.uni_probs = uni_probs\n",
    "        self.pattern = r'\\p{P}|[^\\s\\p{P}]+'\n",
    "\n",
    "    def pretokenize(self, text):\n",
    "        words = re.findall(self.pattern, text)\n",
    "        words = list(map(lambda x: '▁' + x, words))\n",
    "        return words\n",
    "\n",
    "    @staticmethod\n",
    "    def split_word(string, splitpoints):\n",
    "        subwords = []\n",
    "        prev_sp = 0\n",
    "        for i, sp in enumerate(splitpoints, start=1):\n",
    "            if sp == '1':\n",
    "                subword = string[prev_sp:i]\n",
    "                prev_sp = i\n",
    "                subwords.append(subword)\n",
    "        subword = string[prev_sp:]\n",
    "        subwords.append(subword)\n",
    "        return subwords\n",
    "\n",
    "    def encode(self, word):\n",
    "        cnt_sp = len(word) - 1\n",
    "        if cnt_sp > 20:\n",
    "            return list(word)\n",
    "        candidates = []\n",
    "        for i in range(2**cnt_sp):\n",
    "            splitpoints = f'{i:0{cnt_sp}b}'\n",
    "            candidates += [Unigram.split_word(word, splitpoints)]\n",
    "        return min(\n",
    "            [(cand,\n",
    "              sum(map(lambda x: self.uni_probs.get(x, 1000), cand))\n",
    "              ) for cand in candidates],\n",
    "            key=lambda x: x[1])\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        cache = {}\n",
    "        nll_text = 0.0\n",
    "        tokenized_text = []\n",
    "        words = self.pretokenize(text)\n",
    "        for word in tqdm(words):\n",
    "            if word not in cache:\n",
    "                cache[word] = self.encode(word)\n",
    "            subwords, nll = cache[word]\n",
    "            tokenized_text += subwords\n",
    "            nll_text += nll\n",
    "        return tokenized_text, nll_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ther', 'e'], 10.395533624170854)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram = Unigram(uni_probs_bpe)\n",
    "unigram.encode('there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10911.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['▁S',\n",
       "  'it',\n",
       "  '▁c',\n",
       "  'a',\n",
       "  're',\n",
       "  'le',\n",
       "  's',\n",
       "  's',\n",
       "  '▁in',\n",
       "  '▁the',\n",
       "  '▁sh',\n",
       "  'ad',\n",
       "  'e'],\n",
       " 61.740722053383436)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.tokenize('Sit careless in the shade')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize the text with the brute-force algorithm. Crashes half-way with the dickens corpus if there is not length limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312886/312886 [00:05<00:00, 55101.10it/s] \n"
     ]
    }
   ],
   "source": [
    "unigram = Unigram(uni_probs_bpe)\n",
    "tokens_bf = unigram.tokenize(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'K',\n",
       " '▁I',\n",
       " '▁S',\n",
       " 'ing',\n",
       " '▁,',\n",
       " '▁',\n",
       " 'O',\n",
       " '▁go',\n",
       " 'd',\n",
       " 'd',\n",
       " 'es',\n",
       " 's',\n",
       " '▁,',\n",
       " '▁the',\n",
       " '▁an',\n",
       " 'g',\n",
       " 'er',\n",
       " '▁of',\n",
       " '▁Ach',\n",
       " 'ill',\n",
       " 'es',\n",
       " '▁son',\n",
       " '▁of',\n",
       " '▁P',\n",
       " 'e',\n",
       " 'le',\n",
       " 'us',\n",
       " '▁,',\n",
       " '▁that',\n",
       " '▁br',\n",
       " 'ough',\n",
       " 't',\n",
       " '▁c',\n",
       " 'ou',\n",
       " 'n',\n",
       " 't',\n",
       " 'le',\n",
       " 's',\n",
       " 's',\n",
       " '▁',\n",
       " 'ill',\n",
       " 's',\n",
       " '▁up',\n",
       " 'on',\n",
       " '▁the',\n",
       " '▁Ach',\n",
       " 'ae',\n",
       " 'ans',\n",
       " '▁.',\n",
       " '▁M',\n",
       " 'an',\n",
       " 'y',\n",
       " '▁a',\n",
       " '▁br',\n",
       " 'a',\n",
       " 've',\n",
       " '▁s',\n",
       " 'ou',\n",
       " 'l',\n",
       " '▁d',\n",
       " 'id',\n",
       " '▁it',\n",
       " '▁se',\n",
       " 'nd',\n",
       " '▁h',\n",
       " 'ur',\n",
       " 'r',\n",
       " 'y',\n",
       " 'ing',\n",
       " '▁d',\n",
       " 'ow',\n",
       " 'n',\n",
       " '▁to',\n",
       " '▁H',\n",
       " 'ad',\n",
       " 'es',\n",
       " '▁,',\n",
       " '▁and',\n",
       " '▁man',\n",
       " 'y',\n",
       " '▁a',\n",
       " '▁her',\n",
       " 'o',\n",
       " '▁d',\n",
       " 'id',\n",
       " '▁it',\n",
       " '▁y',\n",
       " 'ie',\n",
       " 'ld',\n",
       " '▁a',\n",
       " '▁p',\n",
       " 're',\n",
       " 'y',\n",
       " '▁to',\n",
       " '▁do',\n",
       " 'g',\n",
       " 's',\n",
       " '▁and',\n",
       " '▁',\n",
       " 'v',\n",
       " 'u',\n",
       " 'l',\n",
       " 't',\n",
       " 'ur',\n",
       " 'es',\n",
       " '▁,',\n",
       " '▁for',\n",
       " '▁so',\n",
       " '▁were',\n",
       " '▁the',\n",
       " '▁c',\n",
       " 'ou',\n",
       " 'n',\n",
       " 'sel',\n",
       " 's',\n",
       " '▁of',\n",
       " '▁',\n",
       " 'J',\n",
       " 'ove',\n",
       " '▁f',\n",
       " 'u',\n",
       " 'l',\n",
       " 'f',\n",
       " 'ill',\n",
       " 'ed',\n",
       " '▁from',\n",
       " '▁the',\n",
       " '▁d',\n",
       " 'ay',\n",
       " '▁on',\n",
       " '▁whi',\n",
       " 'ch',\n",
       " '▁the',\n",
       " '▁son',\n",
       " '▁of',\n",
       " '▁A',\n",
       " 't',\n",
       " 're',\n",
       " 'us',\n",
       " '▁,',\n",
       " '▁k',\n",
       " 'ing',\n",
       " '▁of',\n",
       " '▁m',\n",
       " 'en',\n",
       " '▁,',\n",
       " '▁and',\n",
       " '▁g',\n",
       " 're',\n",
       " 'at',\n",
       " '▁Ach',\n",
       " 'ill',\n",
       " 'es',\n",
       " '▁,',\n",
       " '▁f',\n",
       " 'ir',\n",
       " 'st',\n",
       " '▁f',\n",
       " 'ell',\n",
       " '▁',\n",
       " 'out',\n",
       " '▁with',\n",
       " '▁one',\n",
       " '▁an',\n",
       " 'o',\n",
       " 'ther',\n",
       " '▁.',\n",
       " '▁A',\n",
       " 'nd',\n",
       " '▁whi',\n",
       " 'ch',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁go',\n",
       " 'd',\n",
       " 's',\n",
       " '▁was',\n",
       " '▁it',\n",
       " '▁that',\n",
       " '▁se',\n",
       " 't',\n",
       " '▁them',\n",
       " '▁on',\n",
       " '▁to',\n",
       " '▁',\n",
       " 'q',\n",
       " 'u',\n",
       " 'ar',\n",
       " 're',\n",
       " 'l',\n",
       " '▁',\n",
       " '?',\n",
       " '▁I',\n",
       " 't',\n",
       " '▁was',\n",
       " '▁the',\n",
       " '▁son',\n",
       " '▁of',\n",
       " '▁',\n",
       " 'J',\n",
       " 'ove',\n",
       " '▁and',\n",
       " '▁',\n",
       " 'L',\n",
       " 'et',\n",
       " 'o',\n",
       " '▁;',\n",
       " '▁for',\n",
       " '▁he',\n",
       " '▁was',\n",
       " '▁an',\n",
       " 'g',\n",
       " 'r',\n",
       " 'y',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁k',\n",
       " 'ing',\n",
       " '▁and',\n",
       " '▁s',\n",
       " 'ent',\n",
       " '▁a',\n",
       " '▁p',\n",
       " 'est',\n",
       " 'il',\n",
       " 'en',\n",
       " 'ce',\n",
       " '▁up',\n",
       " 'on',\n",
       " '▁the',\n",
       " '▁h',\n",
       " 'o',\n",
       " 'st',\n",
       " '▁to',\n",
       " '▁p',\n",
       " 'l',\n",
       " 'a',\n",
       " 'g',\n",
       " 'u',\n",
       " 'e',\n",
       " '▁the',\n",
       " '▁p',\n",
       " 'e',\n",
       " 'o',\n",
       " 'p',\n",
       " 'le',\n",
       " '▁,',\n",
       " '▁be',\n",
       " 'c',\n",
       " 'a',\n",
       " 'us',\n",
       " 'e',\n",
       " '▁the',\n",
       " '▁son',\n",
       " '▁of',\n",
       " '▁A',\n",
       " 't',\n",
       " 're',\n",
       " 'us',\n",
       " '▁had',\n",
       " '▁d',\n",
       " 'is',\n",
       " 'h',\n",
       " 'on',\n",
       " 'our',\n",
       " 'ed',\n",
       " '▁',\n",
       " 'C',\n",
       " 'h',\n",
       " 'r',\n",
       " 'y',\n",
       " 'ses',\n",
       " '▁his',\n",
       " '▁p',\n",
       " 'ri',\n",
       " 'est',\n",
       " '▁.',\n",
       " '▁',\n",
       " 'N',\n",
       " 'ow',\n",
       " '▁',\n",
       " 'C',\n",
       " 'h',\n",
       " 'r',\n",
       " 'y',\n",
       " 'ses',\n",
       " '▁had',\n",
       " '▁c',\n",
       " 'ome',\n",
       " '▁to',\n",
       " '▁the',\n",
       " '▁ship',\n",
       " 's',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁Ach',\n",
       " 'ae',\n",
       " 'ans',\n",
       " '▁to',\n",
       " '▁f',\n",
       " 're',\n",
       " 'e',\n",
       " '▁his',\n",
       " '▁d',\n",
       " 'a',\n",
       " 'u',\n",
       " 'ght',\n",
       " 'er',\n",
       " '▁,',\n",
       " '▁and',\n",
       " '▁had',\n",
       " '▁br',\n",
       " 'ough',\n",
       " 't',\n",
       " '▁with',\n",
       " '▁him',\n",
       " '▁a',\n",
       " '▁g',\n",
       " 're',\n",
       " 'at',\n",
       " '▁r',\n",
       " 'ans',\n",
       " 'om',\n",
       " '▁',\n",
       " ':',\n",
       " '▁m',\n",
       " 'ore',\n",
       " 'o',\n",
       " 'ver',\n",
       " '▁he',\n",
       " '▁b',\n",
       " 'ore',\n",
       " '▁in',\n",
       " '▁his',\n",
       " '▁ha',\n",
       " 'nd',\n",
       " '▁the',\n",
       " '▁s',\n",
       " 'ce',\n",
       " 'p',\n",
       " 't',\n",
       " 're',\n",
       " '▁of',\n",
       " '▁A',\n",
       " 'p',\n",
       " 'o',\n",
       " 'll',\n",
       " 'o',\n",
       " '▁w',\n",
       " 're',\n",
       " 'at',\n",
       " 'h',\n",
       " 'ed',\n",
       " '▁with',\n",
       " '▁a',\n",
       " '▁su',\n",
       " 'p',\n",
       " 'p',\n",
       " 'l',\n",
       " 'i',\n",
       " 'an',\n",
       " 't',\n",
       " \"▁'\",\n",
       " '▁s',\n",
       " '▁w',\n",
       " 're',\n",
       " 'at',\n",
       " 'h',\n",
       " '▁and',\n",
       " '▁he',\n",
       " '▁be',\n",
       " 's',\n",
       " 'ough',\n",
       " 't',\n",
       " '▁the',\n",
       " '▁Ach',\n",
       " 'ae',\n",
       " 'ans',\n",
       " '▁,',\n",
       " '▁but',\n",
       " '▁m',\n",
       " 'o',\n",
       " 'st',\n",
       " '▁of',\n",
       " '▁all',\n",
       " '▁the',\n",
       " '▁t',\n",
       " 'w',\n",
       " 'o',\n",
       " '▁son',\n",
       " 's',\n",
       " '▁of',\n",
       " '▁A',\n",
       " 't',\n",
       " 're',\n",
       " 'us',\n",
       " '▁,',\n",
       " '▁who',\n",
       " '▁were',\n",
       " '▁their',\n",
       " '▁ch',\n",
       " 'ie',\n",
       " 'f',\n",
       " 's',\n",
       " '▁.',\n",
       " '▁\"',\n",
       " '▁S',\n",
       " 'on',\n",
       " 's',\n",
       " '▁of',\n",
       " '▁A',\n",
       " 't',\n",
       " 're',\n",
       " 'us',\n",
       " '▁,',\n",
       " '▁\"',\n",
       " '▁he',\n",
       " '▁c',\n",
       " 'ri',\n",
       " 'ed',\n",
       " '▁,',\n",
       " '▁\"',\n",
       " '▁and',\n",
       " '▁all',\n",
       " '▁o',\n",
       " 'ther',\n",
       " '▁Ach',\n",
       " 'ae',\n",
       " 'ans',\n",
       " '▁,',\n",
       " '▁m',\n",
       " 'ay',\n",
       " '▁the',\n",
       " '▁go',\n",
       " 'd',\n",
       " 's',\n",
       " '▁who',\n",
       " '▁d',\n",
       " 'w',\n",
       " 'ell',\n",
       " '▁in',\n",
       " '▁',\n",
       " 'O',\n",
       " 'ly',\n",
       " 'm',\n",
       " 'p',\n",
       " 'us',\n",
       " '▁g',\n",
       " 'r',\n",
       " 'an',\n",
       " 't',\n",
       " '▁you',\n",
       " '▁to',\n",
       " '▁sa',\n",
       " 'ck',\n",
       " '▁the',\n",
       " '▁c',\n",
       " 'it',\n",
       " 'y',\n",
       " '▁of',\n",
       " '▁P',\n",
       " 'ri',\n",
       " 'am',\n",
       " '▁,',\n",
       " '▁and',\n",
       " '▁to',\n",
       " '▁re',\n",
       " 'a',\n",
       " 'ch',\n",
       " '▁your',\n",
       " '▁h',\n",
       " 'ome',\n",
       " 's',\n",
       " '▁in',\n",
       " '▁sa',\n",
       " 'f',\n",
       " 'et',\n",
       " 'y',\n",
       " '▁;',\n",
       " '▁but',\n",
       " '▁f',\n",
       " 're',\n",
       " 'e',\n",
       " '▁my',\n",
       " '▁d',\n",
       " 'a',\n",
       " 'u',\n",
       " 'ght',\n",
       " 'er',\n",
       " '▁,',\n",
       " '▁and',\n",
       " '▁a',\n",
       " 'c',\n",
       " 'ce',\n",
       " 'p',\n",
       " 't',\n",
       " '▁a',\n",
       " '▁r',\n",
       " 'ans',\n",
       " 'om',\n",
       " '▁for',\n",
       " '▁her',\n",
       " '▁,',\n",
       " '▁in',\n",
       " '▁re',\n",
       " 'ver',\n",
       " 'en',\n",
       " 'ce',\n",
       " '▁to',\n",
       " '▁A',\n",
       " 'p',\n",
       " 'o',\n",
       " 'll',\n",
       " 'o',\n",
       " '▁,',\n",
       " '▁son',\n",
       " '▁of',\n",
       " '▁',\n",
       " 'J',\n",
       " 'ove',\n",
       " '▁.',\n",
       " '▁\"',\n",
       " '▁',\n",
       " 'O',\n",
       " 'n',\n",
       " '▁this',\n",
       " '▁the',\n",
       " '▁re',\n",
       " 'st',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁Ach',\n",
       " 'ae',\n",
       " 'ans',\n",
       " '▁with',\n",
       " '▁one',\n",
       " '▁',\n",
       " 'v',\n",
       " 'o',\n",
       " 'i',\n",
       " 'ce',\n",
       " '▁were',\n",
       " '▁for',\n",
       " '▁re',\n",
       " 's',\n",
       " 'p',\n",
       " 'e',\n",
       " 'ct',\n",
       " 'ing',\n",
       " '▁the',\n",
       " '▁p',\n",
       " 'ri',\n",
       " 'est',\n",
       " '▁and',\n",
       " '▁t',\n",
       " 'a',\n",
       " 'k',\n",
       " 'ing',\n",
       " '▁the',\n",
       " '▁r',\n",
       " 'ans',\n",
       " 'om',\n",
       " '▁that',\n",
       " '▁he',\n",
       " '▁of',\n",
       " 'f',\n",
       " 'er',\n",
       " 'ed',\n",
       " '▁;',\n",
       " '▁but',\n",
       " '▁not',\n",
       " '▁so',\n",
       " '▁A',\n",
       " 'g',\n",
       " 'ame',\n",
       " 'm',\n",
       " 'n',\n",
       " 'on',\n",
       " '▁,',\n",
       " '▁who',\n",
       " '▁sp',\n",
       " 'o',\n",
       " 'ke',\n",
       " '▁f',\n",
       " 'i',\n",
       " 'er',\n",
       " 'ce',\n",
       " 'ly',\n",
       " '▁to',\n",
       " '▁him',\n",
       " '▁and',\n",
       " '▁s',\n",
       " 'ent',\n",
       " '▁him',\n",
       " '▁r',\n",
       " 'ough',\n",
       " 'ly',\n",
       " '▁a',\n",
       " 'w',\n",
       " 'ay',\n",
       " '▁.',\n",
       " '▁\"',\n",
       " '▁',\n",
       " 'O',\n",
       " 'ld',\n",
       " '▁man',\n",
       " '▁,',\n",
       " '▁\"',\n",
       " '▁said',\n",
       " '▁he',\n",
       " '▁,',\n",
       " '▁\"',\n",
       " '▁le',\n",
       " 't',\n",
       " '▁me',\n",
       " '▁not',\n",
       " '▁f',\n",
       " 'ind',\n",
       " '▁you',\n",
       " '▁t',\n",
       " 'ar',\n",
       " 'r',\n",
       " 'y',\n",
       " 'ing',\n",
       " '▁ab',\n",
       " 'out',\n",
       " '▁',\n",
       " 'our',\n",
       " '▁ship',\n",
       " 's',\n",
       " '▁,',\n",
       " '▁n',\n",
       " 'or',\n",
       " '▁y',\n",
       " 'et',\n",
       " '▁c',\n",
       " 'om',\n",
       " 'ing',\n",
       " '▁he',\n",
       " 're',\n",
       " 'a',\n",
       " 'f',\n",
       " 'ter',\n",
       " '▁.',\n",
       " '▁',\n",
       " 'Y',\n",
       " 'our',\n",
       " '▁s',\n",
       " 'ce',\n",
       " 'p',\n",
       " 't',\n",
       " 're',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁go',\n",
       " 'd',\n",
       " '▁and',\n",
       " '▁your',\n",
       " '▁w',\n",
       " 're',\n",
       " 'at',\n",
       " 'h',\n",
       " '▁sh',\n",
       " 'all',\n",
       " '▁p',\n",
       " 'ro',\n",
       " 'f',\n",
       " 'it',\n",
       " '▁you',\n",
       " '▁not',\n",
       " 'h',\n",
       " 'ing',\n",
       " '▁.',\n",
       " '▁I',\n",
       " '▁will',\n",
       " '▁not',\n",
       " '▁f',\n",
       " 're',\n",
       " 'e',\n",
       " '▁her',\n",
       " '▁.',\n",
       " '▁S',\n",
       " 'he',\n",
       " '▁sh',\n",
       " 'all',\n",
       " '▁g',\n",
       " 'r',\n",
       " 'ow',\n",
       " '▁o',\n",
       " 'ld',\n",
       " '▁in',\n",
       " '▁my',\n",
       " '▁h',\n",
       " 'ou',\n",
       " 'se',\n",
       " '▁at',\n",
       " '▁A',\n",
       " 'r',\n",
       " 'g',\n",
       " 'o',\n",
       " 's',\n",
       " '▁f',\n",
       " 'ar',\n",
       " '▁from',\n",
       " '▁her',\n",
       " '▁',\n",
       " 'ow',\n",
       " 'n',\n",
       " '▁h',\n",
       " 'ome',\n",
       " '▁,',\n",
       " '▁b',\n",
       " 'us',\n",
       " 'y',\n",
       " 'ing',\n",
       " '▁her',\n",
       " 'sel',\n",
       " 'f',\n",
       " '▁with',\n",
       " '▁her',\n",
       " '▁l',\n",
       " 'o',\n",
       " 'om',\n",
       " '▁and',\n",
       " '▁',\n",
       " 'v',\n",
       " 'is',\n",
       " 'it',\n",
       " 'ing',\n",
       " '▁my',\n",
       " '▁c',\n",
       " 'ou',\n",
       " 'ch',\n",
       " '▁;',\n",
       " '▁so',\n",
       " '▁go',\n",
       " '▁,',\n",
       " '▁and',\n",
       " '▁do',\n",
       " '▁not',\n",
       " '▁p',\n",
       " 'ro',\n",
       " 'v',\n",
       " 'o',\n",
       " 'ke',\n",
       " '▁me',\n",
       " '▁or',\n",
       " '▁it',\n",
       " '▁sh',\n",
       " 'all',\n",
       " '▁be',\n",
       " '▁the',\n",
       " '▁w',\n",
       " 'or',\n",
       " 'se',\n",
       " '▁for',\n",
       " '▁you',\n",
       " '▁.',\n",
       " '▁\"',\n",
       " '▁The',\n",
       " '▁o',\n",
       " 'ld',\n",
       " '▁man',\n",
       " '▁f',\n",
       " 'ear',\n",
       " 'ed',\n",
       " '▁him',\n",
       " '▁and',\n",
       " '▁o',\n",
       " 'b',\n",
       " 'e',\n",
       " 'y',\n",
       " 'ed',\n",
       " '▁.',\n",
       " '▁',\n",
       " 'N',\n",
       " 'ot',\n",
       " '▁a',\n",
       " '▁w',\n",
       " 'or',\n",
       " 'd',\n",
       " '▁he',\n",
       " '▁sp',\n",
       " 'o',\n",
       " 'ke',\n",
       " '▁,',\n",
       " '▁but',\n",
       " '▁w',\n",
       " 'ent',\n",
       " '▁by',\n",
       " '▁the',\n",
       " '▁sh',\n",
       " 'ore',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁s',\n",
       " 'ound',\n",
       " 'ing',\n",
       " '▁se',\n",
       " 'a',\n",
       " '▁and',\n",
       " '▁p',\n",
       " 'r',\n",
       " 'ay',\n",
       " 'ed',\n",
       " '▁a',\n",
       " 'p',\n",
       " 'ar',\n",
       " 't',\n",
       " '▁to',\n",
       " '▁',\n",
       " 'K',\n",
       " 'ing',\n",
       " '▁A',\n",
       " 'p',\n",
       " 'o',\n",
       " 'll',\n",
       " 'o',\n",
       " '▁who',\n",
       " 'm',\n",
       " '▁l',\n",
       " 'ove',\n",
       " 'ly',\n",
       " '▁',\n",
       " 'L',\n",
       " 'et',\n",
       " 'o',\n",
       " '▁had',\n",
       " '▁b',\n",
       " 'or',\n",
       " 'n',\n",
       " 'e',\n",
       " '▁.',\n",
       " '▁\"',\n",
       " '▁He',\n",
       " 'ar',\n",
       " '▁me',\n",
       " '▁,',\n",
       " '▁\"',\n",
       " '▁he',\n",
       " '▁c',\n",
       " 'ri',\n",
       " 'ed',\n",
       " '▁,',\n",
       " '▁\"',\n",
       " '▁',\n",
       " 'O',\n",
       " '▁go',\n",
       " 'd',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁s',\n",
       " 'il',\n",
       " 'ver',\n",
       " '▁b',\n",
       " 'ow',\n",
       " '▁,',\n",
       " '▁that',\n",
       " '▁p',\n",
       " 'ro',\n",
       " 't',\n",
       " 'e',\n",
       " 'ct',\n",
       " 'est',\n",
       " '▁',\n",
       " 'C',\n",
       " 'h',\n",
       " 'r',\n",
       " 'y',\n",
       " 'se',\n",
       " '▁and',\n",
       " '▁h',\n",
       " 'o',\n",
       " 'ly',\n",
       " '▁',\n",
       " 'C',\n",
       " 'ill',\n",
       " 'a',\n",
       " '▁and',\n",
       " '▁r',\n",
       " 'u',\n",
       " 'le',\n",
       " 'st',\n",
       " '▁T',\n",
       " 'en',\n",
       " 'ed',\n",
       " 'o',\n",
       " 's',\n",
       " '▁with',\n",
       " '▁th',\n",
       " 'y',\n",
       " '▁m',\n",
       " 'ight',\n",
       " '▁,',\n",
       " '▁he',\n",
       " 'ar',\n",
       " '▁me',\n",
       " '▁o',\n",
       " 'h',\n",
       " '▁th',\n",
       " 'ou',\n",
       " '▁of',\n",
       " '▁S',\n",
       " 'm',\n",
       " 'in',\n",
       " 't',\n",
       " 'he',\n",
       " '▁.',\n",
       " '▁I',\n",
       " 'f',\n",
       " '▁I',\n",
       " '▁have',\n",
       " '▁e',\n",
       " 'ver',\n",
       " '▁de',\n",
       " 'ck',\n",
       " 'ed',\n",
       " '▁your',\n",
       " '▁t',\n",
       " 'e',\n",
       " 'm',\n",
       " 'p',\n",
       " 'le',\n",
       " '▁with',\n",
       " '▁g',\n",
       " 'ar',\n",
       " 'l',\n",
       " 'and',\n",
       " 's',\n",
       " '▁,',\n",
       " '▁or',\n",
       " '▁b',\n",
       " 'ur',\n",
       " 'n',\n",
       " 'ed',\n",
       " '▁your',\n",
       " '▁th',\n",
       " 'i',\n",
       " 'gh',\n",
       " '▁-',\n",
       " '▁b',\n",
       " 'on',\n",
       " 'es',\n",
       " '▁in',\n",
       " '▁f',\n",
       " 'at',\n",
       " '▁of',\n",
       " '▁b',\n",
       " 'u',\n",
       " 'll',\n",
       " 's',\n",
       " '▁or',\n",
       " '▁go',\n",
       " 'at',\n",
       " 's',\n",
       " '▁,',\n",
       " '▁g',\n",
       " 'r',\n",
       " 'an',\n",
       " 't',\n",
       " '▁my',\n",
       " '▁p',\n",
       " 'r',\n",
       " 'ay',\n",
       " 'er',\n",
       " '▁,',\n",
       " '▁and',\n",
       " '▁le',\n",
       " 't',\n",
       " '▁your',\n",
       " '▁a',\n",
       " 'r',\n",
       " 'r',\n",
       " 'ow',\n",
       " 's',\n",
       " '▁a',\n",
       " 'ven',\n",
       " 'g',\n",
       " 'e',\n",
       " '▁the',\n",
       " 'se',\n",
       " '▁my',\n",
       " '▁t',\n",
       " 'ear',\n",
       " 's',\n",
       " '▁up',\n",
       " 'on',\n",
       " '▁the',\n",
       " '▁',\n",
       " 'D',\n",
       " 'an',\n",
       " 'a',\n",
       " 'ans',\n",
       " '▁.',\n",
       " '▁\"',\n",
       " '▁T',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_bf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation with the Language Model: Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.105016576360653, 5.245661261179482, 5.56798617894901)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_probs_bpe['▁t'], uni_probs_bpe['h'], uni_probs_bpe['▁th']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram():\n",
    "    def __init__(self, uni_probs):\n",
    "        self.uni_probs = uni_probs\n",
    "        self.pattern = r'\\p{P}|[^\\s\\p{P}]+'\n",
    "\n",
    "    def pretokenize(self, text):\n",
    "        words = re.findall(self.pattern, text)\n",
    "        words = list(map(lambda x: '▁' + x, words))\n",
    "        return words\n",
    "\n",
    "    @staticmethod\n",
    "    def split_word(string, splitpoints):\n",
    "        subwords = []\n",
    "        prev_sp = 0\n",
    "        for i, sp in enumerate(splitpoints, start=1):\n",
    "            if sp == '1':\n",
    "                subword = string[prev_sp:i]\n",
    "                prev_sp = i\n",
    "                subwords.append(subword)\n",
    "        subword = string[prev_sp:]\n",
    "        subwords.append(subword)\n",
    "        return subwords\n",
    "\n",
    "    def encode_bf(self, word):\n",
    "        cnt_sp = len(word) - 1\n",
    "        if cnt_sp > 20:\n",
    "            return list(word)\n",
    "        candidates = []\n",
    "        for i in range(2**cnt_sp):\n",
    "            splitpoints = f'{i:0{cnt_sp}b}'\n",
    "            candidates += [Unigram.split_word(word, splitpoints)]\n",
    "        return min(\n",
    "            [(cand,\n",
    "              sum(map(lambda x: self.uni_probs.get(x, 1000), cand))\n",
    "              ) for cand in candidates],\n",
    "            key=lambda x: x[1])\n",
    "\n",
    "    def encode(self, word):\n",
    "        n = len(word)\n",
    "        swords = [word[:i] for i in range(1, n + 1)]\n",
    "        min_nlls = [self.uni_probs.get(sword, 1000.0) for sword in swords]\n",
    "\n",
    "        for i in range(2, n + 1):\n",
    "            for j in range(1, i):\n",
    "                sword = word[j:i]\n",
    "                nll = self.uni_probs.get(sword, 1000.0) + min_nlls[j - 1]\n",
    "                if min_nlls[i - 1] > nll:\n",
    "                    min_nlls[i - 1] = nll\n",
    "                    swords[i - 1] = sword\n",
    "        # backtrace\n",
    "        final_swords = [swords.pop()]\n",
    "        while True:\n",
    "            for i in range(len(final_swords[-1]) - 1):\n",
    "                swords.pop()\n",
    "            if swords:\n",
    "                final_swords += [swords.pop()]\n",
    "            else:\n",
    "                break\n",
    "        return final_swords[::-1], min_nlls[-1]\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        cache = {}\n",
    "        nll_text = 0.0\n",
    "        tokenized_text = []\n",
    "        words = self.pretokenize(text)\n",
    "        for word in tqdm(words):\n",
    "            if word not in cache:\n",
    "                cache[word] = self.encode(word)\n",
    "            subwords, nll = cache[word]\n",
    "            tokenized_text += subwords\n",
    "            nll_text += nll\n",
    "        return tokenized_text, nll_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = Unigram(uni_probs_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ther', 'e'], 10.395533624170854)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 79137.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['▁S',\n",
       "  'it',\n",
       "  '▁c',\n",
       "  'a',\n",
       "  're',\n",
       "  'le',\n",
       "  's',\n",
       "  's',\n",
       "  '▁in',\n",
       "  '▁the',\n",
       "  '▁sh',\n",
       "  'ad',\n",
       "  'e'],\n",
       " 61.740722053383436)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.tokenize('Sit careless in the shade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁the', 'x', 're', 'x', 'f', 'ore'], 32.56230540341623)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('▁thexrexfore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁with'], 5.3599913308366505)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('▁with')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312886/312886 [00:00<00:00, 1601948.94it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens_viterbi = unigram.tokenize(text)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the tokenization of Viterbi and brute force. This should be true if the length of the words is less than 20 chars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_viterbi == tokens_bf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norvig's Method\n",
    "See reference here: https://github.com/norvig/pytudes/blob/main/ipynb/How%20to%20Do%20Things%20with%20Words.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram():\n",
    "    def __init__(self, uni_probs):\n",
    "        self.uni_probs = uni_probs\n",
    "        self.pattern = r'\\p{P}|[^\\s\\p{P}]+'\n",
    "\n",
    "    def pretokenize(self, text):\n",
    "        words = re.findall(self.pattern, text)\n",
    "        words = list(map(lambda x: '▁' + x, words))\n",
    "        return words\n",
    "\n",
    "    @staticmethod\n",
    "    def split_word(string, splitpoints):\n",
    "        subwords = []\n",
    "        prev_sp = 0\n",
    "        for i, sp in enumerate(splitpoints, start=1):\n",
    "            if sp == '1':\n",
    "                subword = string[prev_sp:i]\n",
    "                prev_sp = i\n",
    "                subwords.append(subword)\n",
    "        subword = string[prev_sp:]\n",
    "        subwords.append(subword)\n",
    "        return subwords\n",
    "\n",
    "    def encode_bf(self, word):\n",
    "        cnt_sp = len(word) - 1\n",
    "        if cnt_sp > 20:\n",
    "            return list(word)\n",
    "        candidates = []\n",
    "        for i in range(2**cnt_sp):\n",
    "            splitpoints = f'{i:0{cnt_sp}b}'\n",
    "            candidates += [Unigram.split_word(word, splitpoints)]\n",
    "        return min(\n",
    "            [(cand,\n",
    "              sum(map(lambda x: self.uni_probs.get(x, 1000), cand))\n",
    "              ) for cand in candidates],\n",
    "            key=lambda x: x[1])\n",
    "\n",
    "    def encode_viterbi(self, word):\n",
    "        n = len(word)\n",
    "        swords = [word[:i] for i in range(1, n + 1)]\n",
    "        min_nlls = [self.uni_probs.get(sword, 1000.0) for sword in swords]\n",
    "\n",
    "        for i in range(2, n + 1):\n",
    "            for j in range(1, i):\n",
    "                sword = word[j:i]\n",
    "                nll = self.uni_probs.get(sword, 1000.0) + min_nlls[j - 1]\n",
    "                if min_nlls[i - 1] > nll:\n",
    "                    min_nlls[i - 1] = nll\n",
    "                    swords[i - 1] = sword\n",
    "        # backtrace\n",
    "        final_swords = [swords.pop()]\n",
    "        while True:\n",
    "            for i in range(len(final_swords[-1]) - 1):\n",
    "                swords.pop()\n",
    "            if swords:\n",
    "                final_swords += [swords.pop()]\n",
    "            else:\n",
    "                break\n",
    "        return final_swords[::-1], min_nlls[-1]\n",
    "\n",
    "    def encode(self, char_seq):\n",
    "        # Use one of the two cache functions below to have a faster answer:\n",
    "        # @functools.lru_cache(maxsize=2**10)\n",
    "        @functools.cache  # Available from Python 3.9\n",
    "        # The arguments of the cached function must be hashable that's why we define an inner cacheable function\n",
    "        def __tokenize_lm(char_seq):\n",
    "            # Write your code here\n",
    "            if not char_seq:\n",
    "                return [], 0.0\n",
    "            splits = [(char_seq[:i + 1], char_seq[i + 1:])\n",
    "                      for i in range(len(char_seq))]\n",
    "            candidates = []\n",
    "            for first, rest in splits:\n",
    "                first_prob = self.uni_probs.get(first, 1000.0)\n",
    "                rest, rest_prob = __tokenize_lm(rest)\n",
    "                candidates.append(([first] + rest, first_prob + rest_prob))\n",
    "            return min(candidates, key=lambda x: x[1])\n",
    "\n",
    "        return __tokenize_lm(char_seq)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        cache = {}\n",
    "        nll_text = 0.0\n",
    "        tokenized_text = []\n",
    "        words = self.pretokenize(text)\n",
    "        for word in tqdm(words):\n",
    "            if word not in cache:\n",
    "                cache[word] = self.encode(word)\n",
    "            subwords, nll = cache[word]\n",
    "            tokenized_text += subwords\n",
    "            nll_text += nll\n",
    "        return tokenized_text, nll_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = Unigram(uni_probs_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ther', 'e', 'f', 'ore'], 21.390774681844547)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('therefore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['w', 'ith', 'x'], 19.49583823140657)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('withx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenize with the BPE distribution all the words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312886/312886 [00:00<00:00, 1116244.91it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens_norvig = unigram.tokenize(text)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the tokenization of the two techniques. This should be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_norvig == tokens_viterbi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation-Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_probs_2 = calc_nll(tokens_viterbi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'▁': 3.8357429341950673,\n",
       " 'B': 7.31475192396911,\n",
       " 'O': 6.840086281617563,\n",
       " 'K': 8.12685104739042,\n",
       " '▁I': 5.049053820782126,\n",
       " '▁S': 6.556044548096757,\n",
       " 'ing': 4.537065237152543,\n",
       " '▁,': 3.474395588412318,\n",
       " '▁go': 5.599019352885387,\n",
       " 'd': 5.278581342706259,\n",
       " 'es': 5.244110673756736,\n",
       " 's': 3.6623958893982778,\n",
       " '▁the': 3.6736672184002113,\n",
       " '▁an': 5.969596001513639,\n",
       " 'g': 4.920900500461321,\n",
       " 'er': 4.778240501828107,\n",
       " '▁of': 4.243335817778279,\n",
       " '▁Ach': 6.3808599966179465,\n",
       " 'ill': 5.860711574316832,\n",
       " '▁son': 6.086998707800207,\n",
       " '▁P': 6.08017739894947,\n",
       " 'e': 3.8552415512188336,\n",
       " 'le': 4.9411510847611195,\n",
       " 'us': 4.715877051543648,\n",
       " '▁that': 5.5265032833911185,\n",
       " '▁br': 6.304000991092335,\n",
       " 'ough': 6.220041317972064,\n",
       " 't': 4.126528021945629,\n",
       " '▁c': 4.557614910816325,\n",
       " 'ou': 5.845005862908656,\n",
       " 'n': 4.452017140197274,\n",
       " '▁up': 6.022716893120213,\n",
       " 'on': 4.940063537073721,\n",
       " 'ae': 6.5100717280979525,\n",
       " 'ans': 5.949113357727698,\n",
       " '▁.': 4.373268611979016,\n",
       " '▁M': 6.073402305283108,\n",
       " 'an': 5.095446860351836,\n",
       " 'y': 4.626046511062165,\n",
       " '▁a': 4.505321079019706,\n",
       " 'a': 3.927514458446835,\n",
       " 've': 6.186217955435951,\n",
       " '▁s': 4.85668192813467,\n",
       " 'l': 4.581477377194001,\n",
       " '▁d': 4.936374697043918,\n",
       " 'id': 5.567993079322286,\n",
       " '▁it': 5.631039164120158,\n",
       " '▁se': 5.885581604391479,\n",
       " 'nd': 5.6168239775188935,\n",
       " '▁h': 5.18075139803884,\n",
       " 'ur': 5.799830114178707,\n",
       " 'r': 4.549344298024447,\n",
       " 'ow': 5.052940150667498,\n",
       " '▁to': 4.399130506828174,\n",
       " '▁H': 7.565732629570463,\n",
       " 'ad': 5.687712816058001,\n",
       " '▁and': 4.026646495512603,\n",
       " '▁man': 6.26236300305475,\n",
       " '▁her': 6.118990309473569,\n",
       " 'o': 4.026384909427491,\n",
       " '▁y': 7.1592670211287155,\n",
       " 'ie': 6.5484150832956,\n",
       " 'ld': 5.807046640342576,\n",
       " '▁p': 5.006342702689076,\n",
       " 're': 4.9196217279085435,\n",
       " '▁do': 6.505900710580614,\n",
       " 'v': 5.699257622186544,\n",
       " 'u': 4.995024877756414,\n",
       " '▁for': 5.297359791998579,\n",
       " '▁so': 5.961111102124344,\n",
       " '▁were': 6.325488710829024,\n",
       " 'sel': 6.51846632094098,\n",
       " 'J': 6.710742423560104,\n",
       " 'ove': 6.38730866014448,\n",
       " '▁f': 4.63321842800954,\n",
       " 'f': 4.979980144479163,\n",
       " 'ed': 4.32499541370135,\n",
       " '▁from': 6.046094581129276,\n",
       " 'ay': 5.349012969264496,\n",
       " '▁on': 5.658305585030699,\n",
       " '▁whi': 6.241377567890863,\n",
       " 'ch': 5.354920436395189,\n",
       " '▁A': 5.455246466208667,\n",
       " '▁k': 6.207609145417269,\n",
       " '▁m': 4.7218014459408515,\n",
       " 'en': 5.1411691096899315,\n",
       " '▁g': 5.247061398824793,\n",
       " 'at': 5.023445146012771,\n",
       " 'ir': 6.137535776796563,\n",
       " 'st': 5.557055153786354,\n",
       " 'ell': 6.295533539993237,\n",
       " 'out': 5.796753188674228,\n",
       " '▁with': 5.35623795964243,\n",
       " '▁one': 6.468121843239443,\n",
       " 'ther': 5.490051904658754,\n",
       " '▁was': 5.639316275196151,\n",
       " '▁them': 5.807564104778444,\n",
       " 'q': 7.112383435229865,\n",
       " 'ar': 5.233851167087987,\n",
       " '?': 7.028238758722312,\n",
       " 'L': 7.204264387059451,\n",
       " 'et': 6.086998707800207,\n",
       " '▁;': 5.5458370874250775,\n",
       " '▁he': 4.585739179687187,\n",
       " 'ent': 5.807046640342576,\n",
       " 'est': 6.601939563711305,\n",
       " 'il': 6.4832659994037405,\n",
       " 'ce': 5.695548763044021,\n",
       " 'p': 4.901470110924803,\n",
       " '▁be': 5.124299969550709,\n",
       " 'c': 5.346398588690425,\n",
       " '▁had': 5.920892790085447,\n",
       " 'is': 5.7270437281204245,\n",
       " 'h': 5.306412452540849,\n",
       " 'our': 6.058656729797932,\n",
       " 'C': 7.195931005500307,\n",
       " 'ses': 6.324620278295071,\n",
       " '▁his': 5.143031555352672,\n",
       " 'ri': 6.092489455980624,\n",
       " 'N': 6.9124069431971895,\n",
       " 'ome': 5.797777778927796,\n",
       " '▁ship': 6.659704589641436,\n",
       " 'ght': 7.577817368785535,\n",
       " '▁him': 5.313335073012267,\n",
       " '▁r': 5.532775354128788,\n",
       " 'om': 6.182445789514528,\n",
       " ':': 7.83654085253237,\n",
       " 'ore': 6.1586351408208095,\n",
       " 'ver': 5.593572031642534,\n",
       " '▁b': 5.043011506326163,\n",
       " '▁in': 4.866126386962669,\n",
       " '▁ha': 5.81954029582516,\n",
       " 'll': 6.7248905695261305,\n",
       " '▁w': 4.670202361192051,\n",
       " '▁su': 6.41257907364074,\n",
       " 'i': 4.500267018001797,\n",
       " \"▁'\": 6.330715203562567,\n",
       " '▁but': 5.988024041425698,\n",
       " '▁all': 5.965950796991308,\n",
       " '▁t': 5.099518112794615,\n",
       " 'w': 5.066909254182333,\n",
       " '▁who': 5.919155170186906,\n",
       " '▁their': 6.180940898335107,\n",
       " '▁ch': 6.541921553985052,\n",
       " '▁\"': 5.192434423831534,\n",
       " '▁o': 5.8013721345305225,\n",
       " 'ly': 5.32764601847553,\n",
       " 'm': 5.05830863598663,\n",
       " '▁you': 5.154010377638256,\n",
       " '▁sa': 6.657280346029929,\n",
       " 'ck': 5.989885661572398,\n",
       " 'it': 5.787578812398187,\n",
       " 'am': 6.513211448102621,\n",
       " '▁re': 6.138255978484157,\n",
       " '▁your': 6.141141983373292,\n",
       " '▁my': 6.034337424143232,\n",
       " '▁this': 6.524808836917449,\n",
       " 'ct': 6.442403313951454,\n",
       " 'k': 5.451251545333621,\n",
       " '▁not': 5.900238011054701,\n",
       " 'ame': 6.4192362546699195,\n",
       " '▁sp': 5.948517232523756,\n",
       " 'ke': 5.682218296740361,\n",
       " '▁said': 6.584903376558737,\n",
       " '▁le': 6.351898696478747,\n",
       " '▁me': 5.7241824958393925,\n",
       " 'ind': 6.590549918946947,\n",
       " '▁ab': 6.559332222290949,\n",
       " '▁n': 5.601122403082165,\n",
       " 'or': 5.042288875920153,\n",
       " 'ter': 6.349226089097271,\n",
       " 'Y': 7.931457409029114,\n",
       " '▁sh': 5.740505469871323,\n",
       " 'all': 6.116167442390864,\n",
       " 'ro': 5.9843111658732715,\n",
       " '▁will': 6.05004455334859,\n",
       " 'he': 6.7069183271217,\n",
       " 'se': 5.691853608724033,\n",
       " '▁at': 6.206065935234463,\n",
       " '▁l': 5.094685342355903,\n",
       " '▁or': 6.600794743895372,\n",
       " '▁The': 5.95030667529174,\n",
       " 'ear': 5.955694296824119,\n",
       " 'b': 5.66546445229354,\n",
       " 'ot': 6.6440510490614315,\n",
       " '▁by': 6.282133004455754,\n",
       " 'ound': 6.391940442394518,\n",
       " '▁He': 6.217698482070292,\n",
       " '▁T': 5.774974662679497,\n",
       " '▁th': 5.5655520691598515,\n",
       " 'ight': 5.899102937153037,\n",
       " 'in': 5.591067856711213,\n",
       " '▁have': 6.052686562811429,\n",
       " '▁e': 5.531989190566284,\n",
       " '▁de': 6.634538492193733,\n",
       " 'and': 6.5100717280979525,\n",
       " 'gh': 7.721385939282256,\n",
       " '▁-': 4.821314784297378,\n",
       " 'ven': 6.268088990069636,\n",
       " 'D': 6.968646661520066,\n",
       " 'ard': 6.318562276211155,\n",
       " 'ould': 5.947921462473366,\n",
       " '▁as': 5.518330441635244,\n",
       " 'F': 7.794145293564685,\n",
       " 'im': 6.7005771517832535,\n",
       " 'ong': 6.257480975457442,\n",
       " '▁am': 6.622773650614147,\n",
       " '▁there': 6.561530025373428,\n",
       " 'un': 6.378108963246056,\n",
       " 'as': 6.142588115223292,\n",
       " '▁when': 6.409739507132662,\n",
       " '▁they': 5.8618038737154405,\n",
       " '▁we': 6.377193631374369,\n",
       " 'if': 6.26317899657208,\n",
       " '▁are': 6.377193631374369,\n",
       " 'ut': 6.5484150832956,\n",
       " '(': 9.847514594934745,\n",
       " ')': 9.847514594934745,\n",
       " '▁wh': 7.181512630076035,\n",
       " '▁is': 5.974477036219553,\n",
       " '▁W': 6.615780615123176,\n",
       " 'ith': 7.918554004193205,\n",
       " 'al': 6.363563252243678,\n",
       " 'od': 6.164534862947997,\n",
       " '▁st': 5.513690062078742,\n",
       " 'ive': 6.41828251115461,\n",
       " 'j': 6.231047718389286,\n",
       " 'ain': 6.092489455980624,\n",
       " '▁no': 6.55058899719522,\n",
       " 'th': 6.031743388966185,\n",
       " 'ep': 6.538690533403606,\n",
       " '▁she': 6.4116316552847,\n",
       " '▁u': 7.533233462177509,\n",
       " 'z': 7.400065507681646,\n",
       " 'G': 8.214819820336379,\n",
       " 'x': 6.593953212078655,\n",
       " 'U': 6.793235982265958,\n",
       " '!': 10.378142845996916,\n",
       " 'hen': 7.382410572442925,\n",
       " 'ip': 7.910043314525297,\n",
       " 'lo': 6.452216935399779,\n",
       " '▁fr': 7.31475192396911,\n",
       " 'her': 6.793235982265958,\n",
       " 'E': 7.040595491411216,\n",
       " 'red': 8.29870130431708,\n",
       " 'V': 8.491073196964535,\n",
       " 'I': 9.279530557328806,\n",
       " 'R': 9.348523428815758,\n",
       " 'Z': 10.665824918448697,\n",
       " 'X': 9.169182500159941,\n",
       " 'Q': 10.665824918448697,\n",
       " '&': 13.373875119550908,\n",
       " 'H': 12.680727938990962,\n",
       " '[': 10.665824918448697,\n",
       " ']': 10.665824918448697}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_probs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.35623795964243"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_probs_2['▁with']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3599913308366505"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_probs_bpe['▁with']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram():\n",
    "    def __init__(self, uni_probs):\n",
    "        self.uni_probs = uni_probs\n",
    "        self.pattern = r'\\p{P}|[^\\s\\p{P}]+'\n",
    "\n",
    "    def pretokenize(self, text):\n",
    "        words = re.findall(self.pattern, text)\n",
    "        words = list(map(lambda x: '▁' + x, words))\n",
    "        return words\n",
    "\n",
    "    @staticmethod\n",
    "    def split_word(string, splitpoints):\n",
    "        subwords = []\n",
    "        prev_sp = 0\n",
    "        for i, sp in enumerate(splitpoints, start=1):\n",
    "            if sp == '1':\n",
    "                subword = string[prev_sp:i]\n",
    "                prev_sp = i\n",
    "                subwords.append(subword)\n",
    "        subword = string[prev_sp:]\n",
    "        subwords.append(subword)\n",
    "        return subwords\n",
    "\n",
    "    def encode_bf(self, word):\n",
    "        cnt_sp = len(word) - 1\n",
    "        if cnt_sp > 20:\n",
    "            return list(word)\n",
    "        candidates = []\n",
    "        for i in range(2**cnt_sp):\n",
    "            splitpoints = f'{i:0{cnt_sp}b}'\n",
    "            candidates += [Unigram.split_word(word, splitpoints)]\n",
    "        return min(\n",
    "            [(cand,\n",
    "              sum(map(lambda x: self.uni_probs.get(x, 1000), cand))\n",
    "              ) for cand in candidates],\n",
    "            key=lambda x: x[1])\n",
    "\n",
    "    def encode(self, word):\n",
    "        n = len(word)\n",
    "        swords = [word[:i] for i in range(1, n + 1)]\n",
    "        min_nlls = [self.uni_probs.get(sword, 1000.0) for sword in swords]\n",
    "\n",
    "        for i in range(2, n + 1):\n",
    "            for j in range(1, i):\n",
    "                sword = word[j:i]\n",
    "                nll = self.uni_probs.get(sword, 1000.0) + min_nlls[j - 1]\n",
    "                if min_nlls[i - 1] > nll:\n",
    "                    min_nlls[i - 1] = nll\n",
    "                    swords[i - 1] = sword\n",
    "        # backtrace\n",
    "        final_swords = [swords.pop()]\n",
    "        while True:\n",
    "            for i in range(len(final_swords[-1]) - 1):\n",
    "                swords.pop()\n",
    "            if swords:\n",
    "                final_swords += [swords.pop()]\n",
    "            else:\n",
    "                break\n",
    "        return final_swords[::-1], min_nlls[-1]\n",
    "\n",
    "    def encode_norvig(self, char_seq):\n",
    "        # Use one of the two cache functions below to have a faster answer:\n",
    "        # @functools.lru_cache(maxsize=2**10)\n",
    "        @functools.cache  # Available from Python 3.9\n",
    "        # The arguments of the cached function must be hashable that's why we define an inner cacheable function\n",
    "        def __tokenize_lm(char_seq):\n",
    "            # Write your code here\n",
    "            if not char_seq:\n",
    "                return [], 0.0\n",
    "            splits = [(char_seq[:i + 1], char_seq[i + 1:])\n",
    "                      for i in range(len(char_seq))]\n",
    "            candidates = []\n",
    "            for first, rest in splits:\n",
    "                first_prob = self.uni_probs.get(first, 1000.0)\n",
    "                rest, rest_prob = __tokenize_lm(rest)\n",
    "                candidates.append(([first] + rest, first_prob + rest_prob))\n",
    "            return min(candidates, key=lambda x: x[1])\n",
    "\n",
    "        return __tokenize_lm(char_seq)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        cache = {}\n",
    "        nll_text = 0.0\n",
    "        tokenized_text = []\n",
    "        words = self.pretokenize(text)\n",
    "        for word in words:\n",
    "            if word not in cache:\n",
    "                cache[word] = self.encode(word)\n",
    "            subwords, nll = cache[word]\n",
    "            tokenized_text += subwords\n",
    "            nll_text += nll\n",
    "        return tokenized_text, nll_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood from BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em(text, uni_probs_old):\n",
    "    cache = {}\n",
    "    tokens = []\n",
    "    unigram = Unigram(uni_probs_old)\n",
    "    words = unigram.pretokenize(text)\n",
    "    for word in words:\n",
    "        if word not in cache:\n",
    "            cache[word] = unigram.encode(word)[0]\n",
    "        tokens += cache[word]\n",
    "    uni_probs_new = calc_nll(tokens)\n",
    "    return uni_probs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.476829698201476, 3.6761013281893695, 3.6892379073687205, 3.8798880662790753, 4.029080605301761]\n",
      "[3.474395588412318, 3.6736672184002113, 3.6623958893982778, 3.8552415512188336, 4.026646495512603]\n",
      "[3.4745775359512794, 3.6738491659391728, 3.662759605546301, 3.83355001105575, 4.026828443051564]\n",
      "[3.474705035010758, 3.6739766649986514, 3.6668943959428217, 3.832743501353862, 4.026955942111043]\n",
      "[3.4747128088178476, 3.673984438805741, 3.6665980242443585, 3.832392273182586, 4.026963715918133]\n",
      "[3.4747128088178476, 3.673984438805741, 3.6665980242443585, 3.832392273182586, 4.026963715918133]\n"
     ]
    }
   ],
   "source": [
    "uni_probs = dict(uni_probs_bpe)\n",
    "print(list(map(uni_probs.get, ['▁,', '▁the', 's', 'e', '▁and'])))\n",
    "for _ in range(5):\n",
    "    uni_probs = em(text, uni_probs)\n",
    "    print(list(map(uni_probs.get, ['▁,', '▁the', 's', 'e', '▁and'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uni_probs_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uni_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.673984438805741"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_probs['▁the']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Final Tokenization with Stable Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram = Unigram(uni_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['t', 'x', 'x', 'her', 'e'], 27.95207566991922)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.encode('txxhere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁S',\n",
       "  'it',\n",
       "  '▁c',\n",
       "  'a',\n",
       "  're',\n",
       "  'x',\n",
       "  'x',\n",
       "  'le',\n",
       "  's',\n",
       "  's',\n",
       "  '▁in',\n",
       "  '▁the',\n",
       "  '▁sh',\n",
       "  'ad',\n",
       "  'e'],\n",
       " 74.93529156047747)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.tokenize('Sit carexxless in the shade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁he', 're'], 9.512558170433628)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.tokenize('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁The', 're', 'f', 'ore'], 22.015487824561927)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.tokenize('Therefore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁S',\n",
       "  'it',\n",
       "  '▁c',\n",
       "  'a',\n",
       "  're',\n",
       "  'le',\n",
       "  's',\n",
       "  's',\n",
       "  '▁in',\n",
       "  '▁the',\n",
       "  '▁sh',\n",
       "  'ad',\n",
       "  'e'],\n",
       " 61.7467506955091)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram.tokenize('Sit careless in the shade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['▁',\n",
       "  'B',\n",
       "  'O',\n",
       "  'O',\n",
       "  'K',\n",
       "  '▁I',\n",
       "  '▁S',\n",
       "  'ing',\n",
       "  '▁,',\n",
       "  '▁',\n",
       "  'O',\n",
       "  '▁go',\n",
       "  'd',\n",
       "  'd',\n",
       "  'es',\n",
       "  's',\n",
       "  '▁,',\n",
       "  '▁the',\n",
       "  '▁an',\n",
       "  'g',\n",
       "  'er',\n",
       "  '▁of',\n",
       "  '▁Ach',\n",
       "  'ill',\n",
       "  'es',\n",
       "  '▁son',\n",
       "  '▁of',\n",
       "  '▁P',\n",
       "  'e',\n",
       "  'le',\n",
       "  'us',\n",
       "  '▁,',\n",
       "  '▁that',\n",
       "  '▁br',\n",
       "  'ough',\n",
       "  't',\n",
       "  '▁c',\n",
       "  'ou',\n",
       "  'n',\n",
       "  't',\n",
       "  'le',\n",
       "  's',\n",
       "  's',\n",
       "  '▁',\n",
       "  'ill',\n",
       "  's',\n",
       "  '▁up',\n",
       "  'on',\n",
       "  '▁the',\n",
       "  '▁Ach',\n",
       "  'ae',\n",
       "  'ans',\n",
       "  '▁.',\n",
       "  '▁M',\n",
       "  'an',\n",
       "  'y',\n",
       "  '▁a',\n",
       "  '▁br',\n",
       "  'a',\n",
       "  've',\n",
       "  '▁s',\n",
       "  'ou',\n",
       "  'l',\n",
       "  '▁d',\n",
       "  'id',\n",
       "  '▁it',\n",
       "  '▁se',\n",
       "  'nd',\n",
       "  '▁h',\n",
       "  'ur',\n",
       "  'r',\n",
       "  'y',\n",
       "  'ing',\n",
       "  '▁d',\n",
       "  'ow',\n",
       "  'n',\n",
       "  '▁to',\n",
       "  '▁H',\n",
       "  'ad',\n",
       "  'es',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁man',\n",
       "  'y',\n",
       "  '▁a',\n",
       "  '▁her',\n",
       "  'o',\n",
       "  '▁d',\n",
       "  'id',\n",
       "  '▁it',\n",
       "  '▁y',\n",
       "  'ie',\n",
       "  'ld',\n",
       "  '▁a',\n",
       "  '▁p',\n",
       "  're',\n",
       "  'y',\n",
       "  '▁to',\n",
       "  '▁do',\n",
       "  'g',\n",
       "  's',\n",
       "  '▁and',\n",
       "  '▁',\n",
       "  'v',\n",
       "  'u',\n",
       "  'l',\n",
       "  't',\n",
       "  'ur',\n",
       "  'es',\n",
       "  '▁,',\n",
       "  '▁for',\n",
       "  '▁so',\n",
       "  '▁were',\n",
       "  '▁the',\n",
       "  '▁c',\n",
       "  'ou',\n",
       "  'n',\n",
       "  'sel',\n",
       "  's',\n",
       "  '▁of',\n",
       "  '▁',\n",
       "  'J',\n",
       "  'ove',\n",
       "  '▁f',\n",
       "  'u',\n",
       "  'l',\n",
       "  'f',\n",
       "  'ill',\n",
       "  'ed',\n",
       "  '▁from',\n",
       "  '▁the',\n",
       "  '▁d',\n",
       "  'ay',\n",
       "  '▁on',\n",
       "  '▁whi',\n",
       "  'ch',\n",
       "  '▁the',\n",
       "  '▁son',\n",
       "  '▁of',\n",
       "  '▁A',\n",
       "  't',\n",
       "  're',\n",
       "  'us',\n",
       "  '▁,',\n",
       "  '▁k',\n",
       "  'ing',\n",
       "  '▁of',\n",
       "  '▁m',\n",
       "  'en',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁g',\n",
       "  're',\n",
       "  'at',\n",
       "  '▁Ach',\n",
       "  'ill',\n",
       "  'es',\n",
       "  '▁,',\n",
       "  '▁f',\n",
       "  'ir',\n",
       "  'st',\n",
       "  '▁f',\n",
       "  'ell',\n",
       "  '▁',\n",
       "  'out',\n",
       "  '▁with',\n",
       "  '▁one',\n",
       "  '▁an',\n",
       "  'o',\n",
       "  'ther',\n",
       "  '▁.',\n",
       "  '▁A',\n",
       "  'nd',\n",
       "  '▁whi',\n",
       "  'ch',\n",
       "  '▁of',\n",
       "  '▁the',\n",
       "  '▁go',\n",
       "  'd',\n",
       "  's',\n",
       "  '▁was',\n",
       "  '▁it',\n",
       "  '▁that',\n",
       "  '▁se',\n",
       "  't',\n",
       "  '▁them',\n",
       "  '▁on',\n",
       "  '▁to',\n",
       "  '▁',\n",
       "  'q',\n",
       "  'u',\n",
       "  'ar',\n",
       "  're',\n",
       "  'l',\n",
       "  '▁',\n",
       "  '?',\n",
       "  '▁I',\n",
       "  't',\n",
       "  '▁was',\n",
       "  '▁the',\n",
       "  '▁son',\n",
       "  '▁of',\n",
       "  '▁',\n",
       "  'J',\n",
       "  'ove',\n",
       "  '▁and',\n",
       "  '▁',\n",
       "  'L',\n",
       "  'et',\n",
       "  'o',\n",
       "  '▁;',\n",
       "  '▁for',\n",
       "  '▁he',\n",
       "  '▁was',\n",
       "  '▁an',\n",
       "  'g',\n",
       "  'r',\n",
       "  'y',\n",
       "  '▁with',\n",
       "  '▁the',\n",
       "  '▁k',\n",
       "  'ing',\n",
       "  '▁and',\n",
       "  '▁s',\n",
       "  'ent',\n",
       "  '▁a',\n",
       "  '▁p',\n",
       "  'est',\n",
       "  'il',\n",
       "  'en',\n",
       "  'ce',\n",
       "  '▁up',\n",
       "  'on',\n",
       "  '▁the',\n",
       "  '▁h',\n",
       "  'o',\n",
       "  'st',\n",
       "  '▁to',\n",
       "  '▁p',\n",
       "  'l',\n",
       "  'a',\n",
       "  'g',\n",
       "  'u',\n",
       "  'e',\n",
       "  '▁the',\n",
       "  '▁p',\n",
       "  'e',\n",
       "  'o',\n",
       "  'p',\n",
       "  'le',\n",
       "  '▁,',\n",
       "  '▁be',\n",
       "  'c',\n",
       "  'a',\n",
       "  'us',\n",
       "  'e',\n",
       "  '▁the',\n",
       "  '▁son',\n",
       "  '▁of',\n",
       "  '▁A',\n",
       "  't',\n",
       "  're',\n",
       "  'us',\n",
       "  '▁had',\n",
       "  '▁d',\n",
       "  'is',\n",
       "  'h',\n",
       "  'on',\n",
       "  'our',\n",
       "  'ed',\n",
       "  '▁',\n",
       "  'C',\n",
       "  'h',\n",
       "  'r',\n",
       "  'y',\n",
       "  'ses',\n",
       "  '▁his',\n",
       "  '▁p',\n",
       "  'ri',\n",
       "  'est',\n",
       "  '▁.',\n",
       "  '▁',\n",
       "  'N',\n",
       "  'ow',\n",
       "  '▁',\n",
       "  'C',\n",
       "  'h',\n",
       "  'r',\n",
       "  'y',\n",
       "  'ses',\n",
       "  '▁had',\n",
       "  '▁c',\n",
       "  'ome',\n",
       "  '▁to',\n",
       "  '▁the',\n",
       "  '▁ship',\n",
       "  's',\n",
       "  '▁of',\n",
       "  '▁the',\n",
       "  '▁Ach',\n",
       "  'ae',\n",
       "  'ans',\n",
       "  '▁to',\n",
       "  '▁f',\n",
       "  're',\n",
       "  'e',\n",
       "  '▁his',\n",
       "  '▁d',\n",
       "  'a',\n",
       "  'u',\n",
       "  'ght',\n",
       "  'er',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁had',\n",
       "  '▁br',\n",
       "  'ough',\n",
       "  't',\n",
       "  '▁with',\n",
       "  '▁him',\n",
       "  '▁a',\n",
       "  '▁g',\n",
       "  're',\n",
       "  'at',\n",
       "  '▁r',\n",
       "  'ans',\n",
       "  'om',\n",
       "  '▁',\n",
       "  ':',\n",
       "  '▁m',\n",
       "  'ore',\n",
       "  'o',\n",
       "  'ver',\n",
       "  '▁he',\n",
       "  '▁b',\n",
       "  'ore',\n",
       "  '▁in',\n",
       "  '▁his',\n",
       "  '▁ha',\n",
       "  'nd',\n",
       "  '▁the',\n",
       "  '▁s',\n",
       "  'ce',\n",
       "  'p',\n",
       "  't',\n",
       "  're',\n",
       "  '▁of',\n",
       "  '▁A',\n",
       "  'p',\n",
       "  'o',\n",
       "  'll',\n",
       "  'o',\n",
       "  '▁w',\n",
       "  're',\n",
       "  'a',\n",
       "  'th',\n",
       "  'ed',\n",
       "  '▁with',\n",
       "  '▁a',\n",
       "  '▁su',\n",
       "  'p',\n",
       "  'p',\n",
       "  'l',\n",
       "  'i',\n",
       "  'an',\n",
       "  't',\n",
       "  \"▁'\",\n",
       "  '▁s',\n",
       "  '▁w',\n",
       "  're',\n",
       "  'a',\n",
       "  'th',\n",
       "  '▁and',\n",
       "  '▁he',\n",
       "  '▁be',\n",
       "  's',\n",
       "  'ough',\n",
       "  't',\n",
       "  '▁the',\n",
       "  '▁Ach',\n",
       "  'ae',\n",
       "  'ans',\n",
       "  '▁,',\n",
       "  '▁but',\n",
       "  '▁m',\n",
       "  'o',\n",
       "  'st',\n",
       "  '▁of',\n",
       "  '▁all',\n",
       "  '▁the',\n",
       "  '▁t',\n",
       "  'w',\n",
       "  'o',\n",
       "  '▁son',\n",
       "  's',\n",
       "  '▁of',\n",
       "  '▁A',\n",
       "  't',\n",
       "  're',\n",
       "  'us',\n",
       "  '▁,',\n",
       "  '▁who',\n",
       "  '▁were',\n",
       "  '▁their',\n",
       "  '▁ch',\n",
       "  'ie',\n",
       "  'f',\n",
       "  's',\n",
       "  '▁.',\n",
       "  '▁\"',\n",
       "  '▁S',\n",
       "  'on',\n",
       "  's',\n",
       "  '▁of',\n",
       "  '▁A',\n",
       "  't',\n",
       "  're',\n",
       "  'us',\n",
       "  '▁,',\n",
       "  '▁\"',\n",
       "  '▁he',\n",
       "  '▁c',\n",
       "  'ri',\n",
       "  'ed',\n",
       "  '▁,',\n",
       "  '▁\"',\n",
       "  '▁and',\n",
       "  '▁all',\n",
       "  '▁o',\n",
       "  'ther',\n",
       "  '▁Ach',\n",
       "  'ae',\n",
       "  'ans',\n",
       "  '▁,',\n",
       "  '▁m',\n",
       "  'ay',\n",
       "  '▁the',\n",
       "  '▁go',\n",
       "  'd',\n",
       "  's',\n",
       "  '▁who',\n",
       "  '▁d',\n",
       "  'w',\n",
       "  'ell',\n",
       "  '▁in',\n",
       "  '▁',\n",
       "  'O',\n",
       "  'ly',\n",
       "  'm',\n",
       "  'p',\n",
       "  'us',\n",
       "  '▁g',\n",
       "  'r',\n",
       "  'an',\n",
       "  't',\n",
       "  '▁you',\n",
       "  '▁to',\n",
       "  '▁sa',\n",
       "  'ck',\n",
       "  '▁the',\n",
       "  '▁c',\n",
       "  'it',\n",
       "  'y',\n",
       "  '▁of',\n",
       "  '▁P',\n",
       "  'ri',\n",
       "  'am',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁to',\n",
       "  '▁re',\n",
       "  'a',\n",
       "  'ch',\n",
       "  '▁your',\n",
       "  '▁h',\n",
       "  'ome',\n",
       "  's',\n",
       "  '▁in',\n",
       "  '▁sa',\n",
       "  'f',\n",
       "  'et',\n",
       "  'y',\n",
       "  '▁;',\n",
       "  '▁but',\n",
       "  '▁f',\n",
       "  're',\n",
       "  'e',\n",
       "  '▁my',\n",
       "  '▁d',\n",
       "  'a',\n",
       "  'u',\n",
       "  'ght',\n",
       "  'er',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁a',\n",
       "  'c',\n",
       "  'ce',\n",
       "  'p',\n",
       "  't',\n",
       "  '▁a',\n",
       "  '▁r',\n",
       "  'ans',\n",
       "  'om',\n",
       "  '▁for',\n",
       "  '▁her',\n",
       "  '▁,',\n",
       "  '▁in',\n",
       "  '▁re',\n",
       "  'ver',\n",
       "  'en',\n",
       "  'ce',\n",
       "  '▁to',\n",
       "  '▁A',\n",
       "  'p',\n",
       "  'o',\n",
       "  'll',\n",
       "  'o',\n",
       "  '▁,',\n",
       "  '▁son',\n",
       "  '▁of',\n",
       "  '▁',\n",
       "  'J',\n",
       "  'ove',\n",
       "  '▁.',\n",
       "  '▁\"',\n",
       "  '▁',\n",
       "  'O',\n",
       "  'n',\n",
       "  '▁this',\n",
       "  '▁the',\n",
       "  '▁re',\n",
       "  'st',\n",
       "  '▁of',\n",
       "  '▁the',\n",
       "  '▁Ach',\n",
       "  'ae',\n",
       "  'ans',\n",
       "  '▁with',\n",
       "  '▁one',\n",
       "  '▁',\n",
       "  'v',\n",
       "  'o',\n",
       "  'i',\n",
       "  'ce',\n",
       "  '▁were',\n",
       "  '▁for',\n",
       "  '▁re',\n",
       "  's',\n",
       "  'p',\n",
       "  'e',\n",
       "  'ct',\n",
       "  'ing',\n",
       "  '▁the',\n",
       "  '▁p',\n",
       "  'ri',\n",
       "  'est',\n",
       "  '▁and',\n",
       "  '▁t',\n",
       "  'a',\n",
       "  'k',\n",
       "  'ing',\n",
       "  '▁the',\n",
       "  '▁r',\n",
       "  'ans',\n",
       "  'om',\n",
       "  '▁that',\n",
       "  '▁he',\n",
       "  '▁of',\n",
       "  'f',\n",
       "  'er',\n",
       "  'ed',\n",
       "  '▁;',\n",
       "  '▁but',\n",
       "  '▁not',\n",
       "  '▁so',\n",
       "  '▁A',\n",
       "  'g',\n",
       "  'ame',\n",
       "  'm',\n",
       "  'n',\n",
       "  'on',\n",
       "  '▁,',\n",
       "  '▁who',\n",
       "  '▁sp',\n",
       "  'o',\n",
       "  'ke',\n",
       "  '▁f',\n",
       "  'i',\n",
       "  'er',\n",
       "  'ce',\n",
       "  'ly',\n",
       "  '▁to',\n",
       "  '▁him',\n",
       "  '▁and',\n",
       "  '▁s',\n",
       "  'ent',\n",
       "  '▁him',\n",
       "  '▁r',\n",
       "  'ough',\n",
       "  'ly',\n",
       "  '▁a',\n",
       "  'w',\n",
       "  'ay',\n",
       "  '▁.',\n",
       "  '▁\"',\n",
       "  '▁',\n",
       "  'O',\n",
       "  'ld',\n",
       "  '▁man',\n",
       "  '▁,',\n",
       "  '▁\"',\n",
       "  '▁said',\n",
       "  '▁he',\n",
       "  '▁,',\n",
       "  '▁\"',\n",
       "  '▁le',\n",
       "  't',\n",
       "  '▁me',\n",
       "  '▁not',\n",
       "  '▁f',\n",
       "  'ind',\n",
       "  '▁you',\n",
       "  '▁t',\n",
       "  'ar',\n",
       "  'r',\n",
       "  'y',\n",
       "  'ing',\n",
       "  '▁ab',\n",
       "  'out',\n",
       "  '▁',\n",
       "  'our',\n",
       "  '▁ship',\n",
       "  's',\n",
       "  '▁,',\n",
       "  '▁n',\n",
       "  'or',\n",
       "  '▁y',\n",
       "  'et',\n",
       "  '▁c',\n",
       "  'om',\n",
       "  'ing',\n",
       "  '▁he',\n",
       "  're',\n",
       "  'a',\n",
       "  'f',\n",
       "  'ter',\n",
       "  '▁.',\n",
       "  '▁',\n",
       "  'Y',\n",
       "  'our',\n",
       "  '▁s',\n",
       "  'ce',\n",
       "  'p',\n",
       "  't',\n",
       "  're',\n",
       "  '▁of',\n",
       "  '▁the',\n",
       "  '▁go',\n",
       "  'd',\n",
       "  '▁and',\n",
       "  '▁your',\n",
       "  '▁w',\n",
       "  're',\n",
       "  'a',\n",
       "  'th',\n",
       "  '▁sh',\n",
       "  'all',\n",
       "  '▁p',\n",
       "  'ro',\n",
       "  'f',\n",
       "  'it',\n",
       "  '▁you',\n",
       "  '▁not',\n",
       "  'h',\n",
       "  'ing',\n",
       "  '▁.',\n",
       "  '▁I',\n",
       "  '▁will',\n",
       "  '▁not',\n",
       "  '▁f',\n",
       "  're',\n",
       "  'e',\n",
       "  '▁her',\n",
       "  '▁.',\n",
       "  '▁S',\n",
       "  'he',\n",
       "  '▁sh',\n",
       "  'all',\n",
       "  '▁g',\n",
       "  'r',\n",
       "  'ow',\n",
       "  '▁o',\n",
       "  'ld',\n",
       "  '▁in',\n",
       "  '▁my',\n",
       "  '▁h',\n",
       "  'ou',\n",
       "  'se',\n",
       "  '▁at',\n",
       "  '▁A',\n",
       "  'r',\n",
       "  'g',\n",
       "  'o',\n",
       "  's',\n",
       "  '▁f',\n",
       "  'ar',\n",
       "  '▁from',\n",
       "  '▁her',\n",
       "  '▁',\n",
       "  'ow',\n",
       "  'n',\n",
       "  '▁h',\n",
       "  'ome',\n",
       "  '▁,',\n",
       "  '▁b',\n",
       "  'us',\n",
       "  'y',\n",
       "  'ing',\n",
       "  '▁her',\n",
       "  'sel',\n",
       "  'f',\n",
       "  '▁with',\n",
       "  '▁her',\n",
       "  '▁l',\n",
       "  'o',\n",
       "  'om',\n",
       "  '▁and',\n",
       "  '▁',\n",
       "  'v',\n",
       "  'is',\n",
       "  'it',\n",
       "  'ing',\n",
       "  '▁my',\n",
       "  '▁c',\n",
       "  'ou',\n",
       "  'ch',\n",
       "  '▁;',\n",
       "  '▁so',\n",
       "  '▁go',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁do',\n",
       "  '▁not',\n",
       "  '▁p',\n",
       "  'ro',\n",
       "  'v',\n",
       "  'o',\n",
       "  'ke',\n",
       "  '▁me',\n",
       "  '▁or',\n",
       "  '▁it',\n",
       "  '▁sh',\n",
       "  'all',\n",
       "  '▁be',\n",
       "  '▁the',\n",
       "  '▁w',\n",
       "  'or',\n",
       "  'se',\n",
       "  '▁for',\n",
       "  '▁you',\n",
       "  '▁.',\n",
       "  '▁\"',\n",
       "  '▁The',\n",
       "  '▁o',\n",
       "  'ld',\n",
       "  '▁man',\n",
       "  '▁f',\n",
       "  'ear',\n",
       "  'ed',\n",
       "  '▁him',\n",
       "  '▁and',\n",
       "  '▁o',\n",
       "  'b',\n",
       "  'e',\n",
       "  'y',\n",
       "  'ed',\n",
       "  '▁.',\n",
       "  '▁',\n",
       "  'N',\n",
       "  'ot',\n",
       "  '▁a',\n",
       "  '▁w',\n",
       "  'or',\n",
       "  'd',\n",
       "  '▁he',\n",
       "  '▁sp',\n",
       "  'o',\n",
       "  'ke',\n",
       "  '▁,',\n",
       "  '▁but',\n",
       "  '▁w',\n",
       "  'ent',\n",
       "  '▁by',\n",
       "  '▁the',\n",
       "  '▁sh',\n",
       "  'ore',\n",
       "  '▁of',\n",
       "  '▁the',\n",
       "  '▁s',\n",
       "  'ound',\n",
       "  'ing',\n",
       "  '▁se',\n",
       "  'a',\n",
       "  '▁and',\n",
       "  '▁p',\n",
       "  'r',\n",
       "  'ay',\n",
       "  'ed',\n",
       "  '▁a',\n",
       "  'p',\n",
       "  'ar',\n",
       "  't',\n",
       "  '▁to',\n",
       "  '▁',\n",
       "  'K',\n",
       "  'ing',\n",
       "  '▁A',\n",
       "  'p',\n",
       "  'o',\n",
       "  'll',\n",
       "  'o',\n",
       "  '▁who',\n",
       "  'm',\n",
       "  '▁l',\n",
       "  'ove',\n",
       "  'ly',\n",
       "  '▁',\n",
       "  'L',\n",
       "  'et',\n",
       "  'o',\n",
       "  '▁had',\n",
       "  '▁b',\n",
       "  'or',\n",
       "  'n',\n",
       "  'e',\n",
       "  '▁.',\n",
       "  '▁\"',\n",
       "  '▁He',\n",
       "  'ar',\n",
       "  '▁me',\n",
       "  '▁,',\n",
       "  '▁\"',\n",
       "  '▁he',\n",
       "  '▁c',\n",
       "  'ri',\n",
       "  'ed',\n",
       "  '▁,',\n",
       "  '▁\"',\n",
       "  '▁',\n",
       "  'O',\n",
       "  '▁go',\n",
       "  'd',\n",
       "  '▁of',\n",
       "  '▁the',\n",
       "  '▁s',\n",
       "  'il',\n",
       "  'ver',\n",
       "  '▁b',\n",
       "  'ow',\n",
       "  '▁,',\n",
       "  '▁that',\n",
       "  '▁p',\n",
       "  'ro',\n",
       "  't',\n",
       "  'e',\n",
       "  'ct',\n",
       "  'est',\n",
       "  '▁',\n",
       "  'C',\n",
       "  'h',\n",
       "  'r',\n",
       "  'y',\n",
       "  'se',\n",
       "  '▁and',\n",
       "  '▁h',\n",
       "  'o',\n",
       "  'ly',\n",
       "  '▁',\n",
       "  'C',\n",
       "  'ill',\n",
       "  'a',\n",
       "  '▁and',\n",
       "  '▁r',\n",
       "  'u',\n",
       "  'le',\n",
       "  'st',\n",
       "  '▁T',\n",
       "  'en',\n",
       "  'ed',\n",
       "  'o',\n",
       "  's',\n",
       "  '▁with',\n",
       "  '▁th',\n",
       "  'y',\n",
       "  '▁m',\n",
       "  'ight',\n",
       "  '▁,',\n",
       "  '▁he',\n",
       "  'ar',\n",
       "  '▁me',\n",
       "  '▁o',\n",
       "  'h',\n",
       "  '▁th',\n",
       "  'ou',\n",
       "  '▁of',\n",
       "  '▁S',\n",
       "  'm',\n",
       "  'in',\n",
       "  'th',\n",
       "  'e',\n",
       "  '▁.',\n",
       "  '▁I',\n",
       "  'f',\n",
       "  '▁I',\n",
       "  '▁have',\n",
       "  '▁e',\n",
       "  'ver',\n",
       "  '▁de',\n",
       "  'ck',\n",
       "  'ed',\n",
       "  '▁your',\n",
       "  '▁t',\n",
       "  'e',\n",
       "  'm',\n",
       "  'p',\n",
       "  'le',\n",
       "  '▁with',\n",
       "  '▁g',\n",
       "  'ar',\n",
       "  'l',\n",
       "  'and',\n",
       "  's',\n",
       "  '▁,',\n",
       "  '▁or',\n",
       "  '▁b',\n",
       "  'ur',\n",
       "  'n',\n",
       "  'ed',\n",
       "  '▁your',\n",
       "  '▁th',\n",
       "  'i',\n",
       "  'gh',\n",
       "  '▁-',\n",
       "  '▁b',\n",
       "  'on',\n",
       "  'es',\n",
       "  '▁in',\n",
       "  '▁f',\n",
       "  'at',\n",
       "  '▁of',\n",
       "  '▁b',\n",
       "  'u',\n",
       "  'll',\n",
       "  's',\n",
       "  '▁or',\n",
       "  '▁go',\n",
       "  'at',\n",
       "  's',\n",
       "  '▁,',\n",
       "  '▁g',\n",
       "  'r',\n",
       "  'an',\n",
       "  't',\n",
       "  '▁my',\n",
       "  '▁p',\n",
       "  'r',\n",
       "  'ay',\n",
       "  'er',\n",
       "  '▁,',\n",
       "  '▁and',\n",
       "  '▁le',\n",
       "  't',\n",
       "  '▁your',\n",
       "  '▁a',\n",
       "  'r',\n",
       "  'r',\n",
       "  'ow',\n",
       "  's',\n",
       "  '▁a',\n",
       "  'ven',\n",
       "  'g',\n",
       "  'e',\n",
       "  '▁the',\n",
       "  'se',\n",
       "  '▁my',\n",
       "  '▁t',\n",
       "  'ear',\n",
       "  's',\n",
       "  '▁up',\n",
       "  'on',\n",
       "  '▁the',\n",
       "  '▁',\n",
       "  'D',\n",
       "  'an',\n",
       "  'a',\n",
       "  'ans',\n",
       "  '▁.',\n",
       "  '▁\"',\n",
       "  '▁T',\n",
       "  ...],\n",
       " 3265027.6823994797)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swords_text, nll = unigram.tokenize(text)\n",
    "swords_text, nll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uni_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:31<00:00,  7.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('ing', 4.537382457558073), 3306107.5517700408],\n",
       " [('▁go', 5.548547607736448), 3271188.935935537],\n",
       " [('es', 5.233293879348584), 3271601.596745802],\n",
       " [('▁the', 3.673984438805741), 3355981.5949805058],\n",
       " [('▁an', 5.969913221919169), 3268895.6580680325],\n",
       " [('er', 4.781520687364294), 3280204.038174003],\n",
       " [('▁of', 4.243653038183809), 3325396.117282533],\n",
       " [('▁Ach', 6.381177217023477), 3269851.5430730497],\n",
       " [('ill', 5.861028794722362), 3273985.120758836],\n",
       " [('▁son', 6.087315928205737), 3270410.2896017404],\n",
       " [('le', 4.916961489712882), 3279223.692795845],\n",
       " [('us', 4.71116870032866), 3283792.1910348255],\n",
       " [('▁that', 5.526820503796648), 3278226.1662566448],\n",
       " [('▁br', 6.304318211497865), 3268232.7728315843],\n",
       " [('ough', 6.220358538377594), 3272541.782391051],\n",
       " [('ou', 5.845323083314186), 3267246.4764114157],\n",
       " [('▁up', 6.0230341135257435), 3275177.2513445555],\n",
       " [('on', 4.965698565463541), 3279495.999228436],\n",
       " [('ae', 6.510388948503483), 3266185.403442203],\n",
       " [('ans', 5.949430578133228), 3269748.6249654917],\n",
       " [('an', 5.100600541756806), 3277516.2177879447],\n",
       " [('ve', 6.218796038059703), 3268415.7620583703],\n",
       " [('id', 5.568310299727816), 3275387.096798451],\n",
       " [('▁it', 5.631356384525688), 3274202.1012116736],\n",
       " [('▁se', 5.885898824797009), 3269300.2632186897],\n",
       " [('nd', 5.617569005417579), 3268997.8995111603],\n",
       " [('ur', 5.800147334584238), 3270965.806761005],\n",
       " [('ow', 5.053257371073028), 3275616.0184154273],\n",
       " [('▁to', 4.399447727233704), 3300661.3987903832],\n",
       " [('ad', 5.637448657502942), 3272777.1937246304],\n",
       " [('▁and', 4.026963715918133), 3335117.1479907334],\n",
       " [('▁man', 6.26268022346028), 3269361.2947466867],\n",
       " [('▁her', 6.119307529879099), 3268974.450156595],\n",
       " [('ie', 6.54873230370113), 3266459.246355639],\n",
       " [('ld', 5.807363860748106), 3272205.9547898667],\n",
       " [('re', 4.926349226674993), 3274734.925294874],\n",
       " [('▁do', 6.505177889290731), 3267381.4673827933],\n",
       " [('▁for', 5.297677012404108), 3278815.379851279],\n",
       " [('▁so', 5.9608250042611965), 3269794.758328771],\n",
       " [('▁were', 6.325805931234554), 3270803.6193106957],\n",
       " [('sel', 6.518783541346509), 3268465.9410043824],\n",
       " [('ove', 6.457477319602828), 3268405.9497026526],\n",
       " [('ed', 4.306107015561126), 3300086.357966766],\n",
       " [('▁from', 6.046411801534806), 3276369.890692371],\n",
       " [('ay', 5.349330189670026), 3273761.048264624],\n",
       " [('▁on', 5.658622805436229), 3272015.5772405006],\n",
       " [('▁whi', 6.241694788296393), 3271136.5745283747],\n",
       " [('ch', 5.3552376568007185), 3281328.627385075],\n",
       " [('en', 5.166790506580082), 3273229.345926958],\n",
       " [('at', 5.118623686672691), 3275175.0214560037],\n",
       " [('ir', 6.134259748635968), 3269008.436610247],\n",
       " [('st', 5.561409521378856), 3269131.6844686195],\n",
       " [('ell', 6.230574737252316), 3269451.1620775736],\n",
       " [('out', 5.797070409079758), 3271805.3794965018],\n",
       " [('▁with', 5.35655518004796), 3287096.3381507164],\n",
       " [('▁one', 6.468439063644973), 3267992.1022448046],\n",
       " [('ther', 5.4903691250642845), 3274860.131487832],\n",
       " [('▁was', 5.639633495601681), 3277133.0041488754],\n",
       " [('▁them', 5.807881325183974), 3270677.7861090573],\n",
       " [('ar', 5.261664576477799), 3273238.3075379785],\n",
       " [('et', 6.08458181850527), 3267657.24573887],\n",
       " [('▁he', 4.586208943758637), 3291333.2878288934],\n",
       " [('ent', 5.823531096851101), 3271348.213804379],\n",
       " [('est', 6.597685347584254), 3266938.4026305825],\n",
       " [('il', 6.483583219809271), 3267397.52010857],\n",
       " [('ce', 5.679799537327016), 3271897.0126286307],\n",
       " [('▁be', 5.1306468320281775), 3277439.714231258],\n",
       " [('▁had', 5.921210010490977), 3273527.843517043],\n",
       " [('is', 5.739855104328117), 3269195.104992056],\n",
       " [('our', 6.0589739502034625), 3269688.350656386],\n",
       " [('ses', 6.300075523759075), 3268009.6464949106],\n",
       " [('▁his', 5.143348775758202), 3286836.3368170625],\n",
       " [('ri', 5.9137020341310995), 3268991.245044874],\n",
       " [('ome', 5.798094999333326), 3272169.0240835063],\n",
       " [('▁ship', 6.660021810046965), 3270788.3994055893],\n",
       " [('ght', 7.578134589191065), 3265844.3613296044],\n",
       " [('▁him', 5.313652293417797), 3285925.5533170304],\n",
       " [('om', 6.18351630562423), 3268216.2882947964],\n",
       " [('ore', 6.158217337304971), 3268688.678698628],\n",
       " [('ver', 5.558985277767349), 3274630.075403911],\n",
       " [('▁in', 4.8664436073682), 3286945.281626011],\n",
       " [('▁ha', 5.764330139042883), 3267897.483680415],\n",
       " [('ll', 6.834606384338768), 3266220.5934180375],\n",
       " [('th', 5.698646337418589), 3271095.445559632],\n",
       " [('▁su', 6.41289629404627), 3268248.939352239],\n",
       " [('▁but', 5.988341261831228), 3274160.6177115766],\n",
       " [('▁all', 5.966268017396838), 3271555.0699879364],\n",
       " [('▁who', 5.9194723905924365), 3272794.4653318655],\n",
       " [('▁their', 6.1812581187406375), 3269851.573870808],\n",
       " [('▁ch', 6.4466344336781205), 3267732.558108831],\n",
       " [('ly', 5.327963238881059), 3276029.447117249],\n",
       " [('▁you', 5.154596885779357), 3294162.6670939596],\n",
       " [('▁sa', 6.6833500625378734), 3266683.884244756],\n",
       " [('ck', 5.990202881977928), 3272757.0445284406],\n",
       " [('it', 5.803233756787427), 3270565.830418973],\n",
       " [('am', 6.51352866850815), 3267234.944921847],\n",
       " [('▁re', 6.129964824353087), 3267863.479648741],\n",
       " [('▁your', 6.140736921334998), 3269923.5398938935],\n",
       " [('▁my', 6.0346546445487625), 3270130.9771396774],\n",
       " [('▁this', 6.5251260573229795), 3269535.7866309723],\n",
       " [('ct', 6.442720534356984), 3268149.759845032],\n",
       " [('▁not', 5.900555231460231), 3272891.187409703],\n",
       " [('ame', 6.41955347507545), 3269022.65251699],\n",
       " [('▁sp', 5.948834452929286), 3271437.764777338],\n",
       " [('ke', 5.672539977314211), 3271351.5107376603],\n",
       " [('▁said', 6.585220596964267), 3270059.4809111916],\n",
       " [('▁le', 6.352215916884277), 3266847.7987727937],\n",
       " [('▁me', 5.724499716244923), 3270727.536208959],\n",
       " [('ind', 6.590867139352477), 3268150.4237682363],\n",
       " [('▁ab', 6.559649442696479), 3268332.610615922],\n",
       " [('or', 5.0440518797100555), 3277669.6269355724],\n",
       " [('ter', 6.347765531256801), 3267734.7851758674],\n",
       " [('▁sh', 5.740822690276853), 3274322.0022514677],\n",
       " [('all', 6.1164846627963945), 3271181.3178768912],\n",
       " [('ro', 5.988341261831228), 3268981.714634426],\n",
       " [('▁will', 6.05036177375412), 3271866.3650084483],\n",
       " [('he', 7.772073519076736), 3265408.9012203133],\n",
       " [('se', 5.644457008571386), 3268594.102528858],\n",
       " [('▁at', 6.206383155639993), 3268203.6554145683],\n",
       " [('▁or', 6.601111964300902), 3266993.6396203497],\n",
       " [('▁The', 5.95062389569727), 3274921.5394355655],\n",
       " [('ear', 5.9542124162946015), 3269248.8092050552],\n",
       " [('ot', 6.692083742506628), 3266193.1468482157],\n",
       " [('▁by', 6.282450224861284), 3269092.5042694323],\n",
       " [('ound', 6.3922576628000485), 3270488.755676226],\n",
       " [('▁He', 6.218015702475822), 3271314.9954471244],\n",
       " [('▁th', 5.565869289565382), 3274726.790426136],\n",
       " [('ight', 5.899420157558567), 3275779.5994930943],\n",
       " [('in', 5.591385077116742), 3272286.343003854],\n",
       " [('▁have', 6.053003783216958), 3273959.1063226736],\n",
       " [('▁de', 6.649158697789594), 3266769.0233107633],\n",
       " [('and', 6.510388948503483), 3267807.4070439455],\n",
       " [('gh', 7.721703159687786), 3265777.7169258883],\n",
       " [('ven', 6.268406210475166), 3269514.8767166245],\n",
       " [('ard', 6.3188794966166855), 3269931.2531281626],\n",
       " [('ould', 5.9482386828788965), 3274605.4510299484],\n",
       " [('▁as', 5.518647662040774), 3271877.247683823],\n",
       " [('im', 6.700894372188784), 3267304.548027584],\n",
       " [('ong', 6.257798195862972), 3269448.444463649],\n",
       " [('▁am', 6.623090871019677), 3267555.883848973],\n",
       " [('▁there', 6.561847245778958), 3266880.6665549893],\n",
       " [('un', 6.3784261836515865), 3267996.121280287],\n",
       " [('as', 6.2456963942764006), 3266659.554187306],\n",
       " [('▁when', 6.410056727538192), 3270917.6430863547],\n",
       " [('▁they', 5.862121094120971), 3269489.6379488455],\n",
       " [('▁we', 6.417646896804868), 3267222.1820270442],\n",
       " [('if', 6.26349621697761), 3268643.6836058036],\n",
       " [('▁are', 6.377510851779898), 3268383.7485152483],\n",
       " [('ut', 6.612619571152382), 3267138.952955736],\n",
       " [('▁wh', 6.81033681342431), 3267054.7613707506],\n",
       " [('▁is', 5.974794256625083), 3270870.205389641],\n",
       " [('ith', 7.931774629434644), 3265554.1070309104],\n",
       " [('al', 6.345104775806775), 3267388.785813121],\n",
       " [('od', 6.1530872417739415), 3269251.754254834],\n",
       " [('▁st', 5.514007282484272), 3273922.9398457115],\n",
       " [('ive', 6.4339698708367985), 3269063.6004064996],\n",
       " [('ain', 6.092806676386154), 3269947.9979966264],\n",
       " [('▁no', 6.568469786539452), 3267777.6798031023],\n",
       " [('ep', 6.469441569994599), 3267093.5925900913],\n",
       " [('▁she', 6.41194887569023), 3268265.7099460354],\n",
       " [('hen', 7.452613920312621), 3266195.8088417994],\n",
       " [('ip', 7.9103605349308275), 3265385.8417472467],\n",
       " [('lo', 6.427216347821019), 3267251.0454604384],\n",
       " [('▁fr', 7.3150691443746405), 3265530.8823400135],\n",
       " [('her', 6.797722770908213), 3265627.4887778256]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swords_excl_one = []\n",
    "for token in tqdm(uni_probs):\n",
    "    if len(token) == 1:\n",
    "        continue\n",
    "    if len(token) == 2 and token[0] == '▁':\n",
    "        continue\n",
    "    sword_excl = (token, uni_probs[token])\n",
    "    uni_prob_temp = dict(uni_probs)\n",
    "    uni_prob_temp.pop(token)\n",
    "    unigram = Unigram(uni_prob_temp)\n",
    "    nll_text = unigram.tokenize(text)[1]\n",
    "    swords_excl_one += [[sword_excl, nll_text]]\n",
    "swords_excl_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ip', 7.9103605349308275), 3265385.8417472467],\n",
       " [('he', 7.772073519076736), 3265408.9012203133],\n",
       " [('▁fr', 7.3150691443746405), 3265530.8823400135],\n",
       " [('ith', 7.931774629434644), 3265554.1070309104],\n",
       " [('her', 6.797722770908213), 3265627.4887778256],\n",
       " [('gh', 7.721703159687786), 3265777.7169258883],\n",
       " [('ght', 7.578134589191065), 3265844.3613296044],\n",
       " [('ae', 6.510388948503483), 3266185.403442203],\n",
       " [('ot', 6.692083742506628), 3266193.1468482157],\n",
       " [('hen', 7.452613920312621), 3266195.8088417994]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(swords_excl_one, key=lambda x: x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
