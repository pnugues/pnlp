{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa3ccdd9-ace9-4c89-ad8e-0faebeec5c20",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chapter 17: Sequence-to-Sequence Architectures: Encoder-Decoders and Decoders\n",
    "Masked attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d90e41",
   "metadata": {},
   "source": [
    "Programs from the book: [_Python for Natural Language Processing_](https://link.springer.com/book/9783031575488)\n",
    "\n",
    "__Author__: Pierre Nugues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba630853-00e0-4b64-ab86-01185c2deb0e",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d21c1d0-b06a-4340-bf3d-419a6edaf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5940e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10aa61070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede5c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f6cdf",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0310511",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_odyssey = 'I must go back to my ship and to my crew'\n",
    "sentence_amazon = 'We process and ship your order'\n",
    "# in the most cost-efficient way possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "766e083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'must', 'go', 'back', 'to', 'my', 'ship', 'and', 'to', 'my', 'crew']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_a = sentence_amazon.lower().split()\n",
    "words_o = sentence_odyssey.lower().split()\n",
    "words_o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9119bcd1-e5af-4b3a-bd87-45276f71c7db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d84fbb-b15e-45c0-bba8-6074ec0bb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    with open(file, encoding='utf8') as glove:\n",
    "        for line in glove:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = [float(value) for value in values[1:]]\n",
    "            vector = torch.FloatTensor(vector)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f855dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../corpus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14e0a3c6-6e89-4500-b555-fb40efb5bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = PATH + 'glove.6B.50d.txt'\n",
    "embeddings_dict = read_embeddings(embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ba6dc1-a704-4e08-b89b-fc5325ebcf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.52,  0.11,  0.38, -0.51,  0.03, -0.13, -1.25,  0.80,  0.85, -1.10,\n",
       "         0.89,  1.37,  0.43,  0.66, -0.26, -0.42, -0.49,  0.91, -1.72, -0.44,\n",
       "         0.78,  0.20, -0.41, -0.54,  0.82, -1.74,  0.14,  0.28,  1.17,  0.17,\n",
       "         2.23, -0.58, -0.46,  0.63,  0.54,  0.28,  0.44, -0.55, -0.36, -0.02,\n",
       "         0.41, -0.87,  1.55, -0.81, -0.10, -0.28, -0.33, -0.51,  0.48, -0.66])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['ship']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "600768d3-408b-48cc-994d-710fdb0c45df",
   "metadata": {},
   "source": [
    "We build the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef726a70-39fb-4bc9-826b-fa4efa6f889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(words, embeddings_dict):\n",
    "    embeddings_seq = [embeddings_dict[word] for word in words]\n",
    "    embeddings_seq = torch.stack(embeddings_seq)\n",
    "    return embeddings_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4dbf6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = embedding_matrix(words_a, embeddings_dict)\n",
    "X_o = embedding_matrix(words_o, embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97d5907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_o.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788b9eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "807f131d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.19e-01,  1.53e-01, -8.21e-02, -7.41e-01,  7.59e-01, -4.83e-01,\n",
       "        -3.10e-01,  5.15e-01, -9.87e-01,  6.18e-04])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_o[0][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61f8b7cf-0ef8-46dd-96d2-e94601dcdf45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b4c43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q, K, V):\n",
    "    d_k = K.size(dim=-1)\n",
    "    attn_weights = F.softmax(Q @ K.T/math.sqrt(d_k), dim=-1)\n",
    "    attn_output = attn_weights @ V\n",
    "    return attn_output, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7b8ca",
   "metadata": {},
   "source": [
    "_ship_ in Homer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20344544",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_output_o, attn_weights_o = attention(X_o, X_o, X_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fe5c321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.36, 0.05, 0.07, 0.05, 0.04, 0.19, 0.01, 0.02, 0.04, 0.19, 0.01],\n",
       "        [0.14, 0.20, 0.10, 0.06, 0.11, 0.10, 0.03, 0.05, 0.11, 0.10, 0.02],\n",
       "        [0.18, 0.09, 0.14, 0.09, 0.08, 0.13, 0.02, 0.04, 0.08, 0.13, 0.02],\n",
       "        [0.14, 0.05, 0.09, 0.19, 0.08, 0.12, 0.03, 0.06, 0.08, 0.12, 0.03],\n",
       "        [0.11, 0.11, 0.09, 0.09, 0.15, 0.08, 0.04, 0.07, 0.15, 0.08, 0.03],\n",
       "        [0.19, 0.03, 0.05, 0.04, 0.03, 0.29, 0.01, 0.02, 0.03, 0.29, 0.01],\n",
       "        [0.03, 0.03, 0.03, 0.04, 0.05, 0.03, 0.55, 0.03, 0.05, 0.03, 0.13],\n",
       "        [0.10, 0.08, 0.07, 0.10, 0.12, 0.09, 0.04, 0.15, 0.12, 0.09, 0.04],\n",
       "        [0.11, 0.11, 0.09, 0.09, 0.15, 0.08, 0.04, 0.07, 0.15, 0.08, 0.03],\n",
       "        [0.19, 0.03, 0.05, 0.04, 0.03, 0.29, 0.01, 0.02, 0.03, 0.29, 0.01],\n",
       "        [0.06, 0.05, 0.05, 0.06, 0.05, 0.06, 0.21, 0.04, 0.05, 0.06, 0.31]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fc9eaba",
   "metadata": {},
   "source": [
    "The word _ship_ in another context: _We process and ship your order_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70859d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_output_a, attn_weights_a = attention(X_a, X_a, X_a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cbaaf4a",
   "metadata": {},
   "source": [
    "Attention weights for _ship:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8bfb2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.61, 0.06, 0.06, 0.02, 0.20, 0.05],\n",
       "        [0.17, 0.50, 0.08, 0.03, 0.11, 0.11],\n",
       "        [0.22, 0.12, 0.30, 0.08, 0.15, 0.13],\n",
       "        [0.04, 0.03, 0.04, 0.78, 0.05, 0.06],\n",
       "        [0.14, 0.03, 0.03, 0.02, 0.74, 0.04],\n",
       "        [0.16, 0.13, 0.10, 0.09, 0.18, 0.34]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb065c0",
   "metadata": {},
   "source": [
    "### Masked Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a0381d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attn_mask(size):\n",
    "    U = torch.empty(size, size).fill_(float('-inf'))\n",
    "    return torch.triu(U, diagonal=1)\n",
    "\n",
    "\n",
    "attn_mask(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "292e6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_masked(Q, K, V, U):\n",
    "    d_k = K.size(dim=-1)\n",
    "    attn_weights = F.softmax(Q @ K.T/math.sqrt(d_k)\n",
    "                             + U, dim=-1)\n",
    "    attn_output = attn_weights @ V\n",
    "    return attn_output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "450038fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = attn_mask(X_o.size(dim=0))\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f71dac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output_masked, attn_weights_masked = attention_masked(X_o, X_o, X_o, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c64462b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.42, 0.58, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.44, 0.22, 0.35, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.29, 0.11, 0.19, 0.40, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.20, 0.20, 0.16, 0.17, 0.27, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.30, 0.05, 0.08, 0.07, 0.04, 0.45, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.04, 0.04, 0.04, 0.05, 0.06, 0.04, 0.73, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.14, 0.10, 0.09, 0.13, 0.16, 0.12, 0.05, 0.21, 0.00, 0.00, 0.00],\n",
       "        [0.12, 0.12, 0.10, 0.11, 0.16, 0.10, 0.04, 0.08, 0.16, 0.00, 0.00],\n",
       "        [0.20, 0.03, 0.05, 0.05, 0.03, 0.29, 0.01, 0.02, 0.03, 0.29, 0.00],\n",
       "        [0.06, 0.05, 0.05, 0.06, 0.05, 0.06, 0.21, 0.04, 0.05, 0.06, 0.31]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57eb77e",
   "metadata": {},
   "source": [
    "## PyTorch Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54fb5070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = nn.Transformer.generate_square_subsequent_mask(X_a.size(dim=0))\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00dfebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output_masked, attn_weights_masked = attention_masked(X_a, X_a, X_a, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "346a11e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.25, 0.75, 0.00, 0.00, 0.00, 0.00],\n",
       "        [0.35, 0.18, 0.47, 0.00, 0.00, 0.00],\n",
       "        [0.05, 0.03, 0.05, 0.88, 0.00, 0.00],\n",
       "        [0.15, 0.03, 0.03, 0.02, 0.77, 0.00],\n",
       "        [0.16, 0.13, 0.10, 0.09, 0.18, 0.34]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_masked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
